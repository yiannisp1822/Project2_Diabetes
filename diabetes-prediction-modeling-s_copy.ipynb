{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diabetes Prediction Modeling Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, balanced_accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, OrdinalEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Needed for decision tree visualization\n",
    "import pydotplus\n",
    "from IPython.display import Image\n",
    "from sklearn import tree\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found our data on Kaggle at the following [link, found by Alex Teboul](https://www.kaggle.com/datasets/alexteboul/diabetes-health-indicators-dataset/data). This data set was obtained from the Behavioral Risk Factor Surveillance System (BRFSS), which is a health-related telephone survey that is collected annually by the CDC. It is an annual survey that has been collected since 1984 and the features are either questions asked of participants or variables calculated based on their responses. We will use this dataset to create a machine learning model that predicts based on the given data, whether a person has diabetes or does not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes_binary</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>...</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Diabetes_binary  HighBP  HighChol  CholCheck   BMI  Smoker  Stroke  \\\n",
       "0              0.0     1.0       0.0        1.0  26.0     0.0     0.0   \n",
       "1              0.0     1.0       1.0        1.0  26.0     1.0     1.0   \n",
       "2              0.0     0.0       0.0        1.0  26.0     0.0     0.0   \n",
       "3              0.0     1.0       1.0        1.0  28.0     1.0     0.0   \n",
       "4              0.0     0.0       0.0        1.0  29.0     1.0     0.0   \n",
       "\n",
       "   HeartDiseaseorAttack  PhysActivity  Fruits  ...  AnyHealthcare  \\\n",
       "0                   0.0           1.0     0.0  ...            1.0   \n",
       "1                   0.0           0.0     1.0  ...            1.0   \n",
       "2                   0.0           1.0     1.0  ...            1.0   \n",
       "3                   0.0           1.0     1.0  ...            1.0   \n",
       "4                   0.0           1.0     1.0  ...            1.0   \n",
       "\n",
       "   NoDocbcCost  GenHlth  MentHlth  PhysHlth  DiffWalk  Sex   Age  Education  \\\n",
       "0          0.0      3.0       5.0      30.0       0.0  1.0   4.0        6.0   \n",
       "1          0.0      3.0       0.0       0.0       0.0  1.0  12.0        6.0   \n",
       "2          0.0      1.0       0.0      10.0       0.0  1.0  13.0        6.0   \n",
       "3          0.0      3.0       0.0       3.0       0.0  1.0  11.0        6.0   \n",
       "4          0.0      2.0       0.0       0.0       0.0  0.0   8.0        5.0   \n",
       "\n",
       "   Income  \n",
       "0     8.0  \n",
       "1     8.0  \n",
       "2     8.0  \n",
       "3     8.0  \n",
       "4     8.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the data (found in \\Resources)\n",
    "diabetes = pd.read_csv(\"Resources/diabetes_binary_5050split_health_indicators_BRFSS2015.csv\")\n",
    "\n",
    "# Head (To view the data)\n",
    "diabetes.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA \n",
    "Now we will begin diving deeper into our dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Diabetes_binary', 'HighBP', 'HighChol', 'CholCheck', 'BMI', 'Smoker',\n",
       "       'Stroke', 'HeartDiseaseorAttack', 'PhysActivity', 'Fruits', 'Veggies',\n",
       "       'HvyAlcoholConsump', 'AnyHealthcare', 'NoDocbcCost', 'GenHlth',\n",
       "       'MentHlth', 'PhysHlth', 'DiffWalk', 'Sex', 'Age', 'Education',\n",
       "       'Income'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column Descriptions\n",
    "Below are the detailed descriptions of the columns/features used for the dataset:\n",
    "\n",
    "1. **Diabetes_binary**: 0 = no diabetes, 1 = prediabetes or diabetes\n",
    "2. **HighBP**: 0 = no high, BP 1 = high BP\n",
    "3. **HighChol**: 0 = no high cholesterol, 1 = high cholesterol\n",
    "4. **CholCheck**: 0 = no cholesterol check in 5 years, 1 = yes cholesterol check in 5 years\n",
    "5. **BMI**: Body Mass Index of the person questioned.\n",
    "6. **Smoker**: Have you smoked at least 100 cigarettes in your entire life? [Note: 5 packs = 100 cigarettes] 0 = no, 1 = yes\n",
    "7. **Stroke**: (Ever) had a stroke; 0 = no, 1 = yes\n",
    "8. **HeartDiseaseorAttack**: coronary heart disease (CHD) or myocardial infarction (MI); 0 = no, 1 = yes\n",
    "9. **PhysActivity**: physical activity in past 30 days - not including job; 0 = no, 1 = yes\n",
    "10. **Fruits**: Consume Fruit 1 or more times per day; 0 = no, 1 = yes\n",
    "11. **Veggies**: Consume Vegetables 1 or more times per day; 0 = no, 1 = yes\n",
    "12. **HvyAlcoholConsump**: Heavy drinkers (adult men having more than 14 drinks per week and adult women having more than 7 drinks per week) 0 = no, 1 = yes\n",
    "13. **AnyHealthcare**: Have any kind of health care coverage, including health insurance, prepaid plans such as HMO, etc. 0 = no, 1 = yes\n",
    "14. **NoDocbcCost**: \"Was there a time in the past 12 months when you needed to see a doctor but could not because of cost?\" 0 = no, 1 = yes\n",
    "15. **GenHlth**: \"Would you say that in general your health is?\": scale 1-5; 1 = excellent, 2 = very good, 3 = good, 4 = fair, 5 = poor\n",
    "16. **MentHlth**: \"Now thinking about your mental health, which includes stress, depression, and problems with emotions, for how many days during the past 30 days was your mental health not good?\" scale 1-30 days\n",
    "17. **PhysHlth**: \"Now thinking about your physical health, which includes physical illness and injury, for how many days during the past 30 days was your physical health not good?\" scale 1-30 days\n",
    "18. **DiffWalk**: \"Do you have serious difficulty walking or climbing stairs?\" 0 = no, 1 = yes\n",
    "19. **Sex**: 0 = female, 1 = male\n",
    "20. **Age**: 13-level age category (_AGEG5YR see codebook) 1 = 18-24 9 = 60-64 13 = 80 or older\n",
    "    - 1 = Age 18 to 24\n",
    "    - 2 = Age 25 to 29\n",
    "    - 3 = Age 30 to 34\n",
    "    - 4 = Age 35 to 39\n",
    "    - 5 = Age 40 to 44\n",
    "    - 6 = Age 45 to 49\n",
    "    - 7 = Age 50 to 54\n",
    "    - 8 = Age 55 to 59\n",
    "    - 9 = Age 60 to 64\n",
    "    - 10 = Age 65 to 69\n",
    "    - 11 = Age 70 to 74\n",
    "    - 12 = Age 75 to 79\n",
    "    - 13 = Age 80 or older \n",
    "21. **Education**: Education Level\n",
    "    - 1 = Never attended school or only kindergarten\n",
    "    - 2 = Grades 1 through 8 (Elementary)\n",
    "    - 3 = Grades 9 through 11 (Some high school)\n",
    "    - 4 = Grade 12 or GED (High school graduate)\n",
    "    - 5 = College 1 year to 3 years (Some college or technical school)\n",
    "    - 6 = College 4 years or more (College graduate)\n",
    "22. **Income**: Income Scale\n",
    "    - 1 = Less than $10,000\n",
    "    - 2 = Less than $15,000 ($10,000 to less than $15,000)\n",
    "    - 3 = Less than $20,000 ($15,000 to less than $20,000)\n",
    "    - 4 = Less than $25,000 ($20,000 to less than $25,000)\n",
    "    - 5 = Less than $35,000 ($25,000 to less than $35,000)\n",
    "    - 6 = Less than $50,000 ($35,000 to less than $50,000)\n",
    "    - 7 = Less than $75,000 ($50,000 to less than $75,000)\n",
    "    - 8 = $75,000 or more\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describing the dataset at a glance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes_binary</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>...</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.563458</td>\n",
       "      <td>0.525703</td>\n",
       "      <td>0.975259</td>\n",
       "      <td>29.856985</td>\n",
       "      <td>0.475273</td>\n",
       "      <td>0.062171</td>\n",
       "      <td>0.147810</td>\n",
       "      <td>0.703036</td>\n",
       "      <td>0.611795</td>\n",
       "      <td>...</td>\n",
       "      <td>0.954960</td>\n",
       "      <td>0.093914</td>\n",
       "      <td>2.837082</td>\n",
       "      <td>3.752037</td>\n",
       "      <td>5.810417</td>\n",
       "      <td>0.252730</td>\n",
       "      <td>0.456997</td>\n",
       "      <td>8.584055</td>\n",
       "      <td>4.920953</td>\n",
       "      <td>5.698311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.500004</td>\n",
       "      <td>0.495960</td>\n",
       "      <td>0.499342</td>\n",
       "      <td>0.155336</td>\n",
       "      <td>7.113954</td>\n",
       "      <td>0.499392</td>\n",
       "      <td>0.241468</td>\n",
       "      <td>0.354914</td>\n",
       "      <td>0.456924</td>\n",
       "      <td>0.487345</td>\n",
       "      <td>...</td>\n",
       "      <td>0.207394</td>\n",
       "      <td>0.291712</td>\n",
       "      <td>1.113565</td>\n",
       "      <td>8.155627</td>\n",
       "      <td>10.062261</td>\n",
       "      <td>0.434581</td>\n",
       "      <td>0.498151</td>\n",
       "      <td>2.852153</td>\n",
       "      <td>1.029081</td>\n",
       "      <td>2.175196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Diabetes_binary        HighBP      HighChol     CholCheck  \\\n",
       "count     70692.000000  70692.000000  70692.000000  70692.000000   \n",
       "mean          0.500000      0.563458      0.525703      0.975259   \n",
       "std           0.500004      0.495960      0.499342      0.155336   \n",
       "min           0.000000      0.000000      0.000000      0.000000   \n",
       "25%           0.000000      0.000000      0.000000      1.000000   \n",
       "50%           0.500000      1.000000      1.000000      1.000000   \n",
       "75%           1.000000      1.000000      1.000000      1.000000   \n",
       "max           1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "                BMI        Smoker        Stroke  HeartDiseaseorAttack  \\\n",
       "count  70692.000000  70692.000000  70692.000000          70692.000000   \n",
       "mean      29.856985      0.475273      0.062171              0.147810   \n",
       "std        7.113954      0.499392      0.241468              0.354914   \n",
       "min       12.000000      0.000000      0.000000              0.000000   \n",
       "25%       25.000000      0.000000      0.000000              0.000000   \n",
       "50%       29.000000      0.000000      0.000000              0.000000   \n",
       "75%       33.000000      1.000000      0.000000              0.000000   \n",
       "max       98.000000      1.000000      1.000000              1.000000   \n",
       "\n",
       "       PhysActivity        Fruits  ...  AnyHealthcare   NoDocbcCost  \\\n",
       "count  70692.000000  70692.000000  ...   70692.000000  70692.000000   \n",
       "mean       0.703036      0.611795  ...       0.954960      0.093914   \n",
       "std        0.456924      0.487345  ...       0.207394      0.291712   \n",
       "min        0.000000      0.000000  ...       0.000000      0.000000   \n",
       "25%        0.000000      0.000000  ...       1.000000      0.000000   \n",
       "50%        1.000000      1.000000  ...       1.000000      0.000000   \n",
       "75%        1.000000      1.000000  ...       1.000000      0.000000   \n",
       "max        1.000000      1.000000  ...       1.000000      1.000000   \n",
       "\n",
       "            GenHlth      MentHlth      PhysHlth      DiffWalk           Sex  \\\n",
       "count  70692.000000  70692.000000  70692.000000  70692.000000  70692.000000   \n",
       "mean       2.837082      3.752037      5.810417      0.252730      0.456997   \n",
       "std        1.113565      8.155627     10.062261      0.434581      0.498151   \n",
       "min        1.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        2.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        3.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        4.000000      2.000000      6.000000      1.000000      1.000000   \n",
       "max        5.000000     30.000000     30.000000      1.000000      1.000000   \n",
       "\n",
       "                Age     Education        Income  \n",
       "count  70692.000000  70692.000000  70692.000000  \n",
       "mean       8.584055      4.920953      5.698311  \n",
       "std        2.852153      1.029081      2.175196  \n",
       "min        1.000000      1.000000      1.000000  \n",
       "25%        7.000000      4.000000      4.000000  \n",
       "50%        9.000000      5.000000      6.000000  \n",
       "75%       11.000000      6.000000      8.000000  \n",
       "max       13.000000      6.000000      8.000000  \n",
       "\n",
       "[8 rows x 22 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Describing the dataset\n",
    "diabetes.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting info about each feature type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 70692 entries, 0 to 70691\n",
      "Data columns (total 22 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   Diabetes_binary       70692 non-null  float64\n",
      " 1   HighBP                70692 non-null  float64\n",
      " 2   HighChol              70692 non-null  float64\n",
      " 3   CholCheck             70692 non-null  float64\n",
      " 4   BMI                   70692 non-null  float64\n",
      " 5   Smoker                70692 non-null  float64\n",
      " 6   Stroke                70692 non-null  float64\n",
      " 7   HeartDiseaseorAttack  70692 non-null  float64\n",
      " 8   PhysActivity          70692 non-null  float64\n",
      " 9   Fruits                70692 non-null  float64\n",
      " 10  Veggies               70692 non-null  float64\n",
      " 11  HvyAlcoholConsump     70692 non-null  float64\n",
      " 12  AnyHealthcare         70692 non-null  float64\n",
      " 13  NoDocbcCost           70692 non-null  float64\n",
      " 14  GenHlth               70692 non-null  float64\n",
      " 15  MentHlth              70692 non-null  float64\n",
      " 16  PhysHlth              70692 non-null  float64\n",
      " 17  DiffWalk              70692 non-null  float64\n",
      " 18  Sex                   70692 non-null  float64\n",
      " 19  Age                   70692 non-null  float64\n",
      " 20  Education             70692 non-null  float64\n",
      " 21  Income                70692 non-null  float64\n",
      "dtypes: float64(22)\n",
      "memory usage: 11.9 MB\n"
     ]
    }
   ],
   "source": [
    "# info about the dataset\n",
    "diabetes.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Preliminary Correlation Matrix of all the features in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes_binary</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>...</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Diabetes_binary</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.381516</td>\n",
       "      <td>0.289213</td>\n",
       "      <td>0.115382</td>\n",
       "      <td>0.293373</td>\n",
       "      <td>0.085999</td>\n",
       "      <td>0.125427</td>\n",
       "      <td>0.211523</td>\n",
       "      <td>-0.158666</td>\n",
       "      <td>-0.054077</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023191</td>\n",
       "      <td>0.040977</td>\n",
       "      <td>0.407612</td>\n",
       "      <td>0.087029</td>\n",
       "      <td>0.213081</td>\n",
       "      <td>0.272646</td>\n",
       "      <td>0.044413</td>\n",
       "      <td>0.278738</td>\n",
       "      <td>-0.170481</td>\n",
       "      <td>-0.224449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HighBP</th>\n",
       "      <td>0.381516</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.316515</td>\n",
       "      <td>0.103283</td>\n",
       "      <td>0.241019</td>\n",
       "      <td>0.087438</td>\n",
       "      <td>0.129060</td>\n",
       "      <td>0.210750</td>\n",
       "      <td>-0.136102</td>\n",
       "      <td>-0.040852</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035764</td>\n",
       "      <td>0.026517</td>\n",
       "      <td>0.320540</td>\n",
       "      <td>0.064294</td>\n",
       "      <td>0.173922</td>\n",
       "      <td>0.234784</td>\n",
       "      <td>0.040819</td>\n",
       "      <td>0.338132</td>\n",
       "      <td>-0.141643</td>\n",
       "      <td>-0.187657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HighChol</th>\n",
       "      <td>0.289213</td>\n",
       "      <td>0.316515</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.085981</td>\n",
       "      <td>0.131309</td>\n",
       "      <td>0.093398</td>\n",
       "      <td>0.099786</td>\n",
       "      <td>0.181187</td>\n",
       "      <td>-0.090453</td>\n",
       "      <td>-0.047384</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031532</td>\n",
       "      <td>0.033199</td>\n",
       "      <td>0.237778</td>\n",
       "      <td>0.083881</td>\n",
       "      <td>0.142610</td>\n",
       "      <td>0.162043</td>\n",
       "      <td>0.017324</td>\n",
       "      <td>0.240338</td>\n",
       "      <td>-0.084386</td>\n",
       "      <td>-0.107777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CholCheck</th>\n",
       "      <td>0.115382</td>\n",
       "      <td>0.103283</td>\n",
       "      <td>0.085981</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.045648</td>\n",
       "      <td>-0.004331</td>\n",
       "      <td>0.022529</td>\n",
       "      <td>0.043497</td>\n",
       "      <td>-0.008249</td>\n",
       "      <td>0.017384</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106800</td>\n",
       "      <td>-0.062669</td>\n",
       "      <td>0.059213</td>\n",
       "      <td>-0.010660</td>\n",
       "      <td>0.034540</td>\n",
       "      <td>0.044430</td>\n",
       "      <td>-0.007991</td>\n",
       "      <td>0.101743</td>\n",
       "      <td>-0.008695</td>\n",
       "      <td>0.007550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMI</th>\n",
       "      <td>0.293373</td>\n",
       "      <td>0.241019</td>\n",
       "      <td>0.131309</td>\n",
       "      <td>0.045648</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.011551</td>\n",
       "      <td>0.022931</td>\n",
       "      <td>0.060355</td>\n",
       "      <td>-0.170936</td>\n",
       "      <td>-0.084505</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013417</td>\n",
       "      <td>0.065832</td>\n",
       "      <td>0.267888</td>\n",
       "      <td>0.104682</td>\n",
       "      <td>0.161862</td>\n",
       "      <td>0.246094</td>\n",
       "      <td>0.000827</td>\n",
       "      <td>-0.038648</td>\n",
       "      <td>-0.100233</td>\n",
       "      <td>-0.124878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Smoker</th>\n",
       "      <td>0.085999</td>\n",
       "      <td>0.087438</td>\n",
       "      <td>0.093398</td>\n",
       "      <td>-0.004331</td>\n",
       "      <td>0.011551</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.064658</td>\n",
       "      <td>0.124418</td>\n",
       "      <td>-0.079823</td>\n",
       "      <td>-0.074811</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012939</td>\n",
       "      <td>0.035799</td>\n",
       "      <td>0.152416</td>\n",
       "      <td>0.091257</td>\n",
       "      <td>0.120698</td>\n",
       "      <td>0.119789</td>\n",
       "      <td>0.112125</td>\n",
       "      <td>0.105424</td>\n",
       "      <td>-0.140966</td>\n",
       "      <td>-0.104725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stroke</th>\n",
       "      <td>0.125427</td>\n",
       "      <td>0.129060</td>\n",
       "      <td>0.099786</td>\n",
       "      <td>0.022529</td>\n",
       "      <td>0.022931</td>\n",
       "      <td>0.064658</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.223394</td>\n",
       "      <td>-0.079985</td>\n",
       "      <td>-0.008996</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006484</td>\n",
       "      <td>0.036198</td>\n",
       "      <td>0.189447</td>\n",
       "      <td>0.087303</td>\n",
       "      <td>0.164488</td>\n",
       "      <td>0.192266</td>\n",
       "      <td>0.003822</td>\n",
       "      <td>0.123879</td>\n",
       "      <td>-0.073926</td>\n",
       "      <td>-0.136577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <td>0.211523</td>\n",
       "      <td>0.210750</td>\n",
       "      <td>0.181187</td>\n",
       "      <td>0.043497</td>\n",
       "      <td>0.060355</td>\n",
       "      <td>0.124418</td>\n",
       "      <td>0.223394</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.098223</td>\n",
       "      <td>-0.019436</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015687</td>\n",
       "      <td>0.036029</td>\n",
       "      <td>0.275868</td>\n",
       "      <td>0.075057</td>\n",
       "      <td>0.198416</td>\n",
       "      <td>0.232611</td>\n",
       "      <td>0.098161</td>\n",
       "      <td>0.221878</td>\n",
       "      <td>-0.096559</td>\n",
       "      <td>-0.146748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhysActivity</th>\n",
       "      <td>-0.158666</td>\n",
       "      <td>-0.136102</td>\n",
       "      <td>-0.090453</td>\n",
       "      <td>-0.008249</td>\n",
       "      <td>-0.170936</td>\n",
       "      <td>-0.079823</td>\n",
       "      <td>-0.079985</td>\n",
       "      <td>-0.098223</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.133813</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027089</td>\n",
       "      <td>-0.063302</td>\n",
       "      <td>-0.273548</td>\n",
       "      <td>-0.130090</td>\n",
       "      <td>-0.234500</td>\n",
       "      <td>-0.276868</td>\n",
       "      <td>0.051753</td>\n",
       "      <td>-0.100753</td>\n",
       "      <td>0.190271</td>\n",
       "      <td>0.196551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fruits</th>\n",
       "      <td>-0.054077</td>\n",
       "      <td>-0.040852</td>\n",
       "      <td>-0.047384</td>\n",
       "      <td>0.017384</td>\n",
       "      <td>-0.084505</td>\n",
       "      <td>-0.074811</td>\n",
       "      <td>-0.008996</td>\n",
       "      <td>-0.019436</td>\n",
       "      <td>0.133813</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029385</td>\n",
       "      <td>-0.045843</td>\n",
       "      <td>-0.098687</td>\n",
       "      <td>-0.062102</td>\n",
       "      <td>-0.048572</td>\n",
       "      <td>-0.050784</td>\n",
       "      <td>-0.088723</td>\n",
       "      <td>0.061096</td>\n",
       "      <td>0.098715</td>\n",
       "      <td>0.079009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Veggies</th>\n",
       "      <td>-0.079293</td>\n",
       "      <td>-0.066624</td>\n",
       "      <td>-0.042836</td>\n",
       "      <td>0.000349</td>\n",
       "      <td>-0.056528</td>\n",
       "      <td>-0.029926</td>\n",
       "      <td>-0.047601</td>\n",
       "      <td>-0.036315</td>\n",
       "      <td>0.149322</td>\n",
       "      <td>0.238605</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029152</td>\n",
       "      <td>-0.037146</td>\n",
       "      <td>-0.115795</td>\n",
       "      <td>-0.052359</td>\n",
       "      <td>-0.066896</td>\n",
       "      <td>-0.084072</td>\n",
       "      <td>-0.052604</td>\n",
       "      <td>-0.018893</td>\n",
       "      <td>0.152512</td>\n",
       "      <td>0.154899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HvyAlcoholConsump</th>\n",
       "      <td>-0.094853</td>\n",
       "      <td>-0.027030</td>\n",
       "      <td>-0.025443</td>\n",
       "      <td>-0.027146</td>\n",
       "      <td>-0.058232</td>\n",
       "      <td>0.077835</td>\n",
       "      <td>-0.023395</td>\n",
       "      <td>-0.037130</td>\n",
       "      <td>0.019111</td>\n",
       "      <td>-0.033246</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013484</td>\n",
       "      <td>0.009683</td>\n",
       "      <td>-0.058796</td>\n",
       "      <td>0.015626</td>\n",
       "      <td>-0.036257</td>\n",
       "      <td>-0.049294</td>\n",
       "      <td>0.014164</td>\n",
       "      <td>-0.057705</td>\n",
       "      <td>0.036279</td>\n",
       "      <td>0.064095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <td>0.023191</td>\n",
       "      <td>0.035764</td>\n",
       "      <td>0.031532</td>\n",
       "      <td>0.106800</td>\n",
       "      <td>-0.013417</td>\n",
       "      <td>-0.012939</td>\n",
       "      <td>0.006484</td>\n",
       "      <td>0.015687</td>\n",
       "      <td>0.027089</td>\n",
       "      <td>0.029385</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.221658</td>\n",
       "      <td>-0.033060</td>\n",
       "      <td>-0.049850</td>\n",
       "      <td>-0.003285</td>\n",
       "      <td>0.008113</td>\n",
       "      <td>-0.006562</td>\n",
       "      <td>0.136975</td>\n",
       "      <td>0.106601</td>\n",
       "      <td>0.130492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <td>0.040977</td>\n",
       "      <td>0.026517</td>\n",
       "      <td>0.033199</td>\n",
       "      <td>-0.062669</td>\n",
       "      <td>0.065832</td>\n",
       "      <td>0.035799</td>\n",
       "      <td>0.036198</td>\n",
       "      <td>0.036029</td>\n",
       "      <td>-0.063302</td>\n",
       "      <td>-0.045843</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.221658</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.169515</td>\n",
       "      <td>0.193877</td>\n",
       "      <td>0.157451</td>\n",
       "      <td>0.127111</td>\n",
       "      <td>-0.048187</td>\n",
       "      <td>-0.129839</td>\n",
       "      <td>-0.096989</td>\n",
       "      <td>-0.198171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GenHlth</th>\n",
       "      <td>0.407612</td>\n",
       "      <td>0.320540</td>\n",
       "      <td>0.237778</td>\n",
       "      <td>0.059213</td>\n",
       "      <td>0.267888</td>\n",
       "      <td>0.152416</td>\n",
       "      <td>0.189447</td>\n",
       "      <td>0.275868</td>\n",
       "      <td>-0.273548</td>\n",
       "      <td>-0.098687</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033060</td>\n",
       "      <td>0.169515</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.315077</td>\n",
       "      <td>0.552757</td>\n",
       "      <td>0.476639</td>\n",
       "      <td>-0.014555</td>\n",
       "      <td>0.155624</td>\n",
       "      <td>-0.285420</td>\n",
       "      <td>-0.382969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MentHlth</th>\n",
       "      <td>0.087029</td>\n",
       "      <td>0.064294</td>\n",
       "      <td>0.083881</td>\n",
       "      <td>-0.010660</td>\n",
       "      <td>0.104682</td>\n",
       "      <td>0.091257</td>\n",
       "      <td>0.087303</td>\n",
       "      <td>0.075057</td>\n",
       "      <td>-0.130090</td>\n",
       "      <td>-0.062102</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.049850</td>\n",
       "      <td>0.193877</td>\n",
       "      <td>0.315077</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.380272</td>\n",
       "      <td>0.251489</td>\n",
       "      <td>-0.089204</td>\n",
       "      <td>-0.101746</td>\n",
       "      <td>-0.107005</td>\n",
       "      <td>-0.219070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhysHlth</th>\n",
       "      <td>0.213081</td>\n",
       "      <td>0.173922</td>\n",
       "      <td>0.142610</td>\n",
       "      <td>0.034540</td>\n",
       "      <td>0.161862</td>\n",
       "      <td>0.120698</td>\n",
       "      <td>0.164488</td>\n",
       "      <td>0.198416</td>\n",
       "      <td>-0.234500</td>\n",
       "      <td>-0.048572</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003285</td>\n",
       "      <td>0.157451</td>\n",
       "      <td>0.552757</td>\n",
       "      <td>0.380272</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.487976</td>\n",
       "      <td>-0.045957</td>\n",
       "      <td>0.084852</td>\n",
       "      <td>-0.159317</td>\n",
       "      <td>-0.279326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DiffWalk</th>\n",
       "      <td>0.272646</td>\n",
       "      <td>0.234784</td>\n",
       "      <td>0.162043</td>\n",
       "      <td>0.044430</td>\n",
       "      <td>0.246094</td>\n",
       "      <td>0.119789</td>\n",
       "      <td>0.192266</td>\n",
       "      <td>0.232611</td>\n",
       "      <td>-0.276868</td>\n",
       "      <td>-0.050784</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008113</td>\n",
       "      <td>0.127111</td>\n",
       "      <td>0.476639</td>\n",
       "      <td>0.251489</td>\n",
       "      <td>0.487976</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.082248</td>\n",
       "      <td>0.195265</td>\n",
       "      <td>-0.202590</td>\n",
       "      <td>-0.343245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>0.044413</td>\n",
       "      <td>0.040819</td>\n",
       "      <td>0.017324</td>\n",
       "      <td>-0.007991</td>\n",
       "      <td>0.000827</td>\n",
       "      <td>0.112125</td>\n",
       "      <td>0.003822</td>\n",
       "      <td>0.098161</td>\n",
       "      <td>0.051753</td>\n",
       "      <td>-0.088723</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006562</td>\n",
       "      <td>-0.048187</td>\n",
       "      <td>-0.014555</td>\n",
       "      <td>-0.089204</td>\n",
       "      <td>-0.045957</td>\n",
       "      <td>-0.082248</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.002315</td>\n",
       "      <td>0.043564</td>\n",
       "      <td>0.159654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0.278738</td>\n",
       "      <td>0.338132</td>\n",
       "      <td>0.240338</td>\n",
       "      <td>0.101743</td>\n",
       "      <td>-0.038648</td>\n",
       "      <td>0.105424</td>\n",
       "      <td>0.123879</td>\n",
       "      <td>0.221878</td>\n",
       "      <td>-0.100753</td>\n",
       "      <td>0.061096</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136975</td>\n",
       "      <td>-0.129839</td>\n",
       "      <td>0.155624</td>\n",
       "      <td>-0.101746</td>\n",
       "      <td>0.084852</td>\n",
       "      <td>0.195265</td>\n",
       "      <td>-0.002315</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.107127</td>\n",
       "      <td>-0.130140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Education</th>\n",
       "      <td>-0.170481</td>\n",
       "      <td>-0.141643</td>\n",
       "      <td>-0.084386</td>\n",
       "      <td>-0.008695</td>\n",
       "      <td>-0.100233</td>\n",
       "      <td>-0.140966</td>\n",
       "      <td>-0.073926</td>\n",
       "      <td>-0.096559</td>\n",
       "      <td>0.190271</td>\n",
       "      <td>0.098715</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106601</td>\n",
       "      <td>-0.096989</td>\n",
       "      <td>-0.285420</td>\n",
       "      <td>-0.107005</td>\n",
       "      <td>-0.159317</td>\n",
       "      <td>-0.202590</td>\n",
       "      <td>0.043564</td>\n",
       "      <td>-0.107127</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.460565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Income</th>\n",
       "      <td>-0.224449</td>\n",
       "      <td>-0.187657</td>\n",
       "      <td>-0.107777</td>\n",
       "      <td>0.007550</td>\n",
       "      <td>-0.124878</td>\n",
       "      <td>-0.104725</td>\n",
       "      <td>-0.136577</td>\n",
       "      <td>-0.146748</td>\n",
       "      <td>0.196551</td>\n",
       "      <td>0.079009</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130492</td>\n",
       "      <td>-0.198171</td>\n",
       "      <td>-0.382969</td>\n",
       "      <td>-0.219070</td>\n",
       "      <td>-0.279326</td>\n",
       "      <td>-0.343245</td>\n",
       "      <td>0.159654</td>\n",
       "      <td>-0.130140</td>\n",
       "      <td>0.460565</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Diabetes_binary    HighBP  HighChol  CholCheck  \\\n",
       "Diabetes_binary              1.000000  0.381516  0.289213   0.115382   \n",
       "HighBP                       0.381516  1.000000  0.316515   0.103283   \n",
       "HighChol                     0.289213  0.316515  1.000000   0.085981   \n",
       "CholCheck                    0.115382  0.103283  0.085981   1.000000   \n",
       "BMI                          0.293373  0.241019  0.131309   0.045648   \n",
       "Smoker                       0.085999  0.087438  0.093398  -0.004331   \n",
       "Stroke                       0.125427  0.129060  0.099786   0.022529   \n",
       "HeartDiseaseorAttack         0.211523  0.210750  0.181187   0.043497   \n",
       "PhysActivity                -0.158666 -0.136102 -0.090453  -0.008249   \n",
       "Fruits                      -0.054077 -0.040852 -0.047384   0.017384   \n",
       "Veggies                     -0.079293 -0.066624 -0.042836   0.000349   \n",
       "HvyAlcoholConsump           -0.094853 -0.027030 -0.025443  -0.027146   \n",
       "AnyHealthcare                0.023191  0.035764  0.031532   0.106800   \n",
       "NoDocbcCost                  0.040977  0.026517  0.033199  -0.062669   \n",
       "GenHlth                      0.407612  0.320540  0.237778   0.059213   \n",
       "MentHlth                     0.087029  0.064294  0.083881  -0.010660   \n",
       "PhysHlth                     0.213081  0.173922  0.142610   0.034540   \n",
       "DiffWalk                     0.272646  0.234784  0.162043   0.044430   \n",
       "Sex                          0.044413  0.040819  0.017324  -0.007991   \n",
       "Age                          0.278738  0.338132  0.240338   0.101743   \n",
       "Education                   -0.170481 -0.141643 -0.084386  -0.008695   \n",
       "Income                      -0.224449 -0.187657 -0.107777   0.007550   \n",
       "\n",
       "                           BMI    Smoker    Stroke  HeartDiseaseorAttack  \\\n",
       "Diabetes_binary       0.293373  0.085999  0.125427              0.211523   \n",
       "HighBP                0.241019  0.087438  0.129060              0.210750   \n",
       "HighChol              0.131309  0.093398  0.099786              0.181187   \n",
       "CholCheck             0.045648 -0.004331  0.022529              0.043497   \n",
       "BMI                   1.000000  0.011551  0.022931              0.060355   \n",
       "Smoker                0.011551  1.000000  0.064658              0.124418   \n",
       "Stroke                0.022931  0.064658  1.000000              0.223394   \n",
       "HeartDiseaseorAttack  0.060355  0.124418  0.223394              1.000000   \n",
       "PhysActivity         -0.170936 -0.079823 -0.079985             -0.098223   \n",
       "Fruits               -0.084505 -0.074811 -0.008996             -0.019436   \n",
       "Veggies              -0.056528 -0.029926 -0.047601             -0.036315   \n",
       "HvyAlcoholConsump    -0.058232  0.077835 -0.023395             -0.037130   \n",
       "AnyHealthcare        -0.013417 -0.012939  0.006484              0.015687   \n",
       "NoDocbcCost           0.065832  0.035799  0.036198              0.036029   \n",
       "GenHlth               0.267888  0.152416  0.189447              0.275868   \n",
       "MentHlth              0.104682  0.091257  0.087303              0.075057   \n",
       "PhysHlth              0.161862  0.120698  0.164488              0.198416   \n",
       "DiffWalk              0.246094  0.119789  0.192266              0.232611   \n",
       "Sex                   0.000827  0.112125  0.003822              0.098161   \n",
       "Age                  -0.038648  0.105424  0.123879              0.221878   \n",
       "Education            -0.100233 -0.140966 -0.073926             -0.096559   \n",
       "Income               -0.124878 -0.104725 -0.136577             -0.146748   \n",
       "\n",
       "                      PhysActivity    Fruits  ...  AnyHealthcare  NoDocbcCost  \\\n",
       "Diabetes_binary          -0.158666 -0.054077  ...       0.023191     0.040977   \n",
       "HighBP                   -0.136102 -0.040852  ...       0.035764     0.026517   \n",
       "HighChol                 -0.090453 -0.047384  ...       0.031532     0.033199   \n",
       "CholCheck                -0.008249  0.017384  ...       0.106800    -0.062669   \n",
       "BMI                      -0.170936 -0.084505  ...      -0.013417     0.065832   \n",
       "Smoker                   -0.079823 -0.074811  ...      -0.012939     0.035799   \n",
       "Stroke                   -0.079985 -0.008996  ...       0.006484     0.036198   \n",
       "HeartDiseaseorAttack     -0.098223 -0.019436  ...       0.015687     0.036029   \n",
       "PhysActivity              1.000000  0.133813  ...       0.027089    -0.063302   \n",
       "Fruits                    0.133813  1.000000  ...       0.029385    -0.045843   \n",
       "Veggies                   0.149322  0.238605  ...       0.029152    -0.037146   \n",
       "HvyAlcoholConsump         0.019111 -0.033246  ...      -0.013484     0.009683   \n",
       "AnyHealthcare             0.027089  0.029385  ...       1.000000    -0.221658   \n",
       "NoDocbcCost              -0.063302 -0.045843  ...      -0.221658     1.000000   \n",
       "GenHlth                  -0.273548 -0.098687  ...      -0.033060     0.169515   \n",
       "MentHlth                 -0.130090 -0.062102  ...      -0.049850     0.193877   \n",
       "PhysHlth                 -0.234500 -0.048572  ...      -0.003285     0.157451   \n",
       "DiffWalk                 -0.276868 -0.050784  ...       0.008113     0.127111   \n",
       "Sex                       0.051753 -0.088723  ...      -0.006562    -0.048187   \n",
       "Age                      -0.100753  0.061096  ...       0.136975    -0.129839   \n",
       "Education                 0.190271  0.098715  ...       0.106601    -0.096989   \n",
       "Income                    0.196551  0.079009  ...       0.130492    -0.198171   \n",
       "\n",
       "                       GenHlth  MentHlth  PhysHlth  DiffWalk       Sex  \\\n",
       "Diabetes_binary       0.407612  0.087029  0.213081  0.272646  0.044413   \n",
       "HighBP                0.320540  0.064294  0.173922  0.234784  0.040819   \n",
       "HighChol              0.237778  0.083881  0.142610  0.162043  0.017324   \n",
       "CholCheck             0.059213 -0.010660  0.034540  0.044430 -0.007991   \n",
       "BMI                   0.267888  0.104682  0.161862  0.246094  0.000827   \n",
       "Smoker                0.152416  0.091257  0.120698  0.119789  0.112125   \n",
       "Stroke                0.189447  0.087303  0.164488  0.192266  0.003822   \n",
       "HeartDiseaseorAttack  0.275868  0.075057  0.198416  0.232611  0.098161   \n",
       "PhysActivity         -0.273548 -0.130090 -0.234500 -0.276868  0.051753   \n",
       "Fruits               -0.098687 -0.062102 -0.048572 -0.050784 -0.088723   \n",
       "Veggies              -0.115795 -0.052359 -0.066896 -0.084072 -0.052604   \n",
       "HvyAlcoholConsump    -0.058796  0.015626 -0.036257 -0.049294  0.014164   \n",
       "AnyHealthcare        -0.033060 -0.049850 -0.003285  0.008113 -0.006562   \n",
       "NoDocbcCost           0.169515  0.193877  0.157451  0.127111 -0.048187   \n",
       "GenHlth               1.000000  0.315077  0.552757  0.476639 -0.014555   \n",
       "MentHlth              0.315077  1.000000  0.380272  0.251489 -0.089204   \n",
       "PhysHlth              0.552757  0.380272  1.000000  0.487976 -0.045957   \n",
       "DiffWalk              0.476639  0.251489  0.487976  1.000000 -0.082248   \n",
       "Sex                  -0.014555 -0.089204 -0.045957 -0.082248  1.000000   \n",
       "Age                   0.155624 -0.101746  0.084852  0.195265 -0.002315   \n",
       "Education            -0.285420 -0.107005 -0.159317 -0.202590  0.043564   \n",
       "Income               -0.382969 -0.219070 -0.279326 -0.343245  0.159654   \n",
       "\n",
       "                           Age  Education    Income  \n",
       "Diabetes_binary       0.278738  -0.170481 -0.224449  \n",
       "HighBP                0.338132  -0.141643 -0.187657  \n",
       "HighChol              0.240338  -0.084386 -0.107777  \n",
       "CholCheck             0.101743  -0.008695  0.007550  \n",
       "BMI                  -0.038648  -0.100233 -0.124878  \n",
       "Smoker                0.105424  -0.140966 -0.104725  \n",
       "Stroke                0.123879  -0.073926 -0.136577  \n",
       "HeartDiseaseorAttack  0.221878  -0.096559 -0.146748  \n",
       "PhysActivity         -0.100753   0.190271  0.196551  \n",
       "Fruits                0.061096   0.098715  0.079009  \n",
       "Veggies              -0.018893   0.152512  0.154899  \n",
       "HvyAlcoholConsump    -0.057705   0.036279  0.064095  \n",
       "AnyHealthcare         0.136975   0.106601  0.130492  \n",
       "NoDocbcCost          -0.129839  -0.096989 -0.198171  \n",
       "GenHlth               0.155624  -0.285420 -0.382969  \n",
       "MentHlth             -0.101746  -0.107005 -0.219070  \n",
       "PhysHlth              0.084852  -0.159317 -0.279326  \n",
       "DiffWalk              0.195265  -0.202590 -0.343245  \n",
       "Sex                  -0.002315   0.043564  0.159654  \n",
       "Age                   1.000000  -0.107127 -0.130140  \n",
       "Education            -0.107127   1.000000  0.460565  \n",
       "Income               -0.130140   0.460565  1.000000  \n",
       "\n",
       "[22 rows x 22 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above, we see that some columns have very low correlations to the target column, **Diabetes_binary**. In particular, the *'Smoker'*, *'Sex'*, *'Fruits'*, *'Veggies'*, *'NoDocbcCost'*, *'MentHlth'*, *'AnyHealthcare'*, and *'HvyAlcoholConsump'* fields had low correlations, so we can assume that they will not add any benefit to our models and will only serve to lower the accuracy. So we decided to take these fields out in our final analysis. \n",
    "\n",
    "To give some background, we initially had decided to remove features that either relied heavily on subjective answers or weren't as important to defining if someone had diabetes. These fields were *'NoDocbcCost'*, *'GenHlth'*, *'MentHlth'*, *'PhysHlth'*, *'DiffWalk'*, *'AnyHealthcare'*, *'HvyAlcoholConsump'*. In the following code, comments will be indicated for our initial development, and can be commented out for different results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes_binary</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Diabetes_binary  HighBP  HighChol  CholCheck   BMI  Stroke  \\\n",
       "0              0.0     1.0       0.0        1.0  26.0     0.0   \n",
       "1              0.0     1.0       1.0        1.0  26.0     1.0   \n",
       "2              0.0     0.0       0.0        1.0  26.0     0.0   \n",
       "3              0.0     1.0       1.0        1.0  28.0     0.0   \n",
       "4              0.0     0.0       0.0        1.0  29.0     0.0   \n",
       "\n",
       "   HeartDiseaseorAttack  PhysActivity  GenHlth  PhysHlth  DiffWalk   Age  \\\n",
       "0                   0.0           1.0      3.0      30.0       0.0   4.0   \n",
       "1                   0.0           0.0      3.0       0.0       0.0  12.0   \n",
       "2                   0.0           1.0      1.0      10.0       0.0  13.0   \n",
       "3                   0.0           1.0      3.0       3.0       0.0  11.0   \n",
       "4                   0.0           1.0      2.0       0.0       0.0   8.0   \n",
       "\n",
       "   Education  Income  \n",
       "0        6.0     8.0  \n",
       "1        6.0     8.0  \n",
       "2        6.0     8.0  \n",
       "3        6.0     8.0  \n",
       "4        5.0     8.0  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping columns that may not be helpful for analysis, heavy alcohol consumption removed since because it is self reported it may not be as honest\n",
    "\n",
    "### INIT DEV\n",
    "#columns_to_drop = ['NoDocbcCost', 'GenHlth', 'MentHlth', 'PhysHlth', 'DiffWalk', 'AnyHealthcare', 'HvyAlcoholConsump']\n",
    "columns_to_drop = ['Smoker', 'Sex', 'Fruits', 'Veggies', 'NoDocbcCost', 'MentHlth', 'AnyHealthcare', 'HvyAlcoholConsump']\n",
    "diabetes_df = diabetes.copy()\n",
    "\n",
    "# Notating our final DF used for the models \n",
    "diabetes_df_final = diabetes.copy()\n",
    "\n",
    "# dropping the columns to drop\n",
    "diabetes_df = diabetes_df.drop(columns=columns_to_drop)\n",
    "diabetes_df_final = diabetes_df_final.drop(columns=columns_to_drop)\n",
    "diabetes_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking if the dataset is balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Diabetes_binary\n",
       "0.0    35346\n",
       "1.0    35346\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_df['Diabetes_binary'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is expected as the dataset we found was balanced already with an even split ration between 0 for 'no diabetes' and 1 for 'prediabetic or diabetic'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Grouping (using functions)\n",
    "\n",
    "We wanted to reduce the amount of groups for the following fields, since they had a few too many groups:\n",
    "1. Age\n",
    "2. Education\n",
    "3. Income\n",
    "4. BMI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age Category Recap:\n",
    "1. Age 18 to 24\n",
    "2. Age 25 to 29\n",
    "3. Age 30 to 34\n",
    "4. Age 35 to 39\n",
    "5. Age 40 to 44\n",
    "6. Age 45 to 49\n",
    "7. Age 50 to 54\n",
    "8. Age 55 to 59\n",
    "9. Age 60 to 64\n",
    "10. Age 65 to 69\n",
    "11. Age 70 to 74\n",
    "12. Age 75 to 79\n",
    "13. Age 80 or older\n",
    "\n",
    "We initially sought to categorize the ages to a smaller subset and group them within 5 groups since we wanted to keep the groups equal. In particular our groupings would have gone as follows:\n",
    "1. 18-34 (Grouping 1-3)\n",
    "2. 35-49 (Grouping 4-6)\n",
    "3. 50-64 (Grouping 7-9)\n",
    "4. 65-79 (Grouping 10-12)\n",
    "5. 80+ (Group 13 by itself)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age\n",
       "10.0    10856\n",
       "9.0     10112\n",
       "8.0      8603\n",
       "11.0     8044\n",
       "7.0      6872\n",
       "13.0     5426\n",
       "12.0     5394\n",
       "6.0      4648\n",
       "5.0      3520\n",
       "4.0      2793\n",
       "3.0      2049\n",
       "2.0      1396\n",
       "1.0       979\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_df['Age'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The age groups that were most represented were between the ages of 60-69"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to replace the existing data with our own age groupings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_replace(x):\n",
    "    if x >= 1 and x <= 3:\n",
    "        return \"Age 18-34\"\n",
    "    elif x > 3 and x <= 6:\n",
    "        return \"Age 35-49\"\n",
    "    elif x > 6 and x <= 9:\n",
    "        return \"Age 50-64\"\n",
    "    elif x > 9 and x <= 12:\n",
    "        return \"Age 65-79\"\n",
    "    elif x > 12:\n",
    "        return \"Age 80+\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age\n",
       "Age 50-64    25587\n",
       "Age 65-79    24294\n",
       "Age 35-49    10961\n",
       "Age 80+       5426\n",
       "Age 18-34     4424\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Go through the dataframe and replace the current age grouping with our smaller grouping\n",
    "diabetes_df['Age'] = diabetes_df['Age'].apply(age_replace)\n",
    "diabetes_df['Age'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. EDUCATION\n",
    "\n",
    "#### Education Category Recap \n",
    "1. Never attended school or only kindergarten\n",
    "2. Grades 1 through 8 (Elementary)\n",
    "3. Grades 9 through 11 (Some high school)\n",
    "4. Grade 12 or GED (High school graduate)\n",
    "5. College 1 year to 3 years (Some college or technical school)\n",
    "6. College 4 years or more (College graduate)\n",
    "\n",
    "We decided to split this category into two, one with lower education encapsulating groups 1-5, and higher education containing group 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Education\n",
       "6.0    26020\n",
       "5.0    20030\n",
       "4.0    19473\n",
       "3.0     3447\n",
       "2.0     1647\n",
       "1.0       75\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_df['Education'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to replace the existing data with our own education groupings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edu_replace(x):\n",
    "    if x >= 1 and x <= 4:\n",
    "        return \"Lower Education\"\n",
    "    elif x > 4:\n",
    "        return \"Higher Education\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Education\n",
       "Higher Education    46050\n",
       "Lower Education     24642\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Go through the dataframe and replace the current education grouping with our smaller grouping\n",
    "diabetes_df['Education'] = diabetes_df['Education'].apply(edu_replace)\n",
    "diabetes_df['Education'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. INCOME\n",
    "#### Income Category Recap:\n",
    "\n",
    "1. Less than $10,000\n",
    "2. Less than $15,000 ($10,000 to less than $15,000)\n",
    "3. Less than $20,000 ($15,000 to less than $20,000)\n",
    "4. Less than $25,000 ($20,000 to less than $25,000)\n",
    "5. Less than $35,000 ($25,000 to less than $35,000)\n",
    "6. Less than $50,000 ($35,000 to less than $50,000)\n",
    "7. Less than $75,000 ($50,000 to less than $75,000)\n",
    "8. $75,000 or more\n",
    "\n",
    "We tried to group the income levels based on broader groups based on lower, middle, and upper class incomes for individuals. We grouped 1-3 together as \"Less than $20,000\", 4-7 together as \"Between $20,000 and $75,000\", and 8 by itself as \"More than $75,000.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Income\n",
       "8.0    20646\n",
       "7.0    11425\n",
       "6.0    10287\n",
       "5.0     8010\n",
       "4.0     6658\n",
       "3.0     5557\n",
       "2.0     4498\n",
       "1.0     3611\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_df['Income'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to replace the existing data with our own income groupings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def income_replace(x):\n",
    "    if x >= 1 and x <= 3:\n",
    "        return \"Less than $20,000\"\n",
    "    elif x > 3 and x <= 7:\n",
    "        return \"Between $20,000 and $75,000\"\n",
    "    elif x > 7:\n",
    "        return \"More than $75,000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Income\n",
       "Between $20,000 and $75,000    36380\n",
       "More than $75,000              20646\n",
       "Less than $20,000              13666\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Go through the dataframe and replace the current income grouping with our smaller grouping\n",
    "diabetes_df['Income'] = diabetes_df['Income'].apply(income_replace)\n",
    "diabetes_df['Income'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. BMI\n",
    "\n",
    "For this feature, we wanted to group the BMI's based on their scientific classifications of **'Underweight'**, **'Normal'**, **'Overweight'**, **'Obesity 1'**, **'Obesity 2'**, and **'Obesity 3'**. We will then encode these down the line. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to replace the existing data with BMI groupings instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BMI_classification(x):\n",
    "    if x < 18.5:\n",
    "        return \"Underweight\"\n",
    "    elif x > 18.5 and x <=24.9:\n",
    "        return \"Normal\"\n",
    "    elif x > 24.9 and x <= 29.9:\n",
    "        return \"Overweight\"\n",
    "    elif x > 29.9 and x <= 34.9:\n",
    "        return \"Obesity 1\"\n",
    "    elif x > 34.9 and x <= 39.9:\n",
    "        return \"Obesity 2\"\n",
    "    elif x > 39.9:\n",
    "        return \"Obesity 3\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go through the dataframe and replace the current BMIs with our grouping\n",
    "diabetes_df['BMI'] = diabetes_df['BMI'].apply(BMI_classification)\n",
    "diabetes_df['BMI'].value_counts()\n",
    "\n",
    "# This is with our final dataframe that we use for our models\n",
    "diabetes_df_final['BMI'] = diabetes_df_final['BMI'].apply(BMI_classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin Analysis and Cleaning of Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Begin Splitting the Data to prepare for cleaning between train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our X variable is all the columns except the categorical variable\n",
    "# This is our initial X, notated as X_init    \n",
    "X_init = diabetes_df.drop(columns='Diabetes_binary')\n",
    "\n",
    "# This is the final X we used for all our models\n",
    "X = diabetes_df_final.drop(columns='Diabetes_binary')\n",
    "\n",
    "# Our y variable, the target, is the Diabetes_binary variable. This is what our machine learning model will try to create predictions for. \n",
    "# This is our initial y, notated as y_init\n",
    "y_init = diabetes_df['Diabetes_binary']\n",
    "\n",
    "# This is the final y we used for all our models\n",
    "y = diabetes_df_final['Diabetes_binary']\n",
    "\n",
    "# Split the train and test splits\n",
    "# Init\n",
    "x_train_init, x_test_init, y_train_init, y_test_init = train_test_split(X_init, y_init, random_state=12)\n",
    "\n",
    "# Final\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, random_state=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding Categorical Features\n",
    "\n",
    "The features we decided to encode were:\n",
    "\n",
    "1. BMI\n",
    "2. Income \n",
    "3. Education\n",
    "4. Age\n",
    "\n",
    "For our final analysis, we only kept our BMI encoding, and used the initial groupings presented from the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Encoding BMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   BMI\n",
       "0  4.0\n",
       "1  3.0\n",
       "2  3.0\n",
       "3  5.0\n",
       "4  3.0"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create encoder and fit to the BMI categories we created\n",
    "# We used an ordinal category since they were categorical, going from low BMI to high BMI and ordered\n",
    "encode_BMI = OrdinalEncoder(categories=[['Underweight', 'Normal', 'Overweight', 'Obesity 1', 'Obesity 2', 'Obesity 3']], handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "\n",
    "# fit the encoder to the BMI training data\n",
    "encode_BMI.fit(x_train['BMI'].values.reshape(-1,1))\n",
    "\n",
    "# transform the encoder onto both the training and testing BMI field\n",
    "encode_BMI_train = encode_BMI.transform(x_train['BMI'].values.reshape(-1, 1))\n",
    "encode_BMI_test = encode_BMI.transform(x_test['BMI'].values.reshape(-1, 1))\n",
    "\n",
    "# create the dfs that has the newly encoded data\n",
    "encode_BMI_df_train = pd.DataFrame(encode_BMI_train, columns=['BMI'])\n",
    "encode_BMI_df_test = pd.DataFrame(encode_BMI_test, columns=['BMI'])\n",
    "\n",
    "# display the new BMI column\n",
    "encode_BMI_df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Income\n",
    "(Note, for our final analysis we reverted to using the original groupings, but we have our original code for encoding the field displayed below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Income\n",
       "0     0.0\n",
       "1     1.0\n",
       "2     2.0\n",
       "3     1.0\n",
       "4     1.0"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create encoder and fit\n",
    "# We used an ordinal category since they were categorical, going from low income to high income and ordered\n",
    "encode_income = OrdinalEncoder(categories=[['Less than $20,000','Between $20,000 and $75,000','More than $75,000']], handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "\n",
    "# fit the encoder to the income training data\n",
    "encode_income.fit(x_train_init['Income'].values.reshape(-1,1))\n",
    "\n",
    "# transform the encoder onto both the training and testing income field\n",
    "encode_income_train = encode_income.transform(x_train_init['Income'].values.reshape(-1, 1))\n",
    "encode_income_test = encode_income.transform(x_test_init['Income'].values.reshape(-1, 1))\n",
    "\n",
    "# create the dfs that has the newly encoded data\n",
    "encode_income_df_train = pd.DataFrame(encode_income_train, columns=['Income'])\n",
    "encode_income_df_test = pd.DataFrame(encode_income_test, columns=['Income'])\n",
    "\n",
    "# display the new income column\n",
    "encode_income_df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Education\n",
    "(Note, for our final analysis we reverted to using the original groupings, but we have our original code for encoding the field displayed below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Education</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Education\n",
       "0        0.0\n",
       "1        1.0\n",
       "2        1.0\n",
       "3        0.0\n",
       "4        0.0"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create encoder and fit \n",
    "# We used an ordinal category since they were categorical, 1 denoting lower education, and 2 denoting higher education. So since it was ordered, we used an ordinal encoder\n",
    "encode_educ = OrdinalEncoder(categories=[['Lower Education', 'Higher Education']], handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "\n",
    "# fit the encoder to the education training data\n",
    "encode_educ.fit(x_train_init['Education'].values.reshape(-1,1))\n",
    "\n",
    "# transform the encoder onto both the training and testing education field\n",
    "encode_educ_train = encode_educ.transform(x_train_init['Education'].values.reshape(-1, 1))\n",
    "encode_educ_test = encode_educ.transform(x_test_init['Education'].values.reshape(-1, 1))\n",
    "\n",
    "# create the dfs that has the newly encoded data\n",
    "encode_educ_df_train = pd.DataFrame(encode_educ_train, columns=['Education'])\n",
    "encode_educ_df_test = pd.DataFrame(encode_educ_test, columns=['Education'])\n",
    "\n",
    "# display the new education column\n",
    "encode_educ_df_train.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Age\n",
    "(Note, for our final analysis we reverted to using the original groupings, but we have our original code for encoding the field displayed below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age\n",
       "0  3.0\n",
       "1  3.0\n",
       "2  2.0\n",
       "3  1.0\n",
       "4  4.0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create encoder and fit \n",
    "# We used an ordinal category since they were categorical, as the ages were ordered from lowest to highest, so we used an ordinal encoder\n",
    "encode_age = OrdinalEncoder(categories=[['Age 18-34', 'Age 35-49', 'Age 50-64', 'Age 65-79', 'Age 80+']], handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "\n",
    "# fit the encoder to the age training data\n",
    "encode_age.fit(x_train_init['Age'].values.reshape(-1,1))\n",
    "\n",
    "# transform the encoder onto both the training and testing age field\n",
    "encode_age_train = encode_age.transform(x_train_init['Age'].values.reshape(-1, 1))\n",
    "encode_age_test = encode_age.transform(x_test_init['Age'].values.reshape(-1, 1))\n",
    "\n",
    "# create the dfs that has the newly encoded data\n",
    "encode_age_df_train = pd.DataFrame(encode_age_train, columns=['Age'])\n",
    "encode_age_df_test = pd.DataFrame(encode_age_test, columns=['Age'])\n",
    "\n",
    "# display the new education column\n",
    "encode_age_df_train.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally, group all encoded columns with the main dataframe to begin creating models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HighBP                  0\n",
       "HighChol                0\n",
       "CholCheck               0\n",
       "Stroke                  0\n",
       "HeartDiseaseorAttack    0\n",
       "PhysActivity            0\n",
       "GenHlth                 0\n",
       "PhysHlth                0\n",
       "DiffWalk                0\n",
       "Age                     0\n",
       "Education               0\n",
       "Income                  0\n",
       "BMI                     0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "HighBP                  0\n",
       "HighChol                0\n",
       "CholCheck               0\n",
       "Stroke                  0\n",
       "HeartDiseaseorAttack    0\n",
       "PhysActivity            0\n",
       "GenHlth                 0\n",
       "PhysHlth                0\n",
       "DiffWalk                0\n",
       "Age                     0\n",
       "Education               0\n",
       "Income                  0\n",
       "BMI                     0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initially, we dropped all the columns that we had encoded, such as Age, Education, Income, and BMI. In the end, we only went with BMI, but the following code still honors our initial research. We first create a copy of the unencoded data and then drop the columns we want to encode. We also reset the index so that our encoded columns to not get mismatched\n",
    "# TRAINING\n",
    "x_train_unencoded_init = x_train_init.copy().drop(columns=['Age', 'Education', 'Income', 'BMI'])\n",
    "x_train_unencoded_init = x_train_unencoded_init.reset_index(drop=True)\n",
    "\n",
    "# For our final analysis, we drop BMI only, as that is the only column we moved forward with encoding and that needed encoding regardless. We first create a copy of the unencoded data and then drop the columns we want to encode\n",
    "x_train_unencoded = x_train.copy().drop(columns=['BMI'])\n",
    "x_train_unencoded = x_train_unencoded.reset_index(drop=True)\n",
    "\n",
    "# The same processes above are applied to the testing data, copy the unencoded data, drop the columns we want to encode, and then reset the index so that the encoded columns arent misaligned when concatenating.\n",
    "# TESTING\n",
    "# Our initial analysis\n",
    "x_test_unencoded_init = x_test.copy().drop(columns=['Age', 'Education', 'Income', 'BMI'])\n",
    "x_test_unencoded_init = x_test_unencoded_init.reset_index(drop=True)\n",
    "\n",
    "# Our final analysis\n",
    "x_test_unencoded = x_test.copy().drop(columns=['BMI'])\n",
    "x_test_unencoded = x_test_unencoded.reset_index(drop=True)\n",
    "\n",
    "# add the encoded columns back to the main dataframe\n",
    "# Our initial analysis, train and test\n",
    "x_train_encoded_init = pd.concat([x_train_unencoded_init, encode_BMI_df_train, encode_income_df_train, encode_educ_df_train, encode_age_df_train], axis=1)\n",
    "x_test_encoded_init = pd.concat([x_test_unencoded_init, encode_BMI_df_test, encode_income_df_test, encode_educ_df_test, encode_age_df_test], axis=1)\n",
    "\n",
    "# Our final analysis, train and test\n",
    "x_train_encoded = pd.concat([x_train_unencoded, encode_BMI_df_train], axis=1)\n",
    "x_test_encoded = pd.concat([x_test_unencoded, encode_BMI_df_test], axis=1)\n",
    "\n",
    "# the results to ensure that the concatentations did not result in misaligns and therefore NaNs\n",
    "display(x_train_encoded.isna().sum())\n",
    "display(x_test_encoded.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "      <th>BMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   HighBP  HighChol  CholCheck  Stroke  HeartDiseaseorAttack  PhysActivity  \\\n",
       "0     1.0       1.0        1.0     1.0                   0.0           1.0   \n",
       "1     1.0       0.0        1.0     0.0                   0.0           0.0   \n",
       "2     1.0       1.0        1.0     0.0                   0.0           1.0   \n",
       "3     1.0       1.0        1.0     0.0                   0.0           1.0   \n",
       "4     0.0       0.0        0.0     0.0                   0.0           1.0   \n",
       "\n",
       "   GenHlth  PhysHlth  DiffWalk   Age  Education  Income  BMI  \n",
       "0      2.0       0.0       0.0  11.0        4.0     1.0  4.0  \n",
       "1      2.0       0.0       0.0  10.0        5.0     6.0  3.0  \n",
       "2      1.0       0.0       0.0   8.0        6.0     8.0  3.0  \n",
       "3      5.0      15.0       1.0   6.0        4.0     4.0  5.0  \n",
       "4      3.0       0.0       0.0  13.0        4.0     5.0  3.0  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our new encoded data to use for the models\n",
    "x_train_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling the Data\n",
    "As we do not only have 0's and 1's in our dataset anymore, we need to scale the data in preparation for creating the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a scaler and fit it to the training data. Then, transform both the train and test encoded dataframes\n",
    "scaler = StandardScaler()\n",
    "scaler_init = StandardScaler()\n",
    "\n",
    "# Initial Analysis\n",
    "scaler_init.fit(x_train_encoded_init)\n",
    "x_train_encoded_init = scaler_init.transform(x_train_encoded_init)\n",
    "x_test_encoded_init = scaler_init.transform(x_test_encoded_init)\n",
    "\n",
    "# Final Analysis\n",
    "scaler.fit(x_train_encoded)\n",
    "x_train_encoded = scaler.transform(x_train_encoded)\n",
    "x_test_encoded = scaler.transform(x_test_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the ML Models\n",
    "\n",
    "Now that the data has been cleaned and prepped for analysis, we will now build the following models to determine the best machine learning model to predict whether someone has diabetes or not based on the survey answers.\n",
    "\n",
    "We will create the following models:\n",
    "\n",
    "1. KNN\n",
    "2. Logistic Regression\n",
    "3. Decision Tree\n",
    "4. Random Forest\n",
    "5. XG Boost \n",
    "6. Adaptive Boost\n",
    "\n",
    "Each model below will have our initial results and our final results after only keeping BMI as our encoded column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 1, Train/Test Score: 0.823/0.675\n",
      "k: 3, Train/Test Score: 0.785/0.703\n",
      "k: 5, Train/Test Score: 0.773/0.718\n",
      "k: 7, Train/Test Score: 0.767/0.724\n",
      "k: 9, Train/Test Score: 0.763/0.727\n",
      "k: 11, Train/Test Score: 0.759/0.728\n",
      "k: 13, Train/Test Score: 0.759/0.731\n",
      "k: 15, Train/Test Score: 0.757/0.736\n",
      "k: 17, Train/Test Score: 0.757/0.735\n",
      "k: 19, Train/Test Score: 0.756/0.740\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loop through different k values to find which has the highest accuracy.\n",
    "# Note: We use only odd numbers because we don't want any ties.\n",
    "# We then plot the results of the testing and training scores to find the best k value without too much overfitting\n",
    "\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for k in range(1, 20, 2):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(x_train_encoded_init, y_train_init)\n",
    "    train_score = knn.score(x_train_encoded_init, y_train_init)\n",
    "    test_score = knn.score(x_test_encoded_init, y_test_init)\n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "    print(f\"k: {k}, Train/Test Score: {train_score:.3f}/{test_score:.3f}\")\n",
    "    \n",
    "# Plot the results\n",
    "plt.plot(range(1, 20, 2), train_scores, marker='o', label=\"training scores\")\n",
    "plt.plot(range(1, 20, 2), test_scores, marker=\"x\", label=\"testing scores\")\n",
    "plt.xlabel(\"k neighbors\")\n",
    "plt.ylabel(\"accuracy score\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 1, Train/Test Score: 0.915/0.664\n",
      "k: 3, Train/Test Score: 0.816/0.699\n",
      "k: 5, Train/Test Score: 0.790/0.714\n",
      "k: 7, Train/Test Score: 0.780/0.723\n",
      "k: 9, Train/Test Score: 0.774/0.731\n",
      "k: 11, Train/Test Score: 0.767/0.733\n",
      "k: 13, Train/Test Score: 0.765/0.736\n",
      "k: 15, Train/Test Score: 0.762/0.739\n",
      "k: 17, Train/Test Score: 0.761/0.742\n",
      "k: 19, Train/Test Score: 0.760/0.743\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loop through different k values to find which has the highest accuracy.\n",
    "# Note: We use only odd numbers because we don't want any ties.\n",
    "# We then plot the results of the testing and training scores to find the best k value without too much overfitting\n",
    "\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for k in range(1, 20, 2):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(x_train_encoded, y_train)\n",
    "    train_score = knn.score(x_train_encoded, y_train)\n",
    "    test_score = knn.score(x_test_encoded, y_test)\n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "    print(f\"k: {k}, Train/Test Score: {train_score:.3f}/{test_score:.3f}\")\n",
    "    \n",
    "# Plot the results\n",
    "plt.plot(range(1, 20, 2), train_scores, marker='o', label=\"training scores\")\n",
    "plt.plot(range(1, 20, 2), test_scores, marker=\"x\", label=\"testing scores\")\n",
    "plt.xlabel(\"k neighbors\")\n",
    "plt.ylabel(\"accuracy score\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for (Initial) Logistic Regression Model is: 0.751145815650993\n"
     ]
    }
   ],
   "source": [
    "#Create and fit the logistic regression model\n",
    "logistic_regression_model = LogisticRegression(random_state=1, max_iter=1000)\n",
    "logistic_regression_model.fit(x_train_encoded_init, y_train_init)\n",
    "\n",
    "#make and save testing predictions with the saved logistic regression model using the test data\n",
    "predictions = logistic_regression_model.predict(x_test_encoded_init)\n",
    "\n",
    "# Review and display the accuracy of the logistic regression model\n",
    "accuracy_lgr_init = accuracy_score(y_test_init, predictions)\n",
    "print(f\"Accuracy for (Initial) Logistic Regression Model is: {accuracy_lgr_init}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Logistic Regression Model is: 0.7522209019408137\n"
     ]
    }
   ],
   "source": [
    "# Create and fit the logistic regression model\n",
    "logistic_regression_model = LogisticRegression(random_state=1, max_iter=1000)\n",
    "logistic_regression_model.fit(x_train_encoded, y_train)\n",
    "\n",
    "# make and save testing predictions with the saved logistic regression model using the test data\n",
    "predictions = logistic_regression_model.predict(x_test_encoded)\n",
    "\n",
    "# Review and display the accuracy of the logistic regression model\n",
    "accuracy_lgr = accuracy_score(y_test, predictions)\n",
    "print(f\"Accuracy for Logistic Regression Model is: {accuracy_lgr}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for (Initial) Decision Tree Model is: 0.6904317320205964\n"
     ]
    }
   ],
   "source": [
    "# create and fit the decision tree model\n",
    "tree_model = tree.DecisionTreeClassifier()\n",
    "tree_model = tree_model.fit(x_train_encoded_init, y_train_init)\n",
    "\n",
    "# make and save testing predictions with the saved decision tree model using the test data\n",
    "predictions = tree_model.predict(x_test_encoded_init)\n",
    "\n",
    "# Review and display the accuracy of the decision tree model\n",
    "accuracy_dt_init = accuracy_score(y_test_init, predictions)\n",
    "print(f\"Accuracy for (Initial) Decision Tree Model is: {accuracy_dt_init}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Decision Tree Model is: 0.6699485090250665\n"
     ]
    }
   ],
   "source": [
    "# create and fit the decision tree model\n",
    "tree_model = tree.DecisionTreeClassifier()\n",
    "tree_model = tree_model.fit(x_train_encoded, y_train)\n",
    "\n",
    "# make and save testing predictions with the saved decision tree model using the test data\n",
    "predictions = tree_model.predict(x_test_encoded)\n",
    "\n",
    "# Calculate the accuracy score\n",
    "accuracy_dt = accuracy_score(y_test, predictions)\n",
    "print(f\"Accuracy for Decision Tree Model is: {accuracy_dt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score for (Initial) Random Forest is: 0.857673664158132\n",
      "Testing Score for (Initial) Random Forest is: 0.722118485825836\n",
      "[[6718 2108]\n",
      " [2875 5972]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.76      0.73      8826\n",
      "           0       0.74      0.68      0.71      8847\n",
      "\n",
      "    accuracy                           0.72     17673\n",
      "   macro avg       0.72      0.72      0.72     17673\n",
      "weighted avg       0.72      0.72      0.72     17673\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create and train the Random Forest model. Then create predictions for the model\n",
    "clf = RandomForestClassifier(random_state=1, n_estimators=1000).fit(x_train_encoded_init, y_train_init)\n",
    "predictions = clf.predict(x_test_encoded)\n",
    "\n",
    "# Evaluate the model and its confusion matrix\n",
    "print(f'Training Score for (Initial) Random Forest is: {clf.score(x_train_encoded_init, y_train_init)}')\n",
    "print(f'Testing Score for (Initial) Random Forest is: {clf.score(x_test_encoded_init, y_test_init)}')\n",
    "\n",
    "print(confusion_matrix(y_test_init, predictions, labels=[1, 0]))\n",
    "print(classification_report(y_test_init, predictions, labels=[1, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score for Random Forest is: 0.930175974650597\n",
      "Testing Score for Random Forest is: 0.7231369886267187\n",
      "[[6616 2210]\n",
      " [2683 6164]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.75      0.73      8826\n",
      "           0       0.74      0.70      0.72      8847\n",
      "\n",
      "    accuracy                           0.72     17673\n",
      "   macro avg       0.72      0.72      0.72     17673\n",
      "weighted avg       0.72      0.72      0.72     17673\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create and train the Random Forest model. Then create predictions for the model\n",
    "clf = RandomForestClassifier(random_state=1, n_estimators=1000).fit(x_train_encoded, y_train)\n",
    "predictions = clf.predict(x_test_encoded)\n",
    "\n",
    "# Evaluate the model and its confusion matrix\n",
    "print(f'Training Score for Random Forest is: {clf.score(x_train_encoded, y_train)}')\n",
    "print(f'Testing Score for Random Forest is: {clf.score(x_test_encoded, y_test)}')\n",
    "print(confusion_matrix(y_test, predictions, labels=[1, 0]))\n",
    "print(classification_report(y_test, predictions, labels=[1, 0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. XG Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for (Initial) XGBoost Model is: 0.753465738697448\n",
      "[[7012 1814]\n",
      " [2543 6304]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.79      0.76      8826\n",
      "           0       0.78      0.71      0.74      8847\n",
      "\n",
      "    accuracy                           0.75     17673\n",
      "   macro avg       0.76      0.75      0.75     17673\n",
      "weighted avg       0.76      0.75      0.75     17673\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create the XGB model\n",
    "xgb_model = XGBClassifier(random_state=1, learning_rate = 0.05, n_estimators = 1000, max_depth=3)\n",
    "\n",
    "# fit the XGB model to the training data and then create predictions\n",
    "xgb_model.fit(x_train_encoded_init, y_train_init)\n",
    "predictions = xgb_model.predict(x_test_encoded_init)\n",
    "\n",
    "# get the accuracy score of the model, and the confusion matrix for the model\n",
    "accuracy_xgb_init = accuracy_score(y_test_init, predictions)\n",
    "print(f\"Accuracy for (Initial) XGBoost Model is: {accuracy_xgb_init}\")\n",
    "print(confusion_matrix(y_test_init, predictions, labels=[1, 0]))\n",
    "print(classification_report(y_test_init, predictions, labels=[1, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for XGBoost Model is: 0.7562949131443445\n",
      "[[7044 1782]\n",
      " [2525 6322]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.80      0.77      8826\n",
      "           0       0.78      0.71      0.75      8847\n",
      "\n",
      "    accuracy                           0.76     17673\n",
      "   macro avg       0.76      0.76      0.76     17673\n",
      "weighted avg       0.76      0.76      0.76     17673\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create the XGB model\n",
    "xgb_model = XGBClassifier(random_state=1, learning_rate = 0.05, n_estimators = 1000, max_depth=3)\n",
    "\n",
    "# fit the XGB model to the training data and then create predictions\n",
    "xgb_model.fit(x_train_encoded, y_train)\n",
    "predictions = xgb_model.predict(x_test_encoded)\n",
    "\n",
    "# get the accuracy score of the model, and the confusion matrix for the model\n",
    "accuracy_xgb = accuracy_score(y_test, predictions)\n",
    "print(f\"Accuracy for XGBoost Model is: {accuracy_xgb}\")\n",
    "print(confusion_matrix(y_test, predictions, labels=[1, 0]))\n",
    "print(classification_report(y_test, predictions, labels=[1, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Adaptive Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sami\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy for Adaptive Boosting Classifier: 0.7449027707048417\n",
      "Testing Accuracy Adaptive Boosting Classifier: 0.7526735698523171\n"
     ]
    }
   ],
   "source": [
    "# create the adaptive boosting model and fit to the training data\n",
    "model_adapt = AdaBoostClassifier()\n",
    "model_adapt.fit(x_train_encoded_init, y_train_init)\n",
    "\n",
    "# get the accuracy score of the model, and the confusion matrix for the model\n",
    "print(f\"Training Accuracy for (Initial) Adaptive Boosting Classifier: {model_adapt.score(x_train_encoded_init, y_train_init)}\")\n",
    "print(f\"Testing Accuracy for (Initial) Adaptive Boosting Classifier: {model_adapt.score(x_test_encoded_init, y_test_init)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sami\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy for Adaptive Boosting Classifier: 0.7464116637431865\n",
      "Testing Accuracy Adaptive Boosting Classifier: 0.7507497312284276\n"
     ]
    }
   ],
   "source": [
    "# create the adaptive boosting model and fit to the training data\n",
    "model_adapt = AdaBoostClassifier()\n",
    "model_adapt.fit(x_train_encoded, y_train)\n",
    "\n",
    "# get the accuracy score of the model, and the confusion matrix for the model\n",
    "print(f\"Training Accuracy for Adaptive Boosting Classifier: {model_adapt.score(x_train_encoded, y_train)}\")\n",
    "print(f\"Testing Accuracy for Adaptive Boosting Classifier: {model_adapt.score(x_test_encoded, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above models and their confusion matrices, we can conclude that our best models were "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tuning the models, finding the best parameters/models\n",
    "\n",
    "Finally, we will explore the best parameters for our models shown above using the GridSearch method. We will only use our final result models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Grid search on KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.69      0.71      8847\n",
      "    positive       0.71      0.75      0.73      8826\n",
      "\n",
      "    accuracy                           0.72     17673\n",
      "   macro avg       0.72      0.72      0.72     17673\n",
      "weighted avg       0.72      0.72      0.72     17673\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the parameter grid for the GridSearchCV model running KNeighborsClassifier\n",
    "param_grid_knn = {\n",
    "    'n_neighbors': [19], \n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan'],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "}\n",
    "\n",
    "# create the grid_tuned model and the grid search estimator\n",
    "grid_model_knn = KNeighborsClassifier()\n",
    "grid_clf_knn = GridSearchCV(grid_model_knn, param_grid_knn, verbose=3)\n",
    "\n",
    "# Fit the model by using the grid search estimator.\n",
    "# This will take the KNN model and try each combination of parameters.\n",
    "grid_clf_knn.fit(x_train_encoded, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the best parameters for this model\n",
    "print(grid_clf_knn.best_params_)\n",
    "\n",
    "# Print the classification report for the best model\n",
    "grid_y_pred_knn = grid_clf_knn.predict(x_test_encoded)\n",
    "print(classification_report(y_test, grid_y_pred_knn,\n",
    "                            target_names=[1, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Grid Search on Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the parameter grid for the GridSearchCV model running logistic regression\n",
    "param_grid_lgr = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear'], \n",
    "    'max_iter': [100, 1000, 10000]\n",
    "}\n",
    "\n",
    "# create the grid_tuned model and the grid search estimator\n",
    "grid_model_lgr = LogisticRegression()\n",
    "grid_clf_lgr = GridSearchCV(grid_model_lgr, param_grid_lgr, verbose=3)\n",
    "\n",
    "# Fit the model by using the grid search estimator.\n",
    "# This will take the Logistic Regression model and try each combination of parameters.\n",
    "grid_clf_lgr.fit(x_train_encoded, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the best parameters for this dataset\n",
    "print(grid_clf_lgr.best_params_)\n",
    "\n",
    "# Print the classification report for the best model\n",
    "grid_y_pred_lgr = grid_clf_lgr.predict(x_test_encoded)\n",
    "print(classification_report(y_test, grid_y_pred_lgr,\n",
    "                            target_names=[1, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Grid Search on Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the parameter grid for the GridSearchCV model running logistic regression\n",
    "param_grid_dt = {\n",
    "    'max_depth': [None, 1, 2, 3, 5, 10],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 5, 10],\n",
    "    'max_features': [None, 'auto', 'sqrt', 'log2'],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "# create the grid_tuned model and the grid search estimator\n",
    "grid_model_dt = DecisionTreeClassifier()\n",
    "grid_clf_dt = GridSearchCV(grid_model_dt, param_grid_dt, verbose=3)\n",
    "\n",
    "# Fit the model by using the grid search estimator.\n",
    "# This will take the Logistic Regression model and try each combination of parameters.\n",
    "grid_clf_dt.fit(x_train_encoded, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the best parameters for this dataset\n",
    "print(grid_clf_dt.best_params_)\n",
    "\n",
    "# Print the classification report for the best model\n",
    "grid_y_pred_dt = grid_clf_dt.predict(x_test_encoded)\n",
    "print(classification_report(y_test, grid_y_pred_dt,\n",
    "                            target_names=[1, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Grid Search on Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the parameter grid for the GridSearchCV model running Random Forest\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 500, 1000],\n",
    "    'max_depth': [3, 7, 11] \n",
    "}\n",
    "\n",
    "# create the grid_tuned model and the grid search estimator\n",
    "grid_model_rf = RandomForestClassifier()\n",
    "grid_clf_rf = GridSearchCV(grid_model_rf, param_grid_rf, verbose=3)\n",
    "\n",
    "# Fit the model by using the grid search estimator.\n",
    "# This will take the Random Forest model and try each combination of parameters.\n",
    "grid_clf_rf.fit(x_train_encoded, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the best parameters for this dataset\n",
    "print(grid_clf_rf.best_params_)\n",
    "\n",
    "# Print the classification report for the best model\n",
    "grid_y_pred_rf = grid_clf_rf.predict(x_test_encoded)\n",
    "print(classification_report(y_test, grid_y_pred_rf,\n",
    "                            target_names=[1, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Grid Search on XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the parameter grid for the GridSearchCV model running XGB\n",
    "param_grid_xgb = {\n",
    "    'learning_rate': [0.05, 0.1, 0.2],\n",
    "    'n_estimators': [100, 500, 1000],\n",
    "    'max_depth': [3, 7, 11]  \n",
    "}\n",
    "\n",
    "# create the grid_tuned model and the grid search estimator\n",
    "grid_model_xgb = XGBClassifier()\n",
    "grid_clf_xgb = GridSearchCV(grid_model_xgb, param_grid_xgb, verbose=3)\n",
    "\n",
    "# Fit the model by using the grid search estimator.\n",
    "# This will take the XGBoost model and try each combination of parameters.\n",
    "grid_clf_xgb.fit(x_train_encoded, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the best parameters for this dataset\n",
    "print(grid_clf_xgb.best_params_)\n",
    "\n",
    "# Print the classification report for the best model\n",
    "grid_y_pred_xgb = grid_clf_xgb.predict(x_test_encoded)\n",
    "print(classification_report(y_test, grid_y_pred_xgb,\n",
    "                            target_names=[1, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Grid Search on Adaptive Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the parameter grid for the GridSearchCV model running XGB\n",
    "param_grid_ada = {\n",
    "    'n_estimators': [50, 100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.5, 1.0],\n",
    "    'algorithm': ['SAMME', 'SAMME.R'] \n",
    "}\n",
    "\n",
    "# create the grid_tuned model and the grid search estimator\n",
    "grid_model_ada = AdaBoostClassifier()\n",
    "grid_clf_ada = GridSearchCV(grid_model_ada, param_grid_ada, verbose=3)\n",
    "\n",
    "# Fit the model by using the grid search estimator.\n",
    "# This will take the XGBoost model and try each combination of parameters.\n",
    "grid_clf_ada.fit(x_train_encoded, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the best parameters for this dataset\n",
    "print(grid_clf_ada.best_params_)\n",
    "\n",
    "# Print the classification report for the best model\n",
    "grid_y_pred_ada = grid_clf_ada.predict(x_test_encoded)\n",
    "print(classification_report(y_test, grid_y_pred_ada,\n",
    "                            target_names=[1, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note the below is old data used to verify everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV 1/5] END leaf_size=1, n_neighbors=5, weights=uniform;, score=0.716 total time=   7.3s\n",
      "[CV 2/5] END leaf_size=1, n_neighbors=5, weights=uniform;, score=0.705 total time=   7.2s\n",
      "[CV 3/5] END leaf_size=1, n_neighbors=5, weights=uniform;, score=0.714 total time=   7.0s\n",
      "[CV 4/5] END leaf_size=1, n_neighbors=5, weights=uniform;, score=0.710 total time=   7.2s\n",
      "[CV 5/5] END leaf_size=1, n_neighbors=5, weights=uniform;, score=0.714 total time=   7.2s\n",
      "[CV 1/5] END leaf_size=500, n_neighbors=19, weights=uniform;, score=0.746 total time=   3.9s\n",
      "[CV 2/5] END leaf_size=500, n_neighbors=19, weights=uniform;, score=0.732 total time=   3.9s\n",
      "[CV 3/5] END leaf_size=500, n_neighbors=19, weights=uniform;, score=0.734 total time=   4.0s\n",
      "[CV 4/5] END leaf_size=500, n_neighbors=19, weights=uniform;, score=0.729 total time=   3.8s\n",
      "[CV 5/5] END leaf_size=500, n_neighbors=19, weights=uniform;, score=0.739 total time=   4.0s\n",
      "[CV 1/5] END leaf_size=100, n_neighbors=5, weights=distance;, score=0.702 total time=   2.2s\n",
      "[CV 2/5] END leaf_size=100, n_neighbors=5, weights=distance;, score=0.693 total time=   2.3s\n",
      "[CV 3/5] END leaf_size=100, n_neighbors=5, weights=distance;, score=0.696 total time=   2.3s\n",
      "[CV 4/5] END leaf_size=100, n_neighbors=5, weights=distance;, score=0.695 total time=   2.3s\n",
      "[CV 5/5] END leaf_size=100, n_neighbors=5, weights=distance;, score=0.703 total time=   2.5s\n",
      "[CV 1/5] END leaf_size=100, n_neighbors=1, weights=uniform;, score=0.663 total time=   1.9s\n",
      "[CV 2/5] END leaf_size=100, n_neighbors=1, weights=uniform;, score=0.656 total time=   1.9s\n",
      "[CV 3/5] END leaf_size=100, n_neighbors=1, weights=uniform;, score=0.666 total time=   1.9s\n",
      "[CV 4/5] END leaf_size=100, n_neighbors=1, weights=uniform;, score=0.657 total time=   1.9s\n",
      "[CV 5/5] END leaf_size=100, n_neighbors=1, weights=uniform;, score=0.666 total time=   1.9s\n",
      "[CV 1/5] END leaf_size=500, n_neighbors=15, weights=uniform;, score=0.742 total time=   3.8s\n",
      "[CV 2/5] END leaf_size=500, n_neighbors=15, weights=uniform;, score=0.727 total time=   3.8s\n",
      "[CV 3/5] END leaf_size=500, n_neighbors=15, weights=uniform;, score=0.732 total time=   3.8s\n",
      "[CV 4/5] END leaf_size=500, n_neighbors=15, weights=uniform;, score=0.729 total time=   3.7s\n",
      "[CV 5/5] END leaf_size=500, n_neighbors=15, weights=uniform;, score=0.734 total time=   3.8s\n",
      "[CV 1/5] END leaf_size=500, n_neighbors=11, weights=uniform;, score=0.737 total time=   3.6s\n",
      "[CV 2/5] END leaf_size=500, n_neighbors=11, weights=uniform;, score=0.720 total time=   3.7s\n",
      "[CV 3/5] END leaf_size=500, n_neighbors=11, weights=uniform;, score=0.731 total time=   3.6s\n",
      "[CV 4/5] END leaf_size=500, n_neighbors=11, weights=uniform;, score=0.722 total time=   3.6s\n",
      "[CV 5/5] END leaf_size=500, n_neighbors=11, weights=uniform;, score=0.725 total time=   3.6s\n",
      "[CV 1/5] END leaf_size=500, n_neighbors=15, weights=distance;, score=0.722 total time=   3.6s\n",
      "[CV 2/5] END leaf_size=500, n_neighbors=15, weights=distance;, score=0.709 total time=   3.5s\n",
      "[CV 3/5] END leaf_size=500, n_neighbors=15, weights=distance;, score=0.712 total time=   3.5s\n",
      "[CV 4/5] END leaf_size=500, n_neighbors=15, weights=distance;, score=0.708 total time=   3.4s\n",
      "[CV 5/5] END leaf_size=500, n_neighbors=15, weights=distance;, score=0.715 total time=   3.5s\n",
      "[CV 1/5] END leaf_size=100, n_neighbors=1, weights=distance;, score=0.663 total time=   1.6s\n",
      "[CV 2/5] END leaf_size=100, n_neighbors=1, weights=distance;, score=0.656 total time=   1.7s\n",
      "[CV 3/5] END leaf_size=100, n_neighbors=1, weights=distance;, score=0.666 total time=   1.6s\n",
      "[CV 4/5] END leaf_size=100, n_neighbors=1, weights=distance;, score=0.657 total time=   1.6s\n",
      "[CV 5/5] END leaf_size=100, n_neighbors=1, weights=distance;, score=0.666 total time=   1.6s\n",
      "[CV 1/5] END leaf_size=100, n_neighbors=15, weights=distance;, score=0.721 total time=   2.8s\n",
      "[CV 2/5] END leaf_size=100, n_neighbors=15, weights=distance;, score=0.708 total time=   2.7s\n",
      "[CV 3/5] END leaf_size=100, n_neighbors=15, weights=distance;, score=0.711 total time=   2.8s\n",
      "[CV 4/5] END leaf_size=100, n_neighbors=15, weights=distance;, score=0.708 total time=   2.8s\n",
      "[CV 5/5] END leaf_size=100, n_neighbors=15, weights=distance;, score=0.715 total time=   2.8s\n",
      "[CV 1/5] END leaf_size=500, n_neighbors=5, weights=uniform;, score=0.715 total time=   3.3s\n",
      "[CV 2/5] END leaf_size=500, n_neighbors=5, weights=uniform;, score=0.705 total time=   3.2s\n",
      "[CV 3/5] END leaf_size=500, n_neighbors=5, weights=uniform;, score=0.715 total time=   3.3s\n",
      "[CV 4/5] END leaf_size=500, n_neighbors=5, weights=uniform;, score=0.708 total time=   3.2s\n",
      "[CV 5/5] END leaf_size=500, n_neighbors=5, weights=uniform;, score=0.713 total time=   3.3s\n",
      "{'weights': 'uniform', 'n_neighbors': 19, 'leaf_size': 500}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.70      0.73      8847\n",
      "    positive       0.72      0.78      0.75      8826\n",
      "\n",
      "    accuracy                           0.74     17673\n",
      "   macro avg       0.74      0.74      0.74     17673\n",
      "weighted avg       0.74      0.74      0.74     17673\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the parameter object for the randomized search estimator.\n",
    "# Try adjusting n_neighbors with values of 1 through 19. \n",
    "# Adjust leaf_size by using a range from 1 to 500.\n",
    "# Include both uniform and distance options for weights.\n",
    "param_grid = {\n",
    "    'n_neighbors': [1, 5, 11, 15, 19],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'leaf_size': [1, 100, 500]\n",
    "}\n",
    "\n",
    "random_clf = RandomizedSearchCV(random_tuned_model, param_grid, random_state=0, verbose=3)\n",
    "random_clf.fit(x_train_encoded, y_train)\n",
    "# List the best parameters for this dataset\n",
    "print(random_clf.best_params_)\n",
    "# Make predictions with the hypertuned model\n",
    "random_tuned_pred = random_clf.predict(x_test_encoded)\n",
    "# Calculate the classification report\n",
    "print(classification_report(y_test, random_tuned_pred,\n",
    "                            target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest fixer\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 500, 1000],\n",
    "    'max_depth': [3,5,7]\n",
    "}\n",
    "\n",
    "grid_clf = GridSearchCV(grid_tuned_model, param_grid, verbose=3)\n",
    "# Fit the model by using the grid search estimator.\n",
    "# This will take the KNN model and try each combination of parameters.\n",
    "grid_clf.fit(x_train_encoded, y_train)\n",
    "# List the best parameters for this dataset\n",
    "print(grid_clf.best_params_)\n",
    "# Print the classification report for the best model\n",
    "grid_y_pred = grid_clf.predict(x_test_encoded)\n",
    "print(classification_report(y_test, grid_y_pred,\n",
    "                            target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=3, n_estimators=100;, score=0.753 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=3, n_estimators=100;, score=0.742 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=3, n_estimators=100;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=3, n_estimators=100;, score=0.742 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=3, n_estimators=100;, score=0.748 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=3, n_estimators=500;, score=0.757 total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=3, n_estimators=500;, score=0.744 total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=3, n_estimators=500;, score=0.748 total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=3, n_estimators=500;, score=0.745 total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=3, n_estimators=500;, score=0.750 total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=3, n_estimators=1000;, score=0.755 total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=3, n_estimators=1000;, score=0.742 total time=   0.8s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=3, n_estimators=1000;, score=0.748 total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=3, n_estimators=1000;, score=0.743 total time=   0.7s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=3, n_estimators=1000;, score=0.750 total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=7, n_estimators=100;, score=0.756 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=7, n_estimators=100;, score=0.743 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=7, n_estimators=100;, score=0.745 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=7, n_estimators=100;, score=0.742 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=7, n_estimators=100;, score=0.749 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=7, n_estimators=500;, score=0.748 total time=   0.8s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=7, n_estimators=500;, score=0.737 total time=   0.8s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=7, n_estimators=500;, score=0.740 total time=   0.9s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=7, n_estimators=500;, score=0.739 total time=   0.8s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=7, n_estimators=500;, score=0.744 total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=7, n_estimators=1000;, score=0.741 total time=   1.5s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=7, n_estimators=1000;, score=0.732 total time=   1.6s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=7, n_estimators=1000;, score=0.736 total time=   1.7s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=7, n_estimators=1000;, score=0.732 total time=   1.6s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=7, n_estimators=1000;, score=0.737 total time=   1.6s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=11, n_estimators=100;, score=0.744 total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=11, n_estimators=100;, score=0.736 total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=11, n_estimators=100;, score=0.737 total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=11, n_estimators=100;, score=0.737 total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=11, n_estimators=100;, score=0.739 total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=11, n_estimators=500;, score=0.726 total time=   1.9s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=11, n_estimators=500;, score=0.717 total time=   1.8s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=11, n_estimators=500;, score=0.724 total time=   1.9s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=11, n_estimators=500;, score=0.723 total time=   1.9s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=11, n_estimators=500;, score=0.726 total time=   1.9s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=11, n_estimators=1000;, score=0.713 total time=   3.6s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=11, n_estimators=1000;, score=0.708 total time=   3.9s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=11, n_estimators=1000;, score=0.717 total time=   3.6s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=11, n_estimators=1000;, score=0.711 total time=   3.6s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=11, n_estimators=1000;, score=0.718 total time=   3.8s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=100;, score=0.757 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=100;, score=0.742 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=100;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=100;, score=0.743 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=100;, score=0.749 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=500;, score=0.756 total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=500;, score=0.743 total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=500;, score=0.748 total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=500;, score=0.744 total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=500;, score=0.749 total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=1000;, score=0.755 total time=   0.9s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=1000;, score=0.740 total time=   0.9s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=1000;, score=0.746 total time=   0.8s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=1000;, score=0.743 total time=   0.8s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=1000;, score=0.749 total time=   0.8s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=7, n_estimators=100;, score=0.752 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=7, n_estimators=100;, score=0.742 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=7, n_estimators=100;, score=0.743 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=7, n_estimators=100;, score=0.743 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=7, n_estimators=100;, score=0.748 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=7, n_estimators=500;, score=0.742 total time=   0.8s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=7, n_estimators=500;, score=0.730 total time=   0.8s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=7, n_estimators=500;, score=0.734 total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=7, n_estimators=500;, score=0.734 total time=   0.8s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=7, n_estimators=500;, score=0.735 total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=7, n_estimators=1000;, score=0.731 total time=   1.6s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=7, n_estimators=1000;, score=0.723 total time=   1.8s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=7, n_estimators=1000;, score=0.728 total time=   1.8s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=7, n_estimators=1000;, score=0.725 total time=   1.8s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=7, n_estimators=1000;, score=0.730 total time=   1.8s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=11, n_estimators=100;, score=0.743 total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=11, n_estimators=100;, score=0.730 total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=11, n_estimators=100;, score=0.733 total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=11, n_estimators=100;, score=0.734 total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=11, n_estimators=100;, score=0.735 total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=11, n_estimators=500;, score=0.713 total time=   1.8s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=11, n_estimators=500;, score=0.708 total time=   1.9s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=11, n_estimators=500;, score=0.714 total time=   1.8s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=11, n_estimators=500;, score=0.711 total time=   1.9s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=11, n_estimators=500;, score=0.715 total time=   1.9s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=11, n_estimators=1000;, score=0.707 total time=   3.5s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=11, n_estimators=1000;, score=0.697 total time=   3.6s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=11, n_estimators=1000;, score=0.707 total time=   3.6s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=11, n_estimators=1000;, score=0.700 total time=   3.7s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=11, n_estimators=1000;, score=0.711 total time=   3.5s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=3, n_estimators=100;, score=0.757 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=3, n_estimators=100;, score=0.742 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=3, n_estimators=100;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=3, n_estimators=100;, score=0.744 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=3, n_estimators=100;, score=0.751 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=3, n_estimators=500;, score=0.755 total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=3, n_estimators=500;, score=0.740 total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=3, n_estimators=500;, score=0.746 total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=3, n_estimators=500;, score=0.743 total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=3, n_estimators=500;, score=0.747 total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=3, n_estimators=1000;, score=0.752 total time=   1.1s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=3, n_estimators=1000;, score=0.741 total time=   1.0s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=3, n_estimators=1000;, score=0.744 total time=   0.9s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=3, n_estimators=1000;, score=0.742 total time=   1.0s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=3, n_estimators=1000;, score=0.747 total time=   1.0s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=7, n_estimators=100;, score=0.747 total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=7, n_estimators=100;, score=0.737 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=7, n_estimators=100;, score=0.740 total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=7, n_estimators=100;, score=0.740 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=7, n_estimators=100;, score=0.745 total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=7, n_estimators=500;, score=0.730 total time=   1.0s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=7, n_estimators=500;, score=0.724 total time=   0.9s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=7, n_estimators=500;, score=0.726 total time=   0.8s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=7, n_estimators=500;, score=0.723 total time=   0.8s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=7, n_estimators=500;, score=0.730 total time=   0.8s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=7, n_estimators=1000;, score=0.719 total time=   1.7s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=7, n_estimators=1000;, score=0.713 total time=   2.0s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=7, n_estimators=1000;, score=0.720 total time=   1.9s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=7, n_estimators=1000;, score=0.710 total time=   1.8s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=7, n_estimators=1000;, score=0.720 total time=   1.8s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=11, n_estimators=100;, score=0.728 total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=11, n_estimators=100;, score=0.718 total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=11, n_estimators=100;, score=0.722 total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=11, n_estimators=100;, score=0.724 total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=11, n_estimators=100;, score=0.726 total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=11, n_estimators=500;, score=0.706 total time=   1.7s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=11, n_estimators=500;, score=0.697 total time=   1.9s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=11, n_estimators=500;, score=0.707 total time=   1.8s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=11, n_estimators=500;, score=0.700 total time=   1.8s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=11, n_estimators=500;, score=0.710 total time=   1.9s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=11, n_estimators=1000;, score=0.701 total time=   3.3s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=11, n_estimators=1000;, score=0.688 total time=   3.3s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=11, n_estimators=1000;, score=0.699 total time=   3.4s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=11, n_estimators=1000;, score=0.694 total time=   3.3s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=11, n_estimators=1000;, score=0.704 total time=   3.4s\n",
      "Accuracy: 0.7555027442992135\n",
      "{'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.7485807202526576\n"
     ]
    }
   ],
   "source": [
    "# Create the parameter grid for the GridSearchCV model running Xgboost\n",
    "param_grid = {\n",
    "  #random_state=1, learning_rate=0.05, n_estimators=1000, max_depth=3\n",
    "    'learning_rate': [0.05, 0.1, 0.2],\n",
    "    'n_estimators': [100, 500, 1000],\n",
    "    'max_depth': [3, 7, 11]\n",
    "}\n",
    "# Create the GridSearchCV model\n",
    "grid_model = GridSearchCV(XGBClassifier(), param_grid, verbose=3)\n",
    "# Fit the model\n",
    "grid_model.fit(x_train_encoded, y_train)\n",
    "# Make predictions\n",
    "predictions = grid_model.predict(x_test_encoded)\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "# Print the best parameters\n",
    "print(grid_model.best_params_)\n",
    "print(grid_model.best_score_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
