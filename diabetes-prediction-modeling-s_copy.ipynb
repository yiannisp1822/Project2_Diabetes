{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diabetes Prediction Modeling Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, balanced_accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, OrdinalEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Needed for decision tree visualization\n",
    "import pydotplus\n",
    "from IPython.display import Image\n",
    "from sklearn import tree\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found our data on Kaggle at the following [link, found by Alex Teboul](https://www.kaggle.com/datasets/alexteboul/diabetes-health-indicators-dataset/data). This data set was obtained from the Behavioral Risk Factor Surveillance System (BRFSS), which is a health-related telephone survey that is collected annually by the CDC. It is an annual survey that has been collected since 1984 and the features are either questions asked of participants or variables calculated based on their responses. We will use this dataset to create a machine learning model that predicts based on the given data, whether a person has diabetes or does not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes_binary</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>...</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Diabetes_binary  HighBP  HighChol  CholCheck   BMI  Smoker  Stroke  \\\n",
       "0              0.0     1.0       0.0        1.0  26.0     0.0     0.0   \n",
       "1              0.0     1.0       1.0        1.0  26.0     1.0     1.0   \n",
       "2              0.0     0.0       0.0        1.0  26.0     0.0     0.0   \n",
       "3              0.0     1.0       1.0        1.0  28.0     1.0     0.0   \n",
       "4              0.0     0.0       0.0        1.0  29.0     1.0     0.0   \n",
       "\n",
       "   HeartDiseaseorAttack  PhysActivity  Fruits  ...  AnyHealthcare  \\\n",
       "0                   0.0           1.0     0.0  ...            1.0   \n",
       "1                   0.0           0.0     1.0  ...            1.0   \n",
       "2                   0.0           1.0     1.0  ...            1.0   \n",
       "3                   0.0           1.0     1.0  ...            1.0   \n",
       "4                   0.0           1.0     1.0  ...            1.0   \n",
       "\n",
       "   NoDocbcCost  GenHlth  MentHlth  PhysHlth  DiffWalk  Sex   Age  Education  \\\n",
       "0          0.0      3.0       5.0      30.0       0.0  1.0   4.0        6.0   \n",
       "1          0.0      3.0       0.0       0.0       0.0  1.0  12.0        6.0   \n",
       "2          0.0      1.0       0.0      10.0       0.0  1.0  13.0        6.0   \n",
       "3          0.0      3.0       0.0       3.0       0.0  1.0  11.0        6.0   \n",
       "4          0.0      2.0       0.0       0.0       0.0  0.0   8.0        5.0   \n",
       "\n",
       "   Income  \n",
       "0     8.0  \n",
       "1     8.0  \n",
       "2     8.0  \n",
       "3     8.0  \n",
       "4     8.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the data (found in \\Resources)\n",
    "diabetes = pd.read_csv(\"Resources/diabetes_binary_5050split_health_indicators_BRFSS2015.csv\")\n",
    "\n",
    "# Head (To view the data)\n",
    "diabetes.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA \n",
    "Now we will begin diving deeper into our dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Diabetes_binary', 'HighBP', 'HighChol', 'CholCheck', 'BMI', 'Smoker',\n",
       "       'Stroke', 'HeartDiseaseorAttack', 'PhysActivity', 'Fruits', 'Veggies',\n",
       "       'HvyAlcoholConsump', 'AnyHealthcare', 'NoDocbcCost', 'GenHlth',\n",
       "       'MentHlth', 'PhysHlth', 'DiffWalk', 'Sex', 'Age', 'Education',\n",
       "       'Income'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column Descriptions\n",
    "Below are the detailed descriptions of the columns/features used for the dataset:\n",
    "\n",
    "1. **Diabetes_binary**: 0 = no diabetes, 1 = prediabetes or diabetes\n",
    "2. **HighBP**: 0 = no high, BP 1 = high BP\n",
    "3. **HighChol**: 0 = no high cholesterol, 1 = high cholesterol\n",
    "4. **CholCheck**: 0 = no cholesterol check in 5 years, 1 = yes cholesterol check in 5 years\n",
    "5. **BMI**: Body Mass Index of the person questioned.\n",
    "6. **Smoker**: Have you smoked at least 100 cigarettes in your entire life? [Note: 5 packs = 100 cigarettes] 0 = no, 1 = yes\n",
    "7. **Stroke**: (Ever) had a stroke; 0 = no, 1 = yes\n",
    "8. **HeartDiseaseorAttack**: coronary heart disease (CHD) or myocardial infarction (MI); 0 = no, 1 = yes\n",
    "9. **PhysActivity**: physical activity in past 30 days - not including job; 0 = no, 1 = yes\n",
    "10. **Fruits**: Consume Fruit 1 or more times per day; 0 = no, 1 = yes\n",
    "11. **Veggies**: Consume Vegetables 1 or more times per day; 0 = no, 1 = yes\n",
    "12. **HvyAlcoholConsump**: Heavy drinkers (adult men having more than 14 drinks per week and adult women having more than 7 drinks per week) 0 = no, 1 = yes\n",
    "13. **AnyHealthcare**: Have any kind of health care coverage, including health insurance, prepaid plans such as HMO, etc. 0 = no, 1 = yes\n",
    "14. **NoDocbcCost**: \"Was there a time in the past 12 months when you needed to see a doctor but could not because of cost?\" 0 = no, 1 = yes\n",
    "15. **GenHlth**: \"Would you say that in general your health is?\": scale 1-5; 1 = excellent, 2 = very good, 3 = good, 4 = fair, 5 = poor\n",
    "16. **MentHlth**: \"Now thinking about your mental health, which includes stress, depression, and problems with emotions, for how many days during the past 30 days was your mental health not good?\" scale 1-30 days\n",
    "17. **PhysHlth**: \"Now thinking about your physical health, which includes physical illness and injury, for how many days during the past 30 days was your physical health not good?\" scale 1-30 days\n",
    "18. **DiffWalk**: \"Do you have serious difficulty walking or climbing stairs?\" 0 = no, 1 = yes\n",
    "19. **Sex**: 0 = female, 1 = male\n",
    "20. **Age**: 13-level age category (_AGEG5YR see codebook) 1 = 18-24 9 = 60-64 13 = 80 or older\n",
    "    - 1 = Age 18 to 24\n",
    "    - 2 = Age 25 to 29\n",
    "    - 3 = Age 30 to 34\n",
    "    - 4 = Age 35 to 39\n",
    "    - 5 = Age 40 to 44\n",
    "    - 6 = Age 45 to 49\n",
    "    - 7 = Age 50 to 54\n",
    "    - 8 = Age 55 to 59\n",
    "    - 9 = Age 60 to 64\n",
    "    - 10 = Age 65 to 69\n",
    "    - 11 = Age 70 to 74\n",
    "    - 12 = Age 75 to 79\n",
    "    - 13 = Age 80 or older \n",
    "21. **Education**: Education Level\n",
    "    - 1 = Never attended school or only kindergarten\n",
    "    - 2 = Grades 1 through 8 (Elementary)\n",
    "    - 3 = Grades 9 through 11 (Some high school)\n",
    "    - 4 = Grade 12 or GED (High school graduate)\n",
    "    - 5 = College 1 year to 3 years (Some college or technical school)\n",
    "    - 6 = College 4 years or more (College graduate)\n",
    "22. **Income**: Income Scale\n",
    "    - 1 = Less than $10,000\n",
    "    - 2 = Less than $15,000 ($10,000 to less than $15,000)\n",
    "    - 3 = Less than $20,000 ($15,000 to less than $20,000)\n",
    "    - 4 = Less than $25,000 ($20,000 to less than $25,000)\n",
    "    - 5 = Less than $35,000 ($25,000 to less than $35,000)\n",
    "    - 6 = Less than $50,000 ($35,000 to less than $50,000)\n",
    "    - 7 = Less than $75,000 ($50,000 to less than $75,000)\n",
    "    - 8 = $75,000 or more\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describing the dataset at a glance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes_binary</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>...</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.563458</td>\n",
       "      <td>0.525703</td>\n",
       "      <td>0.975259</td>\n",
       "      <td>29.856985</td>\n",
       "      <td>0.475273</td>\n",
       "      <td>0.062171</td>\n",
       "      <td>0.147810</td>\n",
       "      <td>0.703036</td>\n",
       "      <td>0.611795</td>\n",
       "      <td>...</td>\n",
       "      <td>0.954960</td>\n",
       "      <td>0.093914</td>\n",
       "      <td>2.837082</td>\n",
       "      <td>3.752037</td>\n",
       "      <td>5.810417</td>\n",
       "      <td>0.252730</td>\n",
       "      <td>0.456997</td>\n",
       "      <td>8.584055</td>\n",
       "      <td>4.920953</td>\n",
       "      <td>5.698311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.500004</td>\n",
       "      <td>0.495960</td>\n",
       "      <td>0.499342</td>\n",
       "      <td>0.155336</td>\n",
       "      <td>7.113954</td>\n",
       "      <td>0.499392</td>\n",
       "      <td>0.241468</td>\n",
       "      <td>0.354914</td>\n",
       "      <td>0.456924</td>\n",
       "      <td>0.487345</td>\n",
       "      <td>...</td>\n",
       "      <td>0.207394</td>\n",
       "      <td>0.291712</td>\n",
       "      <td>1.113565</td>\n",
       "      <td>8.155627</td>\n",
       "      <td>10.062261</td>\n",
       "      <td>0.434581</td>\n",
       "      <td>0.498151</td>\n",
       "      <td>2.852153</td>\n",
       "      <td>1.029081</td>\n",
       "      <td>2.175196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Diabetes_binary        HighBP      HighChol     CholCheck  \\\n",
       "count     70692.000000  70692.000000  70692.000000  70692.000000   \n",
       "mean          0.500000      0.563458      0.525703      0.975259   \n",
       "std           0.500004      0.495960      0.499342      0.155336   \n",
       "min           0.000000      0.000000      0.000000      0.000000   \n",
       "25%           0.000000      0.000000      0.000000      1.000000   \n",
       "50%           0.500000      1.000000      1.000000      1.000000   \n",
       "75%           1.000000      1.000000      1.000000      1.000000   \n",
       "max           1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "                BMI        Smoker        Stroke  HeartDiseaseorAttack  \\\n",
       "count  70692.000000  70692.000000  70692.000000          70692.000000   \n",
       "mean      29.856985      0.475273      0.062171              0.147810   \n",
       "std        7.113954      0.499392      0.241468              0.354914   \n",
       "min       12.000000      0.000000      0.000000              0.000000   \n",
       "25%       25.000000      0.000000      0.000000              0.000000   \n",
       "50%       29.000000      0.000000      0.000000              0.000000   \n",
       "75%       33.000000      1.000000      0.000000              0.000000   \n",
       "max       98.000000      1.000000      1.000000              1.000000   \n",
       "\n",
       "       PhysActivity        Fruits  ...  AnyHealthcare   NoDocbcCost  \\\n",
       "count  70692.000000  70692.000000  ...   70692.000000  70692.000000   \n",
       "mean       0.703036      0.611795  ...       0.954960      0.093914   \n",
       "std        0.456924      0.487345  ...       0.207394      0.291712   \n",
       "min        0.000000      0.000000  ...       0.000000      0.000000   \n",
       "25%        0.000000      0.000000  ...       1.000000      0.000000   \n",
       "50%        1.000000      1.000000  ...       1.000000      0.000000   \n",
       "75%        1.000000      1.000000  ...       1.000000      0.000000   \n",
       "max        1.000000      1.000000  ...       1.000000      1.000000   \n",
       "\n",
       "            GenHlth      MentHlth      PhysHlth      DiffWalk           Sex  \\\n",
       "count  70692.000000  70692.000000  70692.000000  70692.000000  70692.000000   \n",
       "mean       2.837082      3.752037      5.810417      0.252730      0.456997   \n",
       "std        1.113565      8.155627     10.062261      0.434581      0.498151   \n",
       "min        1.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        2.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        3.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        4.000000      2.000000      6.000000      1.000000      1.000000   \n",
       "max        5.000000     30.000000     30.000000      1.000000      1.000000   \n",
       "\n",
       "                Age     Education        Income  \n",
       "count  70692.000000  70692.000000  70692.000000  \n",
       "mean       8.584055      4.920953      5.698311  \n",
       "std        2.852153      1.029081      2.175196  \n",
       "min        1.000000      1.000000      1.000000  \n",
       "25%        7.000000      4.000000      4.000000  \n",
       "50%        9.000000      5.000000      6.000000  \n",
       "75%       11.000000      6.000000      8.000000  \n",
       "max       13.000000      6.000000      8.000000  \n",
       "\n",
       "[8 rows x 22 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Describing the dataset\n",
    "diabetes.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting info about each feature type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 70692 entries, 0 to 70691\n",
      "Data columns (total 22 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   Diabetes_binary       70692 non-null  float64\n",
      " 1   HighBP                70692 non-null  float64\n",
      " 2   HighChol              70692 non-null  float64\n",
      " 3   CholCheck             70692 non-null  float64\n",
      " 4   BMI                   70692 non-null  float64\n",
      " 5   Smoker                70692 non-null  float64\n",
      " 6   Stroke                70692 non-null  float64\n",
      " 7   HeartDiseaseorAttack  70692 non-null  float64\n",
      " 8   PhysActivity          70692 non-null  float64\n",
      " 9   Fruits                70692 non-null  float64\n",
      " 10  Veggies               70692 non-null  float64\n",
      " 11  HvyAlcoholConsump     70692 non-null  float64\n",
      " 12  AnyHealthcare         70692 non-null  float64\n",
      " 13  NoDocbcCost           70692 non-null  float64\n",
      " 14  GenHlth               70692 non-null  float64\n",
      " 15  MentHlth              70692 non-null  float64\n",
      " 16  PhysHlth              70692 non-null  float64\n",
      " 17  DiffWalk              70692 non-null  float64\n",
      " 18  Sex                   70692 non-null  float64\n",
      " 19  Age                   70692 non-null  float64\n",
      " 20  Education             70692 non-null  float64\n",
      " 21  Income                70692 non-null  float64\n",
      "dtypes: float64(22)\n",
      "memory usage: 11.9 MB\n"
     ]
    }
   ],
   "source": [
    "# info about the dataset\n",
    "diabetes.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Preliminary Correlation Matrix of all the features in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes_binary</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>...</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Diabetes_binary</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.381516</td>\n",
       "      <td>0.289213</td>\n",
       "      <td>0.115382</td>\n",
       "      <td>0.293373</td>\n",
       "      <td>0.085999</td>\n",
       "      <td>0.125427</td>\n",
       "      <td>0.211523</td>\n",
       "      <td>-0.158666</td>\n",
       "      <td>-0.054077</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023191</td>\n",
       "      <td>0.040977</td>\n",
       "      <td>0.407612</td>\n",
       "      <td>0.087029</td>\n",
       "      <td>0.213081</td>\n",
       "      <td>0.272646</td>\n",
       "      <td>0.044413</td>\n",
       "      <td>0.278738</td>\n",
       "      <td>-0.170481</td>\n",
       "      <td>-0.224449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HighBP</th>\n",
       "      <td>0.381516</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.316515</td>\n",
       "      <td>0.103283</td>\n",
       "      <td>0.241019</td>\n",
       "      <td>0.087438</td>\n",
       "      <td>0.129060</td>\n",
       "      <td>0.210750</td>\n",
       "      <td>-0.136102</td>\n",
       "      <td>-0.040852</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035764</td>\n",
       "      <td>0.026517</td>\n",
       "      <td>0.320540</td>\n",
       "      <td>0.064294</td>\n",
       "      <td>0.173922</td>\n",
       "      <td>0.234784</td>\n",
       "      <td>0.040819</td>\n",
       "      <td>0.338132</td>\n",
       "      <td>-0.141643</td>\n",
       "      <td>-0.187657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HighChol</th>\n",
       "      <td>0.289213</td>\n",
       "      <td>0.316515</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.085981</td>\n",
       "      <td>0.131309</td>\n",
       "      <td>0.093398</td>\n",
       "      <td>0.099786</td>\n",
       "      <td>0.181187</td>\n",
       "      <td>-0.090453</td>\n",
       "      <td>-0.047384</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031532</td>\n",
       "      <td>0.033199</td>\n",
       "      <td>0.237778</td>\n",
       "      <td>0.083881</td>\n",
       "      <td>0.142610</td>\n",
       "      <td>0.162043</td>\n",
       "      <td>0.017324</td>\n",
       "      <td>0.240338</td>\n",
       "      <td>-0.084386</td>\n",
       "      <td>-0.107777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CholCheck</th>\n",
       "      <td>0.115382</td>\n",
       "      <td>0.103283</td>\n",
       "      <td>0.085981</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.045648</td>\n",
       "      <td>-0.004331</td>\n",
       "      <td>0.022529</td>\n",
       "      <td>0.043497</td>\n",
       "      <td>-0.008249</td>\n",
       "      <td>0.017384</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106800</td>\n",
       "      <td>-0.062669</td>\n",
       "      <td>0.059213</td>\n",
       "      <td>-0.010660</td>\n",
       "      <td>0.034540</td>\n",
       "      <td>0.044430</td>\n",
       "      <td>-0.007991</td>\n",
       "      <td>0.101743</td>\n",
       "      <td>-0.008695</td>\n",
       "      <td>0.007550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMI</th>\n",
       "      <td>0.293373</td>\n",
       "      <td>0.241019</td>\n",
       "      <td>0.131309</td>\n",
       "      <td>0.045648</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.011551</td>\n",
       "      <td>0.022931</td>\n",
       "      <td>0.060355</td>\n",
       "      <td>-0.170936</td>\n",
       "      <td>-0.084505</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013417</td>\n",
       "      <td>0.065832</td>\n",
       "      <td>0.267888</td>\n",
       "      <td>0.104682</td>\n",
       "      <td>0.161862</td>\n",
       "      <td>0.246094</td>\n",
       "      <td>0.000827</td>\n",
       "      <td>-0.038648</td>\n",
       "      <td>-0.100233</td>\n",
       "      <td>-0.124878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Smoker</th>\n",
       "      <td>0.085999</td>\n",
       "      <td>0.087438</td>\n",
       "      <td>0.093398</td>\n",
       "      <td>-0.004331</td>\n",
       "      <td>0.011551</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.064658</td>\n",
       "      <td>0.124418</td>\n",
       "      <td>-0.079823</td>\n",
       "      <td>-0.074811</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012939</td>\n",
       "      <td>0.035799</td>\n",
       "      <td>0.152416</td>\n",
       "      <td>0.091257</td>\n",
       "      <td>0.120698</td>\n",
       "      <td>0.119789</td>\n",
       "      <td>0.112125</td>\n",
       "      <td>0.105424</td>\n",
       "      <td>-0.140966</td>\n",
       "      <td>-0.104725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stroke</th>\n",
       "      <td>0.125427</td>\n",
       "      <td>0.129060</td>\n",
       "      <td>0.099786</td>\n",
       "      <td>0.022529</td>\n",
       "      <td>0.022931</td>\n",
       "      <td>0.064658</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.223394</td>\n",
       "      <td>-0.079985</td>\n",
       "      <td>-0.008996</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006484</td>\n",
       "      <td>0.036198</td>\n",
       "      <td>0.189447</td>\n",
       "      <td>0.087303</td>\n",
       "      <td>0.164488</td>\n",
       "      <td>0.192266</td>\n",
       "      <td>0.003822</td>\n",
       "      <td>0.123879</td>\n",
       "      <td>-0.073926</td>\n",
       "      <td>-0.136577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <td>0.211523</td>\n",
       "      <td>0.210750</td>\n",
       "      <td>0.181187</td>\n",
       "      <td>0.043497</td>\n",
       "      <td>0.060355</td>\n",
       "      <td>0.124418</td>\n",
       "      <td>0.223394</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.098223</td>\n",
       "      <td>-0.019436</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015687</td>\n",
       "      <td>0.036029</td>\n",
       "      <td>0.275868</td>\n",
       "      <td>0.075057</td>\n",
       "      <td>0.198416</td>\n",
       "      <td>0.232611</td>\n",
       "      <td>0.098161</td>\n",
       "      <td>0.221878</td>\n",
       "      <td>-0.096559</td>\n",
       "      <td>-0.146748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhysActivity</th>\n",
       "      <td>-0.158666</td>\n",
       "      <td>-0.136102</td>\n",
       "      <td>-0.090453</td>\n",
       "      <td>-0.008249</td>\n",
       "      <td>-0.170936</td>\n",
       "      <td>-0.079823</td>\n",
       "      <td>-0.079985</td>\n",
       "      <td>-0.098223</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.133813</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027089</td>\n",
       "      <td>-0.063302</td>\n",
       "      <td>-0.273548</td>\n",
       "      <td>-0.130090</td>\n",
       "      <td>-0.234500</td>\n",
       "      <td>-0.276868</td>\n",
       "      <td>0.051753</td>\n",
       "      <td>-0.100753</td>\n",
       "      <td>0.190271</td>\n",
       "      <td>0.196551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fruits</th>\n",
       "      <td>-0.054077</td>\n",
       "      <td>-0.040852</td>\n",
       "      <td>-0.047384</td>\n",
       "      <td>0.017384</td>\n",
       "      <td>-0.084505</td>\n",
       "      <td>-0.074811</td>\n",
       "      <td>-0.008996</td>\n",
       "      <td>-0.019436</td>\n",
       "      <td>0.133813</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029385</td>\n",
       "      <td>-0.045843</td>\n",
       "      <td>-0.098687</td>\n",
       "      <td>-0.062102</td>\n",
       "      <td>-0.048572</td>\n",
       "      <td>-0.050784</td>\n",
       "      <td>-0.088723</td>\n",
       "      <td>0.061096</td>\n",
       "      <td>0.098715</td>\n",
       "      <td>0.079009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Veggies</th>\n",
       "      <td>-0.079293</td>\n",
       "      <td>-0.066624</td>\n",
       "      <td>-0.042836</td>\n",
       "      <td>0.000349</td>\n",
       "      <td>-0.056528</td>\n",
       "      <td>-0.029926</td>\n",
       "      <td>-0.047601</td>\n",
       "      <td>-0.036315</td>\n",
       "      <td>0.149322</td>\n",
       "      <td>0.238605</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029152</td>\n",
       "      <td>-0.037146</td>\n",
       "      <td>-0.115795</td>\n",
       "      <td>-0.052359</td>\n",
       "      <td>-0.066896</td>\n",
       "      <td>-0.084072</td>\n",
       "      <td>-0.052604</td>\n",
       "      <td>-0.018893</td>\n",
       "      <td>0.152512</td>\n",
       "      <td>0.154899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HvyAlcoholConsump</th>\n",
       "      <td>-0.094853</td>\n",
       "      <td>-0.027030</td>\n",
       "      <td>-0.025443</td>\n",
       "      <td>-0.027146</td>\n",
       "      <td>-0.058232</td>\n",
       "      <td>0.077835</td>\n",
       "      <td>-0.023395</td>\n",
       "      <td>-0.037130</td>\n",
       "      <td>0.019111</td>\n",
       "      <td>-0.033246</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013484</td>\n",
       "      <td>0.009683</td>\n",
       "      <td>-0.058796</td>\n",
       "      <td>0.015626</td>\n",
       "      <td>-0.036257</td>\n",
       "      <td>-0.049294</td>\n",
       "      <td>0.014164</td>\n",
       "      <td>-0.057705</td>\n",
       "      <td>0.036279</td>\n",
       "      <td>0.064095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <td>0.023191</td>\n",
       "      <td>0.035764</td>\n",
       "      <td>0.031532</td>\n",
       "      <td>0.106800</td>\n",
       "      <td>-0.013417</td>\n",
       "      <td>-0.012939</td>\n",
       "      <td>0.006484</td>\n",
       "      <td>0.015687</td>\n",
       "      <td>0.027089</td>\n",
       "      <td>0.029385</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.221658</td>\n",
       "      <td>-0.033060</td>\n",
       "      <td>-0.049850</td>\n",
       "      <td>-0.003285</td>\n",
       "      <td>0.008113</td>\n",
       "      <td>-0.006562</td>\n",
       "      <td>0.136975</td>\n",
       "      <td>0.106601</td>\n",
       "      <td>0.130492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <td>0.040977</td>\n",
       "      <td>0.026517</td>\n",
       "      <td>0.033199</td>\n",
       "      <td>-0.062669</td>\n",
       "      <td>0.065832</td>\n",
       "      <td>0.035799</td>\n",
       "      <td>0.036198</td>\n",
       "      <td>0.036029</td>\n",
       "      <td>-0.063302</td>\n",
       "      <td>-0.045843</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.221658</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.169515</td>\n",
       "      <td>0.193877</td>\n",
       "      <td>0.157451</td>\n",
       "      <td>0.127111</td>\n",
       "      <td>-0.048187</td>\n",
       "      <td>-0.129839</td>\n",
       "      <td>-0.096989</td>\n",
       "      <td>-0.198171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GenHlth</th>\n",
       "      <td>0.407612</td>\n",
       "      <td>0.320540</td>\n",
       "      <td>0.237778</td>\n",
       "      <td>0.059213</td>\n",
       "      <td>0.267888</td>\n",
       "      <td>0.152416</td>\n",
       "      <td>0.189447</td>\n",
       "      <td>0.275868</td>\n",
       "      <td>-0.273548</td>\n",
       "      <td>-0.098687</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033060</td>\n",
       "      <td>0.169515</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.315077</td>\n",
       "      <td>0.552757</td>\n",
       "      <td>0.476639</td>\n",
       "      <td>-0.014555</td>\n",
       "      <td>0.155624</td>\n",
       "      <td>-0.285420</td>\n",
       "      <td>-0.382969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MentHlth</th>\n",
       "      <td>0.087029</td>\n",
       "      <td>0.064294</td>\n",
       "      <td>0.083881</td>\n",
       "      <td>-0.010660</td>\n",
       "      <td>0.104682</td>\n",
       "      <td>0.091257</td>\n",
       "      <td>0.087303</td>\n",
       "      <td>0.075057</td>\n",
       "      <td>-0.130090</td>\n",
       "      <td>-0.062102</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.049850</td>\n",
       "      <td>0.193877</td>\n",
       "      <td>0.315077</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.380272</td>\n",
       "      <td>0.251489</td>\n",
       "      <td>-0.089204</td>\n",
       "      <td>-0.101746</td>\n",
       "      <td>-0.107005</td>\n",
       "      <td>-0.219070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhysHlth</th>\n",
       "      <td>0.213081</td>\n",
       "      <td>0.173922</td>\n",
       "      <td>0.142610</td>\n",
       "      <td>0.034540</td>\n",
       "      <td>0.161862</td>\n",
       "      <td>0.120698</td>\n",
       "      <td>0.164488</td>\n",
       "      <td>0.198416</td>\n",
       "      <td>-0.234500</td>\n",
       "      <td>-0.048572</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003285</td>\n",
       "      <td>0.157451</td>\n",
       "      <td>0.552757</td>\n",
       "      <td>0.380272</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.487976</td>\n",
       "      <td>-0.045957</td>\n",
       "      <td>0.084852</td>\n",
       "      <td>-0.159317</td>\n",
       "      <td>-0.279326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DiffWalk</th>\n",
       "      <td>0.272646</td>\n",
       "      <td>0.234784</td>\n",
       "      <td>0.162043</td>\n",
       "      <td>0.044430</td>\n",
       "      <td>0.246094</td>\n",
       "      <td>0.119789</td>\n",
       "      <td>0.192266</td>\n",
       "      <td>0.232611</td>\n",
       "      <td>-0.276868</td>\n",
       "      <td>-0.050784</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008113</td>\n",
       "      <td>0.127111</td>\n",
       "      <td>0.476639</td>\n",
       "      <td>0.251489</td>\n",
       "      <td>0.487976</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.082248</td>\n",
       "      <td>0.195265</td>\n",
       "      <td>-0.202590</td>\n",
       "      <td>-0.343245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>0.044413</td>\n",
       "      <td>0.040819</td>\n",
       "      <td>0.017324</td>\n",
       "      <td>-0.007991</td>\n",
       "      <td>0.000827</td>\n",
       "      <td>0.112125</td>\n",
       "      <td>0.003822</td>\n",
       "      <td>0.098161</td>\n",
       "      <td>0.051753</td>\n",
       "      <td>-0.088723</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006562</td>\n",
       "      <td>-0.048187</td>\n",
       "      <td>-0.014555</td>\n",
       "      <td>-0.089204</td>\n",
       "      <td>-0.045957</td>\n",
       "      <td>-0.082248</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.002315</td>\n",
       "      <td>0.043564</td>\n",
       "      <td>0.159654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0.278738</td>\n",
       "      <td>0.338132</td>\n",
       "      <td>0.240338</td>\n",
       "      <td>0.101743</td>\n",
       "      <td>-0.038648</td>\n",
       "      <td>0.105424</td>\n",
       "      <td>0.123879</td>\n",
       "      <td>0.221878</td>\n",
       "      <td>-0.100753</td>\n",
       "      <td>0.061096</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136975</td>\n",
       "      <td>-0.129839</td>\n",
       "      <td>0.155624</td>\n",
       "      <td>-0.101746</td>\n",
       "      <td>0.084852</td>\n",
       "      <td>0.195265</td>\n",
       "      <td>-0.002315</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.107127</td>\n",
       "      <td>-0.130140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Education</th>\n",
       "      <td>-0.170481</td>\n",
       "      <td>-0.141643</td>\n",
       "      <td>-0.084386</td>\n",
       "      <td>-0.008695</td>\n",
       "      <td>-0.100233</td>\n",
       "      <td>-0.140966</td>\n",
       "      <td>-0.073926</td>\n",
       "      <td>-0.096559</td>\n",
       "      <td>0.190271</td>\n",
       "      <td>0.098715</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106601</td>\n",
       "      <td>-0.096989</td>\n",
       "      <td>-0.285420</td>\n",
       "      <td>-0.107005</td>\n",
       "      <td>-0.159317</td>\n",
       "      <td>-0.202590</td>\n",
       "      <td>0.043564</td>\n",
       "      <td>-0.107127</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.460565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Income</th>\n",
       "      <td>-0.224449</td>\n",
       "      <td>-0.187657</td>\n",
       "      <td>-0.107777</td>\n",
       "      <td>0.007550</td>\n",
       "      <td>-0.124878</td>\n",
       "      <td>-0.104725</td>\n",
       "      <td>-0.136577</td>\n",
       "      <td>-0.146748</td>\n",
       "      <td>0.196551</td>\n",
       "      <td>0.079009</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130492</td>\n",
       "      <td>-0.198171</td>\n",
       "      <td>-0.382969</td>\n",
       "      <td>-0.219070</td>\n",
       "      <td>-0.279326</td>\n",
       "      <td>-0.343245</td>\n",
       "      <td>0.159654</td>\n",
       "      <td>-0.130140</td>\n",
       "      <td>0.460565</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Diabetes_binary    HighBP  HighChol  CholCheck  \\\n",
       "Diabetes_binary              1.000000  0.381516  0.289213   0.115382   \n",
       "HighBP                       0.381516  1.000000  0.316515   0.103283   \n",
       "HighChol                     0.289213  0.316515  1.000000   0.085981   \n",
       "CholCheck                    0.115382  0.103283  0.085981   1.000000   \n",
       "BMI                          0.293373  0.241019  0.131309   0.045648   \n",
       "Smoker                       0.085999  0.087438  0.093398  -0.004331   \n",
       "Stroke                       0.125427  0.129060  0.099786   0.022529   \n",
       "HeartDiseaseorAttack         0.211523  0.210750  0.181187   0.043497   \n",
       "PhysActivity                -0.158666 -0.136102 -0.090453  -0.008249   \n",
       "Fruits                      -0.054077 -0.040852 -0.047384   0.017384   \n",
       "Veggies                     -0.079293 -0.066624 -0.042836   0.000349   \n",
       "HvyAlcoholConsump           -0.094853 -0.027030 -0.025443  -0.027146   \n",
       "AnyHealthcare                0.023191  0.035764  0.031532   0.106800   \n",
       "NoDocbcCost                  0.040977  0.026517  0.033199  -0.062669   \n",
       "GenHlth                      0.407612  0.320540  0.237778   0.059213   \n",
       "MentHlth                     0.087029  0.064294  0.083881  -0.010660   \n",
       "PhysHlth                     0.213081  0.173922  0.142610   0.034540   \n",
       "DiffWalk                     0.272646  0.234784  0.162043   0.044430   \n",
       "Sex                          0.044413  0.040819  0.017324  -0.007991   \n",
       "Age                          0.278738  0.338132  0.240338   0.101743   \n",
       "Education                   -0.170481 -0.141643 -0.084386  -0.008695   \n",
       "Income                      -0.224449 -0.187657 -0.107777   0.007550   \n",
       "\n",
       "                           BMI    Smoker    Stroke  HeartDiseaseorAttack  \\\n",
       "Diabetes_binary       0.293373  0.085999  0.125427              0.211523   \n",
       "HighBP                0.241019  0.087438  0.129060              0.210750   \n",
       "HighChol              0.131309  0.093398  0.099786              0.181187   \n",
       "CholCheck             0.045648 -0.004331  0.022529              0.043497   \n",
       "BMI                   1.000000  0.011551  0.022931              0.060355   \n",
       "Smoker                0.011551  1.000000  0.064658              0.124418   \n",
       "Stroke                0.022931  0.064658  1.000000              0.223394   \n",
       "HeartDiseaseorAttack  0.060355  0.124418  0.223394              1.000000   \n",
       "PhysActivity         -0.170936 -0.079823 -0.079985             -0.098223   \n",
       "Fruits               -0.084505 -0.074811 -0.008996             -0.019436   \n",
       "Veggies              -0.056528 -0.029926 -0.047601             -0.036315   \n",
       "HvyAlcoholConsump    -0.058232  0.077835 -0.023395             -0.037130   \n",
       "AnyHealthcare        -0.013417 -0.012939  0.006484              0.015687   \n",
       "NoDocbcCost           0.065832  0.035799  0.036198              0.036029   \n",
       "GenHlth               0.267888  0.152416  0.189447              0.275868   \n",
       "MentHlth              0.104682  0.091257  0.087303              0.075057   \n",
       "PhysHlth              0.161862  0.120698  0.164488              0.198416   \n",
       "DiffWalk              0.246094  0.119789  0.192266              0.232611   \n",
       "Sex                   0.000827  0.112125  0.003822              0.098161   \n",
       "Age                  -0.038648  0.105424  0.123879              0.221878   \n",
       "Education            -0.100233 -0.140966 -0.073926             -0.096559   \n",
       "Income               -0.124878 -0.104725 -0.136577             -0.146748   \n",
       "\n",
       "                      PhysActivity    Fruits  ...  AnyHealthcare  NoDocbcCost  \\\n",
       "Diabetes_binary          -0.158666 -0.054077  ...       0.023191     0.040977   \n",
       "HighBP                   -0.136102 -0.040852  ...       0.035764     0.026517   \n",
       "HighChol                 -0.090453 -0.047384  ...       0.031532     0.033199   \n",
       "CholCheck                -0.008249  0.017384  ...       0.106800    -0.062669   \n",
       "BMI                      -0.170936 -0.084505  ...      -0.013417     0.065832   \n",
       "Smoker                   -0.079823 -0.074811  ...      -0.012939     0.035799   \n",
       "Stroke                   -0.079985 -0.008996  ...       0.006484     0.036198   \n",
       "HeartDiseaseorAttack     -0.098223 -0.019436  ...       0.015687     0.036029   \n",
       "PhysActivity              1.000000  0.133813  ...       0.027089    -0.063302   \n",
       "Fruits                    0.133813  1.000000  ...       0.029385    -0.045843   \n",
       "Veggies                   0.149322  0.238605  ...       0.029152    -0.037146   \n",
       "HvyAlcoholConsump         0.019111 -0.033246  ...      -0.013484     0.009683   \n",
       "AnyHealthcare             0.027089  0.029385  ...       1.000000    -0.221658   \n",
       "NoDocbcCost              -0.063302 -0.045843  ...      -0.221658     1.000000   \n",
       "GenHlth                  -0.273548 -0.098687  ...      -0.033060     0.169515   \n",
       "MentHlth                 -0.130090 -0.062102  ...      -0.049850     0.193877   \n",
       "PhysHlth                 -0.234500 -0.048572  ...      -0.003285     0.157451   \n",
       "DiffWalk                 -0.276868 -0.050784  ...       0.008113     0.127111   \n",
       "Sex                       0.051753 -0.088723  ...      -0.006562    -0.048187   \n",
       "Age                      -0.100753  0.061096  ...       0.136975    -0.129839   \n",
       "Education                 0.190271  0.098715  ...       0.106601    -0.096989   \n",
       "Income                    0.196551  0.079009  ...       0.130492    -0.198171   \n",
       "\n",
       "                       GenHlth  MentHlth  PhysHlth  DiffWalk       Sex  \\\n",
       "Diabetes_binary       0.407612  0.087029  0.213081  0.272646  0.044413   \n",
       "HighBP                0.320540  0.064294  0.173922  0.234784  0.040819   \n",
       "HighChol              0.237778  0.083881  0.142610  0.162043  0.017324   \n",
       "CholCheck             0.059213 -0.010660  0.034540  0.044430 -0.007991   \n",
       "BMI                   0.267888  0.104682  0.161862  0.246094  0.000827   \n",
       "Smoker                0.152416  0.091257  0.120698  0.119789  0.112125   \n",
       "Stroke                0.189447  0.087303  0.164488  0.192266  0.003822   \n",
       "HeartDiseaseorAttack  0.275868  0.075057  0.198416  0.232611  0.098161   \n",
       "PhysActivity         -0.273548 -0.130090 -0.234500 -0.276868  0.051753   \n",
       "Fruits               -0.098687 -0.062102 -0.048572 -0.050784 -0.088723   \n",
       "Veggies              -0.115795 -0.052359 -0.066896 -0.084072 -0.052604   \n",
       "HvyAlcoholConsump    -0.058796  0.015626 -0.036257 -0.049294  0.014164   \n",
       "AnyHealthcare        -0.033060 -0.049850 -0.003285  0.008113 -0.006562   \n",
       "NoDocbcCost           0.169515  0.193877  0.157451  0.127111 -0.048187   \n",
       "GenHlth               1.000000  0.315077  0.552757  0.476639 -0.014555   \n",
       "MentHlth              0.315077  1.000000  0.380272  0.251489 -0.089204   \n",
       "PhysHlth              0.552757  0.380272  1.000000  0.487976 -0.045957   \n",
       "DiffWalk              0.476639  0.251489  0.487976  1.000000 -0.082248   \n",
       "Sex                  -0.014555 -0.089204 -0.045957 -0.082248  1.000000   \n",
       "Age                   0.155624 -0.101746  0.084852  0.195265 -0.002315   \n",
       "Education            -0.285420 -0.107005 -0.159317 -0.202590  0.043564   \n",
       "Income               -0.382969 -0.219070 -0.279326 -0.343245  0.159654   \n",
       "\n",
       "                           Age  Education    Income  \n",
       "Diabetes_binary       0.278738  -0.170481 -0.224449  \n",
       "HighBP                0.338132  -0.141643 -0.187657  \n",
       "HighChol              0.240338  -0.084386 -0.107777  \n",
       "CholCheck             0.101743  -0.008695  0.007550  \n",
       "BMI                  -0.038648  -0.100233 -0.124878  \n",
       "Smoker                0.105424  -0.140966 -0.104725  \n",
       "Stroke                0.123879  -0.073926 -0.136577  \n",
       "HeartDiseaseorAttack  0.221878  -0.096559 -0.146748  \n",
       "PhysActivity         -0.100753   0.190271  0.196551  \n",
       "Fruits                0.061096   0.098715  0.079009  \n",
       "Veggies              -0.018893   0.152512  0.154899  \n",
       "HvyAlcoholConsump    -0.057705   0.036279  0.064095  \n",
       "AnyHealthcare         0.136975   0.106601  0.130492  \n",
       "NoDocbcCost          -0.129839  -0.096989 -0.198171  \n",
       "GenHlth               0.155624  -0.285420 -0.382969  \n",
       "MentHlth             -0.101746  -0.107005 -0.219070  \n",
       "PhysHlth              0.084852  -0.159317 -0.279326  \n",
       "DiffWalk              0.195265  -0.202590 -0.343245  \n",
       "Sex                  -0.002315   0.043564  0.159654  \n",
       "Age                   1.000000  -0.107127 -0.130140  \n",
       "Education            -0.107127   1.000000  0.460565  \n",
       "Income               -0.130140   0.460565  1.000000  \n",
       "\n",
       "[22 rows x 22 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above, we see that some columns have very low correlations to the target column, **Diabetes_binary**. In particular, the *'Smoker'*, *'Sex'*, *'Fruits'*, *'Veggies'*, *'NoDocbcCost'*, *'MentHlth'*, *'AnyHealthcare'*, and *'HvyAlcoholConsump'* fields had low correlations, so we can assume that they will not add any benefit to our models and will only serve to lower the accuracy. So we decided to take these fields out in our final analysis. \n",
    "\n",
    "To give some background, we initially had decided to remove features that either relied heavily on subjective answers or weren't as important to defining if someone had diabetes. These fields were *'NoDocbcCost'*, *'GenHlth'*, *'MentHlth'*, *'PhysHlth'*, *'DiffWalk'*, *'AnyHealthcare'*, *'HvyAlcoholConsump'*. In the following code, comments will be indicated for our initial development, and can be commented out for different results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes_binary</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Diabetes_binary  HighBP  HighChol  CholCheck   BMI  Stroke  \\\n",
       "0              0.0     1.0       0.0        1.0  26.0     0.0   \n",
       "1              0.0     1.0       1.0        1.0  26.0     1.0   \n",
       "2              0.0     0.0       0.0        1.0  26.0     0.0   \n",
       "3              0.0     1.0       1.0        1.0  28.0     0.0   \n",
       "4              0.0     0.0       0.0        1.0  29.0     0.0   \n",
       "\n",
       "   HeartDiseaseorAttack  PhysActivity  GenHlth  PhysHlth  DiffWalk   Age  \\\n",
       "0                   0.0           1.0      3.0      30.0       0.0   4.0   \n",
       "1                   0.0           0.0      3.0       0.0       0.0  12.0   \n",
       "2                   0.0           1.0      1.0      10.0       0.0  13.0   \n",
       "3                   0.0           1.0      3.0       3.0       0.0  11.0   \n",
       "4                   0.0           1.0      2.0       0.0       0.0   8.0   \n",
       "\n",
       "   Education  Income  \n",
       "0        6.0     8.0  \n",
       "1        6.0     8.0  \n",
       "2        6.0     8.0  \n",
       "3        6.0     8.0  \n",
       "4        5.0     8.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping columns that may not be helpful for analysis, heavy alcohol consumption removed since because it is self reported it may not be as honest\n",
    "\n",
    "### INIT DEV\n",
    "#columns_to_drop = ['NoDocbcCost', 'GenHlth', 'MentHlth', 'PhysHlth', 'DiffWalk', 'AnyHealthcare', 'HvyAlcoholConsump']\n",
    "columns_to_drop = ['Smoker', 'Sex', 'Fruits', 'Veggies', 'NoDocbcCost', 'MentHlth', 'AnyHealthcare', 'HvyAlcoholConsump']\n",
    "\n",
    "diabetes_df = diabetes.copy()\n",
    "diabetes_df = diabetes_df.drop(columns=columns_to_drop)\n",
    "diabetes_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Grouping (using functions)\n",
    "\n",
    "We wanted to reduce the amount of groups for the following fields, since they had a few too many groups:\n",
    "1. Age\n",
    "2. Education\n",
    "3. Income\n",
    "4. BMI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age Category Recap:\n",
    "1. Age 18 to 24\n",
    "2. Age 25 to 29\n",
    "3. Age 30 to 34\n",
    "4. Age 35 to 39\n",
    "5. Age 40 to 44\n",
    "6. Age 45 to 49\n",
    "7. Age 50 to 54\n",
    "8. Age 55 to 59\n",
    "9. Age 60 to 64\n",
    "10. Age 65 to 69\n",
    "11. Age 70 to 74\n",
    "12. Age 75 to 79\n",
    "13. Age 80 or older\n",
    "\n",
    "We initially sought to categorize the ages to a smaller subset and group them within 5 groups since we wanted to keep the groups equal. In particular our groupings would have gone as follows:\n",
    "1. 18-34 (Grouping 1-3)\n",
    "2. 35-49 (Grouping 4-6)\n",
    "3. 50-64 (Grouping 7-9)\n",
    "4. 65-79 (Grouping 10-12)\n",
    "5. 80+ (Group 13 by itself)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age\n",
       "10.0    10856\n",
       "9.0     10112\n",
       "8.0      8603\n",
       "11.0     8044\n",
       "7.0      6872\n",
       "13.0     5426\n",
       "12.0     5394\n",
       "6.0      4648\n",
       "5.0      3520\n",
       "4.0      2793\n",
       "3.0      2049\n",
       "2.0      1396\n",
       "1.0       979\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_df['Age'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The age groups that were most represented were between the ages of 60-69"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to replace the existing data with our own age groupings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_replace(x):\n",
    "    if x >= 1 and x <= 3:\n",
    "        return \"Age 18-34\"\n",
    "    elif x > 3 and x <= 6:\n",
    "        return \"Age 35-49\"\n",
    "    elif x > 6 and x <= 9:\n",
    "        return \"Age 50-64\"\n",
    "    elif x > 9 and x <= 12:\n",
    "        return \"Age 65-79\"\n",
    "    elif x > 12:\n",
    "        return \"Age 80+\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then replace the data as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_df['Age'] = diabetes_df['Age'].apply(age_replace)\n",
    "diabetes_df['Age'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. EDUCATION\n",
    "\n",
    "#### Education Recap\n",
    "1. Never attended school or only kindergarten\n",
    "2. Grades 1 through 8 (Elementary)\n",
    "3. Grades 9 through 11 (Some high school)\n",
    "4. Grade 12 or GED (High school graduate)\n",
    "5. College 1 year to 3 years (Some college or technical school)\n",
    "6. College 4 years or more (College graduate)\n",
    "\n",
    "#### split between : higher vs non-higher edu, 5-6 higher, 1-4 lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edu_replace(x):\n",
    "    if x >= 1 and x <= 4:\n",
    "        return \"Lower Education\"\n",
    "    elif x > 4:\n",
    "        return \"Higher Education\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Education\n",
       "Higher Education    46050\n",
       "Lower Education     24642\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_df['Education'] = diabetes_df['Education'].apply(edu_replace)\n",
    "diabetes_df['Education'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INCOME\n",
    "1. Less than $10,000\n",
    "2. Less than $15,000 ($10,000 to less than $15,000)\n",
    "3. Less than $20,000 ($15,000 to less than $20,000)\n",
    "4. Less than $25,000 ($20,000 to less than $25,000)\n",
    "5. Less than $35,000 ($25,000 to less than $35,000)\n",
    "6. Less than $50,000 ($35,000 to less than $50,000)\n",
    "7. Less than $75,000 ($50,000 to less than $75,000)\n",
    "8. $75,000 or more\n",
    "\n",
    "#### group 1-3, 4-7, 8 by itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Income\n",
       "8.0    20646\n",
       "7.0    11425\n",
       "6.0    10287\n",
       "5.0     8010\n",
       "4.0     6658\n",
       "3.0     5557\n",
       "2.0     4498\n",
       "1.0     3611\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_df['Income'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def income_replace(x):\n",
    "#     if x >= 1 and x <= 3:\n",
    "#         return \"Less than $20,000\"\n",
    "#     elif x > 3 and x <= 7:\n",
    "#         return \"Between $20,000 and $75,000\"\n",
    "#     elif x > 7:\n",
    "#         return \"More than $75,000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diabetes_df['Income'] = diabetes_df['Income'].apply(income_replace)\n",
    "# diabetes_df['Income'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BMI_classification(x):\n",
    "    if x < 18.5:\n",
    "        return \"Underweight\"\n",
    "    elif x > 18.5 and x <=24.9:\n",
    "        return \"Normal\"\n",
    "    elif x > 24.9 and x <= 29.9:\n",
    "        return \"Overweight\"\n",
    "    elif x > 29.9 and x <= 34.9:\n",
    "        return \"Obesity 1\"\n",
    "    elif x > 34.9 and x <= 39.9:\n",
    "        return \"Obesity 2\"\n",
    "    elif x > 39.9:\n",
    "        return \"Obesity 3\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BMI\n",
       "Overweight     24135\n",
       "Obesity 1      17301\n",
       "Normal         14460\n",
       "Obesity 2       8112\n",
       "Obesity 3       6031\n",
       "Underweight      653\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_df['BMI'] = diabetes_df['BMI'].apply(BMI_classification)\n",
    "diabetes_df['BMI'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin Splitting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = diabetes_df.drop(columns='Diabetes_binary')\n",
    "y = diabetes_df['Diabetes_binary']\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, random_state=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding Categorical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BMI    0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "BMI    0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create encoder and fit\n",
    "encode_BMI = OrdinalEncoder(categories=[['Underweight', 'Normal', 'Overweight', 'Obesity 1', 'Obesity 2', 'Obesity 3']], handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "encode_BMI.fit(x_train['BMI'].values.reshape(-1,1))\n",
    "encode_BMI_train = encode_BMI.transform(x_train['BMI'].values.reshape(-1, 1))\n",
    "encode_BMI_test = encode_BMI.transform(x_test['BMI'].values.reshape(-1, 1))\n",
    "\n",
    "# create the df\n",
    "encode_BMI_df_train = pd.DataFrame(encode_BMI_train, columns=['BMI'])\n",
    "encode_BMI_df_test = pd.DataFrame(encode_BMI_test, columns=['BMI'])\n",
    "encode_BMI_df_train.head()\n",
    "display(encode_BMI_df_train.isna().sum())\n",
    "display(encode_BMI_df_test.isna().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create encoder and fit\n",
    "# encode_income = OrdinalEncoder(categories=[['Less than $20,000','Between $20,000 and $75,000','More than $75,000']], handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "# encode_income.fit(x_train['Income'].values.reshape(-1,1))\n",
    "# encode_income_train = encode_income.transform(x_train['Income'].values.reshape(-1, 1))\n",
    "# encode_income_test = encode_income.transform(x_test['Income'].values.reshape(-1, 1))\n",
    "\n",
    "# # create the df\n",
    "# encode_income_df_train = pd.DataFrame(encode_income_train, columns=['Income'])\n",
    "# encode_income_df_test = pd.DataFrame(encode_income_test, columns=['Income'])\n",
    "# display(encode_income_df_train.isna().sum())\n",
    "# display(encode_income_df_test.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Education    0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Education    0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create encoder and fit \n",
    "encode_educ = OrdinalEncoder(categories=[['Lower Education', 'Higher Education']], handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "encode_educ.fit(x_train['Education'].values.reshape(-1,1))\n",
    "encode_educ_train = encode_educ.transform(x_train['Education'].values.reshape(-1, 1))\n",
    "encode_educ_test = encode_educ.transform(x_test['Education'].values.reshape(-1, 1))\n",
    "\n",
    "# create the df\n",
    "encode_educ_df_train = pd.DataFrame(encode_educ_train, columns=['Education'])\n",
    "encode_educ_df_test = pd.DataFrame(encode_educ_test, columns=['Education'])\n",
    "\n",
    "display(encode_educ_df_train.isna().sum())\n",
    "display(encode_educ_df_test.isna().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create encoder and fit \n",
    "# encode_age = OrdinalEncoder(categories=[['Age 18-34', 'Age 35-49', 'Age 50-64', 'Age 65-79', 'Age 80+']], handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "# encode_age.fit(x_train['Age'].values.reshape(-1,1))\n",
    "# encode_age_train = encode_age.transform(x_train['Age'].values.reshape(-1, 1))\n",
    "# encode_age_test = encode_age.transform(x_test['Age'].values.reshape(-1, 1))\n",
    "\n",
    "# # create the df\n",
    "# encode_age_df_train = pd.DataFrame(encode_age_train, columns=['Age'])\n",
    "# encode_age_df_test = pd.DataFrame(encode_age_test, columns=['Age'])\n",
    "\n",
    "# display(encode_age_df_train.isna().sum())\n",
    "# display(encode_age_df_test.isna().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Group all encoded_dfs with the main df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HighBP                  0\n",
       "HighChol                0\n",
       "CholCheck               0\n",
       "Stroke                  0\n",
       "HeartDiseaseorAttack    0\n",
       "PhysActivity            0\n",
       "GenHlth                 0\n",
       "PhysHlth                0\n",
       "DiffWalk                0\n",
       "Age                     0\n",
       "Income                  0\n",
       "BMI                     0\n",
       "Education               0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "HighBP                  0\n",
       "HighChol                0\n",
       "CholCheck               0\n",
       "Stroke                  0\n",
       "HeartDiseaseorAttack    0\n",
       "PhysActivity            0\n",
       "GenHlth                 0\n",
       "PhysHlth                0\n",
       "DiffWalk                0\n",
       "Age                     0\n",
       "Income                  0\n",
       "BMI                     0\n",
       "Education               0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create a copy of the df without the unencoded columns\n",
    "# train\n",
    "x_train_unencoded = x_train.copy().drop(columns=['Education', 'BMI'])\n",
    "#x_train_unencoded = x_train.copy().drop(columns=['Age', 'Education', 'Income', 'BMI'])\n",
    "x_train_unencoded = x_train_unencoded.reset_index(drop=True)\n",
    "# test\n",
    "x_test_unencoded = x_test.copy().drop(columns=['Education', 'BMI'])\n",
    "#x_test_unencoded = x_test.copy().drop(columns=['Age', 'Education', 'Income', 'BMI'])\n",
    "x_test_unencoded = x_test_unencoded.reset_index(drop=True)\n",
    "\n",
    "# add the encoded columns\n",
    "x_train_encoded = pd.concat([x_train_unencoded, encode_BMI_df_train, encode_educ_df_train], axis=1)\n",
    "#x_train_encoded = pd.concat([x_train_unencoded, encode_BMI_df_train, encode_income_df_train, encode_educ_df_train, encode_age_df_train], axis=1)\n",
    "x_test_encoded = pd.concat([x_test_unencoded, encode_BMI_df_test, encode_educ_df_test], axis=1)\n",
    "#x_test_encoded = pd.concat([x_test_unencoded, encode_BMI_df_test, encode_income_df_test, encode_educ_df_test, encode_age_df_test], axis=1)\n",
    "\n",
    "# the results\n",
    "display(x_train_encoded.isna().sum())\n",
    "display(x_test_encoded.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train_encoded)\n",
    "x_train_encoded = scaler.transform(x_train_encoded)\n",
    "x_test_encoded = scaler.transform(x_test_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the ML Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 1, Train/Test Score: 0.895/0.666\n",
      "k: 3, Train/Test Score: 0.812/0.705\n",
      "k: 5, Train/Test Score: 0.788/0.720\n",
      "k: 7, Train/Test Score: 0.777/0.729\n",
      "k: 9, Train/Test Score: 0.771/0.734\n",
      "k: 11, Train/Test Score: 0.769/0.736\n",
      "k: 13, Train/Test Score: 0.764/0.739\n",
      "k: 15, Train/Test Score: 0.762/0.741\n",
      "k: 17, Train/Test Score: 0.760/0.740\n",
      "k: 19, Train/Test Score: 0.759/0.739\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loop through different k values to find which has the highest accuracy.\n",
    "# Note: We use only odd numbers because we don't want any ties.\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for k in range(1, 20, 2):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(x_train_encoded, y_train)\n",
    "    train_score = knn.score(x_train_encoded, y_train)\n",
    "    test_score = knn.score(x_test_encoded, y_test)\n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "    print(f\"k: {k}, Train/Test Score: {train_score:.3f}/{test_score:.3f}\")\n",
    "    \n",
    "# Plot the results\n",
    "plt.plot(range(1, 20, 2), train_scores, marker='o', label=\"training scores\")\n",
    "plt.plot(range(1, 20, 2), test_scores, marker=\"x\", label=\"testing scores\")\n",
    "plt.xlabel(\"k neighbors\")\n",
    "plt.ylabel(\"accuracy score\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7521077349629378"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Create and fit the logistic regression model\n",
    "logistic_regression_model = LogisticRegression(random_state=1, max_iter=1000)\n",
    "logistic_regression_model.fit(x_train_encoded, y_train)\n",
    "\n",
    "#make and save testing predictions with the saved logistic regression model using the test data\n",
    "predictions = logistic_regression_model.predict(x_test_encoded)\n",
    "\n",
    "# Review the accuracy\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "display(accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.6731737678945284\n"
     ]
    }
   ],
   "source": [
    "# create the model\n",
    "tree_model = tree.DecisionTreeClassifier()\n",
    "#fit the model\n",
    "tree_model = tree_model.fit(x_train_encoded, y_train)\n",
    "# Making predictions using the testing data\n",
    "predictions = tree_model.predict(x_test_encoded)\n",
    "# Calculate the accuracy score\n",
    "acc_score = accuracy_score(y_test, predictions)\n",
    "print(f\"Accuracy Score : {acc_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.9145966540296875\n",
      "Testing Score: 0.72364624002716\n"
     ]
    }
   ],
   "source": [
    "# Train the Random Forest model\n",
    "clf = RandomForestClassifier(random_state=1, n_estimators=1000).fit(x_train_encoded, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "print(f'Training Score: {clf.score(x_train_encoded, y_train)}')\n",
    "print(f'Testing Score: {clf.score(x_test_encoded, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XG Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.7562949131443445\n",
      "[[7048 1778]\n",
      " [2529 6318]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.80      0.77      8826\n",
      "           0       0.78      0.71      0.75      8847\n",
      "\n",
      "    accuracy                           0.76     17673\n",
      "   macro avg       0.76      0.76      0.76     17673\n",
      "weighted avg       0.76      0.76      0.76     17673\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_model = XGBClassifier(random_state=1, learning_rate = 0.05, n_estimators = 1000, max_depth=3)\n",
    "\n",
    "xgb_model.fit(x_train_encoded, y_train)\n",
    "predictions = xgb_model.predict(x_test_encoded)\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Accuracy Score: {accuracy}\")\n",
    "print(confusion_matrix(y_test,predictions, labels=[1, 0]))\n",
    "print(classification_report(y_test,predictions, labels=[1, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### notes from this, we dont have balancing issues. overall problem is acc isnt as high. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaptive Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sami\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy for Adaptive Boosting Classifier: 0.7465625530470209\n",
      "Testing Accuracy Adaptive Boosting Classifier: 0.7505799807616138\n"
     ]
    }
   ],
   "source": [
    "model_adapt = AdaBoostClassifier()\n",
    "model_adapt.fit(x_train_encoded, y_train)\n",
    "\n",
    "print(f\"Training Accuracy for Adaptive Boosting Classifier: {model_adapt.score(x_train_encoded,y_train)}\")\n",
    "print(f\"Testing Accuracy Adaptive Boosting Classifier: {model_adapt.score(x_test_encoded,y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.69      0.71      8847\n",
      "    positive       0.71      0.75      0.73      8826\n",
      "\n",
      "    accuracy                           0.72     17673\n",
      "   macro avg       0.72      0.72      0.72     17673\n",
      "weighted avg       0.72      0.72      0.72     17673\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create base models for grid search\n",
    "untuned_model = KNeighborsClassifier()\n",
    "grid_tuned_model = KNeighborsClassifier()\n",
    "random_tuned_model = KNeighborsClassifier()\n",
    "\n",
    "target_names = [\"negative\", \"positive\"]\n",
    "\n",
    "## Train a model without tuning\n",
    "untuned_model.fit(x_train_encoded, y_train)\n",
    "untuned_y_pred = untuned_model.predict(x_test_encoded)\n",
    "print(classification_report(y_test, untuned_y_pred,\n",
    "                            target_names=target_names))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "[CV 1/5] END leaf_size=10, n_neighbors=1, weights=uniform;, score=0.663 total time=   2.3s\n",
      "[CV 2/5] END leaf_size=10, n_neighbors=1, weights=uniform;, score=0.656 total time=   2.3s\n",
      "[CV 3/5] END leaf_size=10, n_neighbors=1, weights=uniform;, score=0.667 total time=   2.4s\n",
      "[CV 4/5] END leaf_size=10, n_neighbors=1, weights=uniform;, score=0.658 total time=   2.5s\n",
      "[CV 5/5] END leaf_size=10, n_neighbors=1, weights=uniform;, score=0.666 total time=   2.3s\n",
      "[CV 1/5] END leaf_size=10, n_neighbors=1, weights=distance;, score=0.663 total time=   2.1s\n",
      "[CV 2/5] END leaf_size=10, n_neighbors=1, weights=distance;, score=0.656 total time=   2.1s\n",
      "[CV 3/5] END leaf_size=10, n_neighbors=1, weights=distance;, score=0.667 total time=   2.1s\n",
      "[CV 4/5] END leaf_size=10, n_neighbors=1, weights=distance;, score=0.658 total time=   2.0s\n",
      "[CV 5/5] END leaf_size=10, n_neighbors=1, weights=distance;, score=0.666 total time=   2.1s\n",
      "[CV 1/5] END leaf_size=10, n_neighbors=5, weights=uniform;, score=0.716 total time=   3.5s\n",
      "[CV 2/5] END leaf_size=10, n_neighbors=5, weights=uniform;, score=0.705 total time=   3.6s\n",
      "[CV 3/5] END leaf_size=10, n_neighbors=5, weights=uniform;, score=0.714 total time=   3.4s\n",
      "[CV 4/5] END leaf_size=10, n_neighbors=5, weights=uniform;, score=0.710 total time=   3.5s\n",
      "[CV 5/5] END leaf_size=10, n_neighbors=5, weights=uniform;, score=0.714 total time=   3.4s\n",
      "[CV 1/5] END leaf_size=10, n_neighbors=5, weights=distance;, score=0.702 total time=   3.2s\n",
      "[CV 2/5] END leaf_size=10, n_neighbors=5, weights=distance;, score=0.694 total time=   3.1s\n",
      "[CV 3/5] END leaf_size=10, n_neighbors=5, weights=distance;, score=0.696 total time=   3.3s\n",
      "[CV 4/5] END leaf_size=10, n_neighbors=5, weights=distance;, score=0.695 total time=   3.2s\n",
      "[CV 5/5] END leaf_size=10, n_neighbors=5, weights=distance;, score=0.703 total time=   3.3s\n",
      "[CV 1/5] END leaf_size=10, n_neighbors=11, weights=uniform;, score=0.737 total time=   4.3s\n",
      "[CV 2/5] END leaf_size=10, n_neighbors=11, weights=uniform;, score=0.719 total time=   4.6s\n",
      "[CV 3/5] END leaf_size=10, n_neighbors=11, weights=uniform;, score=0.731 total time=   4.5s\n",
      "[CV 4/5] END leaf_size=10, n_neighbors=11, weights=uniform;, score=0.723 total time=   4.3s\n",
      "[CV 5/5] END leaf_size=10, n_neighbors=11, weights=uniform;, score=0.725 total time=   4.4s\n",
      "[CV 1/5] END leaf_size=10, n_neighbors=11, weights=distance;, score=0.719 total time=   4.0s\n",
      "[CV 2/5] END leaf_size=10, n_neighbors=11, weights=distance;, score=0.703 total time=   4.1s\n",
      "[CV 3/5] END leaf_size=10, n_neighbors=11, weights=distance;, score=0.711 total time=   4.2s\n",
      "[CV 4/5] END leaf_size=10, n_neighbors=11, weights=distance;, score=0.704 total time=   4.0s\n",
      "[CV 5/5] END leaf_size=10, n_neighbors=11, weights=distance;, score=0.708 total time=   4.1s\n",
      "[CV 1/5] END leaf_size=10, n_neighbors=15, weights=uniform;, score=0.741 total time=   4.7s\n",
      "[CV 2/5] END leaf_size=10, n_neighbors=15, weights=uniform;, score=0.726 total time=   4.6s\n",
      "[CV 3/5] END leaf_size=10, n_neighbors=15, weights=uniform;, score=0.731 total time=   5.0s\n",
      "[CV 4/5] END leaf_size=10, n_neighbors=15, weights=uniform;, score=0.730 total time=   5.0s\n",
      "[CV 5/5] END leaf_size=10, n_neighbors=15, weights=uniform;, score=0.733 total time=   4.7s\n",
      "[CV 1/5] END leaf_size=10, n_neighbors=15, weights=distance;, score=0.722 total time=   4.7s\n",
      "[CV 2/5] END leaf_size=10, n_neighbors=15, weights=distance;, score=0.709 total time=   4.7s\n",
      "[CV 3/5] END leaf_size=10, n_neighbors=15, weights=distance;, score=0.711 total time=   4.5s\n",
      "[CV 4/5] END leaf_size=10, n_neighbors=15, weights=distance;, score=0.708 total time=   4.5s\n",
      "[CV 5/5] END leaf_size=10, n_neighbors=15, weights=distance;, score=0.715 total time=   4.7s\n",
      "[CV 1/5] END leaf_size=10, n_neighbors=19, weights=uniform;, score=0.745 total time=   5.2s\n",
      "[CV 2/5] END leaf_size=10, n_neighbors=19, weights=uniform;, score=0.731 total time=   5.2s\n",
      "[CV 3/5] END leaf_size=10, n_neighbors=19, weights=uniform;, score=0.734 total time=   5.3s\n",
      "[CV 4/5] END leaf_size=10, n_neighbors=19, weights=uniform;, score=0.728 total time=   5.3s\n",
      "[CV 5/5] END leaf_size=10, n_neighbors=19, weights=uniform;, score=0.739 total time=   5.2s\n",
      "[CV 1/5] END leaf_size=10, n_neighbors=19, weights=distance;, score=0.724 total time=   4.9s\n",
      "[CV 2/5] END leaf_size=10, n_neighbors=19, weights=distance;, score=0.711 total time=   4.9s\n",
      "[CV 3/5] END leaf_size=10, n_neighbors=19, weights=distance;, score=0.714 total time=   5.1s\n",
      "[CV 4/5] END leaf_size=10, n_neighbors=19, weights=distance;, score=0.709 total time=   4.8s\n",
      "[CV 5/5] END leaf_size=10, n_neighbors=19, weights=distance;, score=0.719 total time=   4.8s\n",
      "[CV 1/5] END leaf_size=100, n_neighbors=1, weights=uniform;, score=0.663 total time=   2.0s\n",
      "[CV 2/5] END leaf_size=100, n_neighbors=1, weights=uniform;, score=0.656 total time=   1.9s\n",
      "[CV 3/5] END leaf_size=100, n_neighbors=1, weights=uniform;, score=0.666 total time=   1.9s\n",
      "[CV 4/5] END leaf_size=100, n_neighbors=1, weights=uniform;, score=0.657 total time=   1.9s\n",
      "[CV 5/5] END leaf_size=100, n_neighbors=1, weights=uniform;, score=0.666 total time=   2.0s\n",
      "[CV 1/5] END leaf_size=100, n_neighbors=1, weights=distance;, score=0.663 total time=   1.6s\n",
      "[CV 2/5] END leaf_size=100, n_neighbors=1, weights=distance;, score=0.656 total time=   1.6s\n",
      "[CV 3/5] END leaf_size=100, n_neighbors=1, weights=distance;, score=0.666 total time=   1.7s\n",
      "[CV 4/5] END leaf_size=100, n_neighbors=1, weights=distance;, score=0.657 total time=   1.7s\n",
      "[CV 5/5] END leaf_size=100, n_neighbors=1, weights=distance;, score=0.666 total time=   1.6s\n",
      "[CV 1/5] END leaf_size=100, n_neighbors=5, weights=uniform;, score=0.715 total time=   2.5s\n",
      "[CV 2/5] END leaf_size=100, n_neighbors=5, weights=uniform;, score=0.705 total time=   2.5s\n",
      "[CV 3/5] END leaf_size=100, n_neighbors=5, weights=uniform;, score=0.714 total time=   2.4s\n",
      "[CV 4/5] END leaf_size=100, n_neighbors=5, weights=uniform;, score=0.709 total time=   2.5s\n",
      "[CV 5/5] END leaf_size=100, n_neighbors=5, weights=uniform;, score=0.714 total time=   2.4s\n",
      "[CV 1/5] END leaf_size=100, n_neighbors=5, weights=distance;, score=0.702 total time=   2.1s\n",
      "[CV 2/5] END leaf_size=100, n_neighbors=5, weights=distance;, score=0.693 total time=   2.2s\n",
      "[CV 3/5] END leaf_size=100, n_neighbors=5, weights=distance;, score=0.696 total time=   2.3s\n",
      "[CV 4/5] END leaf_size=100, n_neighbors=5, weights=distance;, score=0.695 total time=   2.2s\n",
      "[CV 5/5] END leaf_size=100, n_neighbors=5, weights=distance;, score=0.703 total time=   2.2s\n",
      "[CV 1/5] END leaf_size=100, n_neighbors=11, weights=uniform;, score=0.738 total time=   2.8s\n",
      "[CV 2/5] END leaf_size=100, n_neighbors=11, weights=uniform;, score=0.720 total time=   2.9s\n",
      "[CV 3/5] END leaf_size=100, n_neighbors=11, weights=uniform;, score=0.732 total time=   2.9s\n",
      "[CV 4/5] END leaf_size=100, n_neighbors=11, weights=uniform;, score=0.722 total time=   2.9s\n",
      "[CV 5/5] END leaf_size=100, n_neighbors=11, weights=uniform;, score=0.727 total time=   2.9s\n",
      "[CV 1/5] END leaf_size=100, n_neighbors=11, weights=distance;, score=0.719 total time=   2.6s\n",
      "[CV 2/5] END leaf_size=100, n_neighbors=11, weights=distance;, score=0.703 total time=   2.7s\n",
      "[CV 3/5] END leaf_size=100, n_neighbors=11, weights=distance;, score=0.711 total time=   2.7s\n",
      "[CV 4/5] END leaf_size=100, n_neighbors=11, weights=distance;, score=0.704 total time=   2.6s\n",
      "[CV 5/5] END leaf_size=100, n_neighbors=11, weights=distance;, score=0.709 total time=   2.7s\n",
      "[CV 1/5] END leaf_size=100, n_neighbors=15, weights=uniform;, score=0.740 total time=   3.1s\n",
      "[CV 2/5] END leaf_size=100, n_neighbors=15, weights=uniform;, score=0.727 total time=   3.3s\n",
      "[CV 3/5] END leaf_size=100, n_neighbors=15, weights=uniform;, score=0.731 total time=   3.0s\n",
      "[CV 4/5] END leaf_size=100, n_neighbors=15, weights=uniform;, score=0.729 total time=   3.1s\n",
      "[CV 5/5] END leaf_size=100, n_neighbors=15, weights=uniform;, score=0.733 total time=   3.1s\n",
      "[CV 1/5] END leaf_size=100, n_neighbors=15, weights=distance;, score=0.721 total time=   2.8s\n",
      "[CV 2/5] END leaf_size=100, n_neighbors=15, weights=distance;, score=0.708 total time=   2.8s\n",
      "[CV 3/5] END leaf_size=100, n_neighbors=15, weights=distance;, score=0.711 total time=   2.7s\n",
      "[CV 4/5] END leaf_size=100, n_neighbors=15, weights=distance;, score=0.708 total time=   2.9s\n",
      "[CV 5/5] END leaf_size=100, n_neighbors=15, weights=distance;, score=0.715 total time=   2.7s\n",
      "[CV 1/5] END leaf_size=100, n_neighbors=19, weights=uniform;, score=0.745 total time=   3.2s\n",
      "[CV 2/5] END leaf_size=100, n_neighbors=19, weights=uniform;, score=0.730 total time=   3.3s\n",
      "[CV 3/5] END leaf_size=100, n_neighbors=19, weights=uniform;, score=0.733 total time=   3.3s\n",
      "[CV 4/5] END leaf_size=100, n_neighbors=19, weights=uniform;, score=0.729 total time=   3.1s\n",
      "[CV 5/5] END leaf_size=100, n_neighbors=19, weights=uniform;, score=0.739 total time=   3.2s\n",
      "[CV 1/5] END leaf_size=100, n_neighbors=19, weights=distance;, score=0.724 total time=   2.9s\n",
      "[CV 2/5] END leaf_size=100, n_neighbors=19, weights=distance;, score=0.711 total time=   2.9s\n",
      "[CV 3/5] END leaf_size=100, n_neighbors=19, weights=distance;, score=0.714 total time=   3.0s\n",
      "[CV 4/5] END leaf_size=100, n_neighbors=19, weights=distance;, score=0.709 total time=   2.9s\n",
      "[CV 5/5] END leaf_size=100, n_neighbors=19, weights=distance;, score=0.719 total time=   2.9s\n",
      "[CV 1/5] END leaf_size=500, n_neighbors=1, weights=uniform;, score=0.663 total time=   2.7s\n",
      "[CV 2/5] END leaf_size=500, n_neighbors=1, weights=uniform;, score=0.659 total time=   2.7s\n",
      "[CV 3/5] END leaf_size=500, n_neighbors=1, weights=uniform;, score=0.667 total time=   2.7s\n",
      "[CV 4/5] END leaf_size=500, n_neighbors=1, weights=uniform;, score=0.659 total time=   2.6s\n",
      "[CV 5/5] END leaf_size=500, n_neighbors=1, weights=uniform;, score=0.667 total time=   2.7s\n",
      "[CV 1/5] END leaf_size=500, n_neighbors=1, weights=distance;, score=0.663 total time=   2.4s\n",
      "[CV 2/5] END leaf_size=500, n_neighbors=1, weights=distance;, score=0.659 total time=   2.4s\n",
      "[CV 3/5] END leaf_size=500, n_neighbors=1, weights=distance;, score=0.667 total time=   2.5s\n",
      "[CV 4/5] END leaf_size=500, n_neighbors=1, weights=distance;, score=0.659 total time=   2.3s\n",
      "[CV 5/5] END leaf_size=500, n_neighbors=1, weights=distance;, score=0.667 total time=   2.4s\n",
      "[CV 1/5] END leaf_size=500, n_neighbors=5, weights=uniform;, score=0.715 total time=   3.2s\n",
      "[CV 2/5] END leaf_size=500, n_neighbors=5, weights=uniform;, score=0.705 total time=   3.2s\n",
      "[CV 3/5] END leaf_size=500, n_neighbors=5, weights=uniform;, score=0.715 total time=   3.3s\n",
      "[CV 4/5] END leaf_size=500, n_neighbors=5, weights=uniform;, score=0.708 total time=   3.2s\n",
      "[CV 5/5] END leaf_size=500, n_neighbors=5, weights=uniform;, score=0.713 total time=   3.2s\n",
      "[CV 1/5] END leaf_size=500, n_neighbors=5, weights=distance;, score=0.702 total time=   2.9s\n",
      "[CV 2/5] END leaf_size=500, n_neighbors=5, weights=distance;, score=0.694 total time=   2.9s\n",
      "[CV 3/5] END leaf_size=500, n_neighbors=5, weights=distance;, score=0.697 total time=   2.9s\n",
      "[CV 4/5] END leaf_size=500, n_neighbors=5, weights=distance;, score=0.694 total time=   3.0s\n",
      "[CV 5/5] END leaf_size=500, n_neighbors=5, weights=distance;, score=0.702 total time=   2.8s\n",
      "[CV 1/5] END leaf_size=500, n_neighbors=11, weights=uniform;, score=0.737 total time=   3.6s\n",
      "[CV 2/5] END leaf_size=500, n_neighbors=11, weights=uniform;, score=0.720 total time=   3.5s\n",
      "[CV 3/5] END leaf_size=500, n_neighbors=11, weights=uniform;, score=0.731 total time=   3.6s\n",
      "[CV 4/5] END leaf_size=500, n_neighbors=11, weights=uniform;, score=0.722 total time=   3.5s\n",
      "[CV 5/5] END leaf_size=500, n_neighbors=11, weights=uniform;, score=0.725 total time=   3.6s\n",
      "[CV 1/5] END leaf_size=500, n_neighbors=11, weights=distance;, score=0.719 total time=   3.3s\n",
      "[CV 2/5] END leaf_size=500, n_neighbors=11, weights=distance;, score=0.703 total time=   3.3s\n",
      "[CV 3/5] END leaf_size=500, n_neighbors=11, weights=distance;, score=0.711 total time=   3.2s\n",
      "[CV 4/5] END leaf_size=500, n_neighbors=11, weights=distance;, score=0.703 total time=   3.3s\n",
      "[CV 5/5] END leaf_size=500, n_neighbors=11, weights=distance;, score=0.709 total time=   3.2s\n",
      "[CV 1/5] END leaf_size=500, n_neighbors=15, weights=uniform;, score=0.742 total time=   3.8s\n",
      "[CV 2/5] END leaf_size=500, n_neighbors=15, weights=uniform;, score=0.727 total time=   3.7s\n",
      "[CV 3/5] END leaf_size=500, n_neighbors=15, weights=uniform;, score=0.732 total time=   3.7s\n",
      "[CV 4/5] END leaf_size=500, n_neighbors=15, weights=uniform;, score=0.729 total time=   3.8s\n",
      "[CV 5/5] END leaf_size=500, n_neighbors=15, weights=uniform;, score=0.734 total time=   3.8s\n",
      "[CV 1/5] END leaf_size=500, n_neighbors=15, weights=distance;, score=0.722 total time=   3.5s\n",
      "[CV 2/5] END leaf_size=500, n_neighbors=15, weights=distance;, score=0.709 total time=   3.4s\n",
      "[CV 3/5] END leaf_size=500, n_neighbors=15, weights=distance;, score=0.712 total time=   3.4s\n",
      "[CV 4/5] END leaf_size=500, n_neighbors=15, weights=distance;, score=0.708 total time=   3.4s\n",
      "[CV 5/5] END leaf_size=500, n_neighbors=15, weights=distance;, score=0.715 total time=   3.4s\n",
      "[CV 1/5] END leaf_size=500, n_neighbors=19, weights=uniform;, score=0.746 total time=   3.9s\n",
      "[CV 2/5] END leaf_size=500, n_neighbors=19, weights=uniform;, score=0.732 total time=   3.8s\n",
      "[CV 3/5] END leaf_size=500, n_neighbors=19, weights=uniform;, score=0.734 total time=   3.8s\n",
      "[CV 4/5] END leaf_size=500, n_neighbors=19, weights=uniform;, score=0.729 total time=   3.9s\n",
      "[CV 5/5] END leaf_size=500, n_neighbors=19, weights=uniform;, score=0.739 total time=   3.9s\n",
      "[CV 1/5] END leaf_size=500, n_neighbors=19, weights=distance;, score=0.724 total time=   3.6s\n",
      "[CV 2/5] END leaf_size=500, n_neighbors=19, weights=distance;, score=0.711 total time=   3.6s\n",
      "[CV 3/5] END leaf_size=500, n_neighbors=19, weights=distance;, score=0.714 total time=   3.6s\n",
      "[CV 4/5] END leaf_size=500, n_neighbors=19, weights=distance;, score=0.709 total time=   3.6s\n",
      "[CV 5/5] END leaf_size=500, n_neighbors=19, weights=distance;, score=0.719 total time=   3.5s\n",
      "{'leaf_size': 500, 'n_neighbors': 19, 'weights': 'uniform'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.70      0.73      8847\n",
      "    positive       0.72      0.78      0.75      8826\n",
      "\n",
      "    accuracy                           0.74     17673\n",
      "   macro avg       0.74      0.74      0.74     17673\n",
      "weighted avg       0.74      0.74      0.74     17673\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the grid search estimator along with a parameter object containing the values to adjust.\n",
    "# Try adjusting n_neighbors with values of 1 through 19. Adjust leaf_size by using 10, 50, 100, and 500.\n",
    "# Include both uniform and distance options for weights.\n",
    "param_grid = {\n",
    "    'n_neighbors': [1, 5, 11, 15, 19],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'leaf_size': [10, 100, 500]\n",
    "}\n",
    "grid_clf = GridSearchCV(grid_tuned_model, param_grid, verbose=3)\n",
    "# Fit the model by using the grid search estimator.\n",
    "# This will take the KNN model and try each combination of parameters.\n",
    "grid_clf.fit(x_train_encoded, y_train)\n",
    "# List the best parameters for this dataset\n",
    "print(grid_clf.best_params_)\n",
    "# Print the classification report for the best model\n",
    "grid_y_pred = grid_clf.predict(x_test_encoded)\n",
    "print(classification_report(y_test, grid_y_pred,\n",
    "                            target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV 1/5] END leaf_size=1, n_neighbors=5, weights=uniform;, score=0.716 total time=   7.3s\n",
      "[CV 2/5] END leaf_size=1, n_neighbors=5, weights=uniform;, score=0.705 total time=   7.2s\n",
      "[CV 3/5] END leaf_size=1, n_neighbors=5, weights=uniform;, score=0.714 total time=   7.0s\n",
      "[CV 4/5] END leaf_size=1, n_neighbors=5, weights=uniform;, score=0.710 total time=   7.2s\n",
      "[CV 5/5] END leaf_size=1, n_neighbors=5, weights=uniform;, score=0.714 total time=   7.2s\n",
      "[CV 1/5] END leaf_size=500, n_neighbors=19, weights=uniform;, score=0.746 total time=   3.9s\n",
      "[CV 2/5] END leaf_size=500, n_neighbors=19, weights=uniform;, score=0.732 total time=   3.9s\n",
      "[CV 3/5] END leaf_size=500, n_neighbors=19, weights=uniform;, score=0.734 total time=   4.0s\n",
      "[CV 4/5] END leaf_size=500, n_neighbors=19, weights=uniform;, score=0.729 total time=   3.8s\n",
      "[CV 5/5] END leaf_size=500, n_neighbors=19, weights=uniform;, score=0.739 total time=   4.0s\n",
      "[CV 1/5] END leaf_size=100, n_neighbors=5, weights=distance;, score=0.702 total time=   2.2s\n",
      "[CV 2/5] END leaf_size=100, n_neighbors=5, weights=distance;, score=0.693 total time=   2.3s\n",
      "[CV 3/5] END leaf_size=100, n_neighbors=5, weights=distance;, score=0.696 total time=   2.3s\n",
      "[CV 4/5] END leaf_size=100, n_neighbors=5, weights=distance;, score=0.695 total time=   2.3s\n",
      "[CV 5/5] END leaf_size=100, n_neighbors=5, weights=distance;, score=0.703 total time=   2.5s\n",
      "[CV 1/5] END leaf_size=100, n_neighbors=1, weights=uniform;, score=0.663 total time=   1.9s\n",
      "[CV 2/5] END leaf_size=100, n_neighbors=1, weights=uniform;, score=0.656 total time=   1.9s\n",
      "[CV 3/5] END leaf_size=100, n_neighbors=1, weights=uniform;, score=0.666 total time=   1.9s\n",
      "[CV 4/5] END leaf_size=100, n_neighbors=1, weights=uniform;, score=0.657 total time=   1.9s\n",
      "[CV 5/5] END leaf_size=100, n_neighbors=1, weights=uniform;, score=0.666 total time=   1.9s\n",
      "[CV 1/5] END leaf_size=500, n_neighbors=15, weights=uniform;, score=0.742 total time=   3.8s\n",
      "[CV 2/5] END leaf_size=500, n_neighbors=15, weights=uniform;, score=0.727 total time=   3.8s\n",
      "[CV 3/5] END leaf_size=500, n_neighbors=15, weights=uniform;, score=0.732 total time=   3.8s\n",
      "[CV 4/5] END leaf_size=500, n_neighbors=15, weights=uniform;, score=0.729 total time=   3.7s\n",
      "[CV 5/5] END leaf_size=500, n_neighbors=15, weights=uniform;, score=0.734 total time=   3.8s\n",
      "[CV 1/5] END leaf_size=500, n_neighbors=11, weights=uniform;, score=0.737 total time=   3.6s\n",
      "[CV 2/5] END leaf_size=500, n_neighbors=11, weights=uniform;, score=0.720 total time=   3.7s\n",
      "[CV 3/5] END leaf_size=500, n_neighbors=11, weights=uniform;, score=0.731 total time=   3.6s\n",
      "[CV 4/5] END leaf_size=500, n_neighbors=11, weights=uniform;, score=0.722 total time=   3.6s\n",
      "[CV 5/5] END leaf_size=500, n_neighbors=11, weights=uniform;, score=0.725 total time=   3.6s\n",
      "[CV 1/5] END leaf_size=500, n_neighbors=15, weights=distance;, score=0.722 total time=   3.6s\n",
      "[CV 2/5] END leaf_size=500, n_neighbors=15, weights=distance;, score=0.709 total time=   3.5s\n",
      "[CV 3/5] END leaf_size=500, n_neighbors=15, weights=distance;, score=0.712 total time=   3.5s\n",
      "[CV 4/5] END leaf_size=500, n_neighbors=15, weights=distance;, score=0.708 total time=   3.4s\n",
      "[CV 5/5] END leaf_size=500, n_neighbors=15, weights=distance;, score=0.715 total time=   3.5s\n",
      "[CV 1/5] END leaf_size=100, n_neighbors=1, weights=distance;, score=0.663 total time=   1.6s\n",
      "[CV 2/5] END leaf_size=100, n_neighbors=1, weights=distance;, score=0.656 total time=   1.7s\n",
      "[CV 3/5] END leaf_size=100, n_neighbors=1, weights=distance;, score=0.666 total time=   1.6s\n",
      "[CV 4/5] END leaf_size=100, n_neighbors=1, weights=distance;, score=0.657 total time=   1.6s\n",
      "[CV 5/5] END leaf_size=100, n_neighbors=1, weights=distance;, score=0.666 total time=   1.6s\n",
      "[CV 1/5] END leaf_size=100, n_neighbors=15, weights=distance;, score=0.721 total time=   2.8s\n",
      "[CV 2/5] END leaf_size=100, n_neighbors=15, weights=distance;, score=0.708 total time=   2.7s\n",
      "[CV 3/5] END leaf_size=100, n_neighbors=15, weights=distance;, score=0.711 total time=   2.8s\n",
      "[CV 4/5] END leaf_size=100, n_neighbors=15, weights=distance;, score=0.708 total time=   2.8s\n",
      "[CV 5/5] END leaf_size=100, n_neighbors=15, weights=distance;, score=0.715 total time=   2.8s\n",
      "[CV 1/5] END leaf_size=500, n_neighbors=5, weights=uniform;, score=0.715 total time=   3.3s\n",
      "[CV 2/5] END leaf_size=500, n_neighbors=5, weights=uniform;, score=0.705 total time=   3.2s\n",
      "[CV 3/5] END leaf_size=500, n_neighbors=5, weights=uniform;, score=0.715 total time=   3.3s\n",
      "[CV 4/5] END leaf_size=500, n_neighbors=5, weights=uniform;, score=0.708 total time=   3.2s\n",
      "[CV 5/5] END leaf_size=500, n_neighbors=5, weights=uniform;, score=0.713 total time=   3.3s\n",
      "{'weights': 'uniform', 'n_neighbors': 19, 'leaf_size': 500}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.70      0.73      8847\n",
      "    positive       0.72      0.78      0.75      8826\n",
      "\n",
      "    accuracy                           0.74     17673\n",
      "   macro avg       0.74      0.74      0.74     17673\n",
      "weighted avg       0.74      0.74      0.74     17673\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the parameter object for the randomized search estimator.\n",
    "# Try adjusting n_neighbors with values of 1 through 19. \n",
    "# Adjust leaf_size by using a range from 1 to 500.\n",
    "# Include both uniform and distance options for weights.\n",
    "param_grid = {\n",
    "    'n_neighbors': [1, 5, 11, 15, 19],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'leaf_size': [1, 100, 500]\n",
    "}\n",
    "\n",
    "random_clf = RandomizedSearchCV(random_tuned_model, param_grid, random_state=0, verbose=3)\n",
    "random_clf.fit(x_train_encoded, y_train)\n",
    "# List the best parameters for this dataset\n",
    "print(random_clf.best_params_)\n",
    "# Make predictions with the hypertuned model\n",
    "random_tuned_pred = random_clf.predict(x_test_encoded)\n",
    "# Calculate the classification report\n",
    "print(classification_report(y_test, random_tuned_pred,\n",
    "                            target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest fixer\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 500, 1000],\n",
    "    'max_depth': [3,5,7]\n",
    "}\n",
    "\n",
    "grid_clf = GridSearchCV(grid_tuned_model, param_grid, verbose=3)\n",
    "# Fit the model by using the grid search estimator.\n",
    "# This will take the KNN model and try each combination of parameters.\n",
    "grid_clf.fit(x_train_encoded, y_train)\n",
    "# List the best parameters for this dataset\n",
    "print(grid_clf.best_params_)\n",
    "# Print the classification report for the best model\n",
    "grid_y_pred = grid_clf.predict(x_test_encoded)\n",
    "print(classification_report(y_test, grid_y_pred,\n",
    "                            target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=3, n_estimators=100;, score=0.753 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=3, n_estimators=100;, score=0.742 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=3, n_estimators=100;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=3, n_estimators=100;, score=0.742 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=3, n_estimators=100;, score=0.748 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=3, n_estimators=500;, score=0.757 total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=3, n_estimators=500;, score=0.744 total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=3, n_estimators=500;, score=0.748 total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=3, n_estimators=500;, score=0.745 total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=3, n_estimators=500;, score=0.750 total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=3, n_estimators=1000;, score=0.755 total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=3, n_estimators=1000;, score=0.742 total time=   0.8s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=3, n_estimators=1000;, score=0.748 total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=3, n_estimators=1000;, score=0.743 total time=   0.7s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=3, n_estimators=1000;, score=0.750 total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=7, n_estimators=100;, score=0.756 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=7, n_estimators=100;, score=0.743 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=7, n_estimators=100;, score=0.745 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=7, n_estimators=100;, score=0.742 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=7, n_estimators=100;, score=0.749 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=7, n_estimators=500;, score=0.748 total time=   0.8s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=7, n_estimators=500;, score=0.737 total time=   0.8s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=7, n_estimators=500;, score=0.740 total time=   0.9s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=7, n_estimators=500;, score=0.739 total time=   0.8s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=7, n_estimators=500;, score=0.744 total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=7, n_estimators=1000;, score=0.741 total time=   1.5s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=7, n_estimators=1000;, score=0.732 total time=   1.6s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=7, n_estimators=1000;, score=0.736 total time=   1.7s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=7, n_estimators=1000;, score=0.732 total time=   1.6s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=7, n_estimators=1000;, score=0.737 total time=   1.6s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=11, n_estimators=100;, score=0.744 total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=11, n_estimators=100;, score=0.736 total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=11, n_estimators=100;, score=0.737 total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=11, n_estimators=100;, score=0.737 total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=11, n_estimators=100;, score=0.739 total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=11, n_estimators=500;, score=0.726 total time=   1.9s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=11, n_estimators=500;, score=0.717 total time=   1.8s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=11, n_estimators=500;, score=0.724 total time=   1.9s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=11, n_estimators=500;, score=0.723 total time=   1.9s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=11, n_estimators=500;, score=0.726 total time=   1.9s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=11, n_estimators=1000;, score=0.713 total time=   3.6s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=11, n_estimators=1000;, score=0.708 total time=   3.9s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=11, n_estimators=1000;, score=0.717 total time=   3.6s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=11, n_estimators=1000;, score=0.711 total time=   3.6s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=11, n_estimators=1000;, score=0.718 total time=   3.8s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=100;, score=0.757 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=100;, score=0.742 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=100;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=100;, score=0.743 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=100;, score=0.749 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=500;, score=0.756 total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=500;, score=0.743 total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=500;, score=0.748 total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=500;, score=0.744 total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=500;, score=0.749 total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=1000;, score=0.755 total time=   0.9s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=1000;, score=0.740 total time=   0.9s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=1000;, score=0.746 total time=   0.8s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=1000;, score=0.743 total time=   0.8s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=1000;, score=0.749 total time=   0.8s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=7, n_estimators=100;, score=0.752 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=7, n_estimators=100;, score=0.742 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=7, n_estimators=100;, score=0.743 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=7, n_estimators=100;, score=0.743 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=7, n_estimators=100;, score=0.748 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=7, n_estimators=500;, score=0.742 total time=   0.8s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=7, n_estimators=500;, score=0.730 total time=   0.8s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=7, n_estimators=500;, score=0.734 total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=7, n_estimators=500;, score=0.734 total time=   0.8s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=7, n_estimators=500;, score=0.735 total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=7, n_estimators=1000;, score=0.731 total time=   1.6s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=7, n_estimators=1000;, score=0.723 total time=   1.8s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=7, n_estimators=1000;, score=0.728 total time=   1.8s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=7, n_estimators=1000;, score=0.725 total time=   1.8s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=7, n_estimators=1000;, score=0.730 total time=   1.8s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=11, n_estimators=100;, score=0.743 total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=11, n_estimators=100;, score=0.730 total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=11, n_estimators=100;, score=0.733 total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=11, n_estimators=100;, score=0.734 total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=11, n_estimators=100;, score=0.735 total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=11, n_estimators=500;, score=0.713 total time=   1.8s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=11, n_estimators=500;, score=0.708 total time=   1.9s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=11, n_estimators=500;, score=0.714 total time=   1.8s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=11, n_estimators=500;, score=0.711 total time=   1.9s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=11, n_estimators=500;, score=0.715 total time=   1.9s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=11, n_estimators=1000;, score=0.707 total time=   3.5s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=11, n_estimators=1000;, score=0.697 total time=   3.6s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=11, n_estimators=1000;, score=0.707 total time=   3.6s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=11, n_estimators=1000;, score=0.700 total time=   3.7s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=11, n_estimators=1000;, score=0.711 total time=   3.5s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=3, n_estimators=100;, score=0.757 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=3, n_estimators=100;, score=0.742 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=3, n_estimators=100;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=3, n_estimators=100;, score=0.744 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=3, n_estimators=100;, score=0.751 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=3, n_estimators=500;, score=0.755 total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=3, n_estimators=500;, score=0.740 total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=3, n_estimators=500;, score=0.746 total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=3, n_estimators=500;, score=0.743 total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=3, n_estimators=500;, score=0.747 total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=3, n_estimators=1000;, score=0.752 total time=   1.1s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=3, n_estimators=1000;, score=0.741 total time=   1.0s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=3, n_estimators=1000;, score=0.744 total time=   0.9s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=3, n_estimators=1000;, score=0.742 total time=   1.0s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=3, n_estimators=1000;, score=0.747 total time=   1.0s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=7, n_estimators=100;, score=0.747 total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=7, n_estimators=100;, score=0.737 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=7, n_estimators=100;, score=0.740 total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=7, n_estimators=100;, score=0.740 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=7, n_estimators=100;, score=0.745 total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=7, n_estimators=500;, score=0.730 total time=   1.0s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=7, n_estimators=500;, score=0.724 total time=   0.9s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=7, n_estimators=500;, score=0.726 total time=   0.8s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=7, n_estimators=500;, score=0.723 total time=   0.8s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=7, n_estimators=500;, score=0.730 total time=   0.8s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=7, n_estimators=1000;, score=0.719 total time=   1.7s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=7, n_estimators=1000;, score=0.713 total time=   2.0s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=7, n_estimators=1000;, score=0.720 total time=   1.9s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=7, n_estimators=1000;, score=0.710 total time=   1.8s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=7, n_estimators=1000;, score=0.720 total time=   1.8s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=11, n_estimators=100;, score=0.728 total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=11, n_estimators=100;, score=0.718 total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=11, n_estimators=100;, score=0.722 total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=11, n_estimators=100;, score=0.724 total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=11, n_estimators=100;, score=0.726 total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=11, n_estimators=500;, score=0.706 total time=   1.7s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=11, n_estimators=500;, score=0.697 total time=   1.9s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=11, n_estimators=500;, score=0.707 total time=   1.8s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=11, n_estimators=500;, score=0.700 total time=   1.8s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=11, n_estimators=500;, score=0.710 total time=   1.9s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=11, n_estimators=1000;, score=0.701 total time=   3.3s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=11, n_estimators=1000;, score=0.688 total time=   3.3s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=11, n_estimators=1000;, score=0.699 total time=   3.4s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=11, n_estimators=1000;, score=0.694 total time=   3.3s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=11, n_estimators=1000;, score=0.704 total time=   3.4s\n",
      "Accuracy: 0.7555027442992135\n",
      "{'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.7485807202526576\n"
     ]
    }
   ],
   "source": [
    "# Create the parameter grid for the GridSearchCV model running Xgboost\n",
    "param_grid = {\n",
    "  #random_state=1, learning_rate=0.05, n_estimators=1000, max_depth=3\n",
    "    'learning_rate': [0.05, 0.1, 0.2],\n",
    "    'n_estimators': [100, 500, 1000],\n",
    "    'max_depth': [3, 7, 11]\n",
    "}\n",
    "# Create the GridSearchCV model\n",
    "grid_model = GridSearchCV(XGBClassifier(), param_grid, verbose=3)\n",
    "# Fit the model\n",
    "grid_model.fit(x_train_encoded, y_train)\n",
    "# Make predictions\n",
    "predictions = grid_model.predict(x_test_encoded)\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "# Print the best parameters\n",
    "print(grid_model.best_params_)\n",
    "print(grid_model.best_score_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
