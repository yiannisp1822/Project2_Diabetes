{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, OrdinalEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "# Needed for decision tree visualization\n",
    "import pydotplus\n",
    "from IPython.display import Image\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes_binary</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>...</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Diabetes_binary  HighBP  HighChol  CholCheck   BMI  Smoker  Stroke  \\\n",
       "0              0.0     1.0       0.0        1.0  26.0     0.0     0.0   \n",
       "1              0.0     1.0       1.0        1.0  26.0     1.0     1.0   \n",
       "2              0.0     0.0       0.0        1.0  26.0     0.0     0.0   \n",
       "3              0.0     1.0       1.0        1.0  28.0     1.0     0.0   \n",
       "4              0.0     0.0       0.0        1.0  29.0     1.0     0.0   \n",
       "\n",
       "   HeartDiseaseorAttack  PhysActivity  Fruits  ...  AnyHealthcare  \\\n",
       "0                   0.0           1.0     0.0  ...            1.0   \n",
       "1                   0.0           0.0     1.0  ...            1.0   \n",
       "2                   0.0           1.0     1.0  ...            1.0   \n",
       "3                   0.0           1.0     1.0  ...            1.0   \n",
       "4                   0.0           1.0     1.0  ...            1.0   \n",
       "\n",
       "   NoDocbcCost  GenHlth  MentHlth  PhysHlth  DiffWalk  Sex   Age  Education  \\\n",
       "0          0.0      3.0       5.0      30.0       0.0  1.0   4.0        6.0   \n",
       "1          0.0      3.0       0.0       0.0       0.0  1.0  12.0        6.0   \n",
       "2          0.0      1.0       0.0      10.0       0.0  1.0  13.0        6.0   \n",
       "3          0.0      3.0       0.0       3.0       0.0  1.0  11.0        6.0   \n",
       "4          0.0      2.0       0.0       0.0       0.0  0.0   8.0        5.0   \n",
       "\n",
       "   Income  \n",
       "0     8.0  \n",
       "1     8.0  \n",
       "2     8.0  \n",
       "3     8.0  \n",
       "4     8.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import\n",
    "diabetes = pd.read_csv(\"Resources/diabetes_binary_5050split_health_indicators_BRFSS2015.csv\")\n",
    "\n",
    "# Head\n",
    "diabetes.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Diabetes_binary', 'HighBP', 'HighChol', 'CholCheck', 'BMI', 'Smoker',\n",
       "       'Stroke', 'HeartDiseaseorAttack', 'PhysActivity', 'Fruits', 'Veggies',\n",
       "       'HvyAlcoholConsump', 'AnyHealthcare', 'NoDocbcCost', 'GenHlth',\n",
       "       'MentHlth', 'PhysHlth', 'DiffWalk', 'Sex', 'Age', 'Education',\n",
       "       'Income'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column Descriptions\n",
    "1. Diabetes_binary: 0 = no diabetes 1 = prediabetes or diabetes\n",
    "2. HighBP: 0 = no high BP 1 = high BP\n",
    "3. HighChol: 0 = no high cholesterol 1 = high cholesterol\n",
    "4. CholCheck: 0 = no cholesterol check in 5 years 1 = yes cholesterol check in 5 years\n",
    "5. BMI: Body Mass Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes_binary</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>...</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.563458</td>\n",
       "      <td>0.525703</td>\n",
       "      <td>0.975259</td>\n",
       "      <td>29.856985</td>\n",
       "      <td>0.475273</td>\n",
       "      <td>0.062171</td>\n",
       "      <td>0.147810</td>\n",
       "      <td>0.703036</td>\n",
       "      <td>0.611795</td>\n",
       "      <td>...</td>\n",
       "      <td>0.954960</td>\n",
       "      <td>0.093914</td>\n",
       "      <td>2.837082</td>\n",
       "      <td>3.752037</td>\n",
       "      <td>5.810417</td>\n",
       "      <td>0.252730</td>\n",
       "      <td>0.456997</td>\n",
       "      <td>8.584055</td>\n",
       "      <td>4.920953</td>\n",
       "      <td>5.698311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.500004</td>\n",
       "      <td>0.495960</td>\n",
       "      <td>0.499342</td>\n",
       "      <td>0.155336</td>\n",
       "      <td>7.113954</td>\n",
       "      <td>0.499392</td>\n",
       "      <td>0.241468</td>\n",
       "      <td>0.354914</td>\n",
       "      <td>0.456924</td>\n",
       "      <td>0.487345</td>\n",
       "      <td>...</td>\n",
       "      <td>0.207394</td>\n",
       "      <td>0.291712</td>\n",
       "      <td>1.113565</td>\n",
       "      <td>8.155627</td>\n",
       "      <td>10.062261</td>\n",
       "      <td>0.434581</td>\n",
       "      <td>0.498151</td>\n",
       "      <td>2.852153</td>\n",
       "      <td>1.029081</td>\n",
       "      <td>2.175196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Diabetes_binary        HighBP      HighChol     CholCheck  \\\n",
       "count     70692.000000  70692.000000  70692.000000  70692.000000   \n",
       "mean          0.500000      0.563458      0.525703      0.975259   \n",
       "std           0.500004      0.495960      0.499342      0.155336   \n",
       "min           0.000000      0.000000      0.000000      0.000000   \n",
       "25%           0.000000      0.000000      0.000000      1.000000   \n",
       "50%           0.500000      1.000000      1.000000      1.000000   \n",
       "75%           1.000000      1.000000      1.000000      1.000000   \n",
       "max           1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "                BMI        Smoker        Stroke  HeartDiseaseorAttack  \\\n",
       "count  70692.000000  70692.000000  70692.000000          70692.000000   \n",
       "mean      29.856985      0.475273      0.062171              0.147810   \n",
       "std        7.113954      0.499392      0.241468              0.354914   \n",
       "min       12.000000      0.000000      0.000000              0.000000   \n",
       "25%       25.000000      0.000000      0.000000              0.000000   \n",
       "50%       29.000000      0.000000      0.000000              0.000000   \n",
       "75%       33.000000      1.000000      0.000000              0.000000   \n",
       "max       98.000000      1.000000      1.000000              1.000000   \n",
       "\n",
       "       PhysActivity        Fruits  ...  AnyHealthcare   NoDocbcCost  \\\n",
       "count  70692.000000  70692.000000  ...   70692.000000  70692.000000   \n",
       "mean       0.703036      0.611795  ...       0.954960      0.093914   \n",
       "std        0.456924      0.487345  ...       0.207394      0.291712   \n",
       "min        0.000000      0.000000  ...       0.000000      0.000000   \n",
       "25%        0.000000      0.000000  ...       1.000000      0.000000   \n",
       "50%        1.000000      1.000000  ...       1.000000      0.000000   \n",
       "75%        1.000000      1.000000  ...       1.000000      0.000000   \n",
       "max        1.000000      1.000000  ...       1.000000      1.000000   \n",
       "\n",
       "            GenHlth      MentHlth      PhysHlth      DiffWalk           Sex  \\\n",
       "count  70692.000000  70692.000000  70692.000000  70692.000000  70692.000000   \n",
       "mean       2.837082      3.752037      5.810417      0.252730      0.456997   \n",
       "std        1.113565      8.155627     10.062261      0.434581      0.498151   \n",
       "min        1.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        2.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        3.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        4.000000      2.000000      6.000000      1.000000      1.000000   \n",
       "max        5.000000     30.000000     30.000000      1.000000      1.000000   \n",
       "\n",
       "                Age     Education        Income  \n",
       "count  70692.000000  70692.000000  70692.000000  \n",
       "mean       8.584055      4.920953      5.698311  \n",
       "std        2.852153      1.029081      2.175196  \n",
       "min        1.000000      1.000000      1.000000  \n",
       "25%        7.000000      4.000000      4.000000  \n",
       "50%        9.000000      5.000000      6.000000  \n",
       "75%       11.000000      6.000000      8.000000  \n",
       "max       13.000000      6.000000      8.000000  \n",
       "\n",
       "[8 rows x 22 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Describing the dataset\n",
    "diabetes.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 70692 entries, 0 to 70691\n",
      "Data columns (total 22 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   Diabetes_binary       70692 non-null  float64\n",
      " 1   HighBP                70692 non-null  float64\n",
      " 2   HighChol              70692 non-null  float64\n",
      " 3   CholCheck             70692 non-null  float64\n",
      " 4   BMI                   70692 non-null  float64\n",
      " 5   Smoker                70692 non-null  float64\n",
      " 6   Stroke                70692 non-null  float64\n",
      " 7   HeartDiseaseorAttack  70692 non-null  float64\n",
      " 8   PhysActivity          70692 non-null  float64\n",
      " 9   Fruits                70692 non-null  float64\n",
      " 10  Veggies               70692 non-null  float64\n",
      " 11  HvyAlcoholConsump     70692 non-null  float64\n",
      " 12  AnyHealthcare         70692 non-null  float64\n",
      " 13  NoDocbcCost           70692 non-null  float64\n",
      " 14  GenHlth               70692 non-null  float64\n",
      " 15  MentHlth              70692 non-null  float64\n",
      " 16  PhysHlth              70692 non-null  float64\n",
      " 17  DiffWalk              70692 non-null  float64\n",
      " 18  Sex                   70692 non-null  float64\n",
      " 19  Age                   70692 non-null  float64\n",
      " 20  Education             70692 non-null  float64\n",
      " 21  Income                70692 non-null  float64\n",
      "dtypes: float64(22)\n",
      "memory usage: 11.9 MB\n"
     ]
    }
   ],
   "source": [
    "# info about the dataset\n",
    "diabetes.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes_binary</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>...</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Diabetes_binary</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.381516</td>\n",
       "      <td>0.289213</td>\n",
       "      <td>0.115382</td>\n",
       "      <td>0.293373</td>\n",
       "      <td>0.085999</td>\n",
       "      <td>0.125427</td>\n",
       "      <td>0.211523</td>\n",
       "      <td>-0.158666</td>\n",
       "      <td>-0.054077</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023191</td>\n",
       "      <td>0.040977</td>\n",
       "      <td>0.407612</td>\n",
       "      <td>0.087029</td>\n",
       "      <td>0.213081</td>\n",
       "      <td>0.272646</td>\n",
       "      <td>0.044413</td>\n",
       "      <td>0.278738</td>\n",
       "      <td>-0.170481</td>\n",
       "      <td>-0.224449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HighBP</th>\n",
       "      <td>0.381516</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.316515</td>\n",
       "      <td>0.103283</td>\n",
       "      <td>0.241019</td>\n",
       "      <td>0.087438</td>\n",
       "      <td>0.129060</td>\n",
       "      <td>0.210750</td>\n",
       "      <td>-0.136102</td>\n",
       "      <td>-0.040852</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035764</td>\n",
       "      <td>0.026517</td>\n",
       "      <td>0.320540</td>\n",
       "      <td>0.064294</td>\n",
       "      <td>0.173922</td>\n",
       "      <td>0.234784</td>\n",
       "      <td>0.040819</td>\n",
       "      <td>0.338132</td>\n",
       "      <td>-0.141643</td>\n",
       "      <td>-0.187657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HighChol</th>\n",
       "      <td>0.289213</td>\n",
       "      <td>0.316515</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.085981</td>\n",
       "      <td>0.131309</td>\n",
       "      <td>0.093398</td>\n",
       "      <td>0.099786</td>\n",
       "      <td>0.181187</td>\n",
       "      <td>-0.090453</td>\n",
       "      <td>-0.047384</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031532</td>\n",
       "      <td>0.033199</td>\n",
       "      <td>0.237778</td>\n",
       "      <td>0.083881</td>\n",
       "      <td>0.142610</td>\n",
       "      <td>0.162043</td>\n",
       "      <td>0.017324</td>\n",
       "      <td>0.240338</td>\n",
       "      <td>-0.084386</td>\n",
       "      <td>-0.107777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CholCheck</th>\n",
       "      <td>0.115382</td>\n",
       "      <td>0.103283</td>\n",
       "      <td>0.085981</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.045648</td>\n",
       "      <td>-0.004331</td>\n",
       "      <td>0.022529</td>\n",
       "      <td>0.043497</td>\n",
       "      <td>-0.008249</td>\n",
       "      <td>0.017384</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106800</td>\n",
       "      <td>-0.062669</td>\n",
       "      <td>0.059213</td>\n",
       "      <td>-0.010660</td>\n",
       "      <td>0.034540</td>\n",
       "      <td>0.044430</td>\n",
       "      <td>-0.007991</td>\n",
       "      <td>0.101743</td>\n",
       "      <td>-0.008695</td>\n",
       "      <td>0.007550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMI</th>\n",
       "      <td>0.293373</td>\n",
       "      <td>0.241019</td>\n",
       "      <td>0.131309</td>\n",
       "      <td>0.045648</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.011551</td>\n",
       "      <td>0.022931</td>\n",
       "      <td>0.060355</td>\n",
       "      <td>-0.170936</td>\n",
       "      <td>-0.084505</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013417</td>\n",
       "      <td>0.065832</td>\n",
       "      <td>0.267888</td>\n",
       "      <td>0.104682</td>\n",
       "      <td>0.161862</td>\n",
       "      <td>0.246094</td>\n",
       "      <td>0.000827</td>\n",
       "      <td>-0.038648</td>\n",
       "      <td>-0.100233</td>\n",
       "      <td>-0.124878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Smoker</th>\n",
       "      <td>0.085999</td>\n",
       "      <td>0.087438</td>\n",
       "      <td>0.093398</td>\n",
       "      <td>-0.004331</td>\n",
       "      <td>0.011551</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.064658</td>\n",
       "      <td>0.124418</td>\n",
       "      <td>-0.079823</td>\n",
       "      <td>-0.074811</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012939</td>\n",
       "      <td>0.035799</td>\n",
       "      <td>0.152416</td>\n",
       "      <td>0.091257</td>\n",
       "      <td>0.120698</td>\n",
       "      <td>0.119789</td>\n",
       "      <td>0.112125</td>\n",
       "      <td>0.105424</td>\n",
       "      <td>-0.140966</td>\n",
       "      <td>-0.104725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stroke</th>\n",
       "      <td>0.125427</td>\n",
       "      <td>0.129060</td>\n",
       "      <td>0.099786</td>\n",
       "      <td>0.022529</td>\n",
       "      <td>0.022931</td>\n",
       "      <td>0.064658</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.223394</td>\n",
       "      <td>-0.079985</td>\n",
       "      <td>-0.008996</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006484</td>\n",
       "      <td>0.036198</td>\n",
       "      <td>0.189447</td>\n",
       "      <td>0.087303</td>\n",
       "      <td>0.164488</td>\n",
       "      <td>0.192266</td>\n",
       "      <td>0.003822</td>\n",
       "      <td>0.123879</td>\n",
       "      <td>-0.073926</td>\n",
       "      <td>-0.136577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <td>0.211523</td>\n",
       "      <td>0.210750</td>\n",
       "      <td>0.181187</td>\n",
       "      <td>0.043497</td>\n",
       "      <td>0.060355</td>\n",
       "      <td>0.124418</td>\n",
       "      <td>0.223394</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.098223</td>\n",
       "      <td>-0.019436</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015687</td>\n",
       "      <td>0.036029</td>\n",
       "      <td>0.275868</td>\n",
       "      <td>0.075057</td>\n",
       "      <td>0.198416</td>\n",
       "      <td>0.232611</td>\n",
       "      <td>0.098161</td>\n",
       "      <td>0.221878</td>\n",
       "      <td>-0.096559</td>\n",
       "      <td>-0.146748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhysActivity</th>\n",
       "      <td>-0.158666</td>\n",
       "      <td>-0.136102</td>\n",
       "      <td>-0.090453</td>\n",
       "      <td>-0.008249</td>\n",
       "      <td>-0.170936</td>\n",
       "      <td>-0.079823</td>\n",
       "      <td>-0.079985</td>\n",
       "      <td>-0.098223</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.133813</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027089</td>\n",
       "      <td>-0.063302</td>\n",
       "      <td>-0.273548</td>\n",
       "      <td>-0.130090</td>\n",
       "      <td>-0.234500</td>\n",
       "      <td>-0.276868</td>\n",
       "      <td>0.051753</td>\n",
       "      <td>-0.100753</td>\n",
       "      <td>0.190271</td>\n",
       "      <td>0.196551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fruits</th>\n",
       "      <td>-0.054077</td>\n",
       "      <td>-0.040852</td>\n",
       "      <td>-0.047384</td>\n",
       "      <td>0.017384</td>\n",
       "      <td>-0.084505</td>\n",
       "      <td>-0.074811</td>\n",
       "      <td>-0.008996</td>\n",
       "      <td>-0.019436</td>\n",
       "      <td>0.133813</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029385</td>\n",
       "      <td>-0.045843</td>\n",
       "      <td>-0.098687</td>\n",
       "      <td>-0.062102</td>\n",
       "      <td>-0.048572</td>\n",
       "      <td>-0.050784</td>\n",
       "      <td>-0.088723</td>\n",
       "      <td>0.061096</td>\n",
       "      <td>0.098715</td>\n",
       "      <td>0.079009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Veggies</th>\n",
       "      <td>-0.079293</td>\n",
       "      <td>-0.066624</td>\n",
       "      <td>-0.042836</td>\n",
       "      <td>0.000349</td>\n",
       "      <td>-0.056528</td>\n",
       "      <td>-0.029926</td>\n",
       "      <td>-0.047601</td>\n",
       "      <td>-0.036315</td>\n",
       "      <td>0.149322</td>\n",
       "      <td>0.238605</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029152</td>\n",
       "      <td>-0.037146</td>\n",
       "      <td>-0.115795</td>\n",
       "      <td>-0.052359</td>\n",
       "      <td>-0.066896</td>\n",
       "      <td>-0.084072</td>\n",
       "      <td>-0.052604</td>\n",
       "      <td>-0.018893</td>\n",
       "      <td>0.152512</td>\n",
       "      <td>0.154899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HvyAlcoholConsump</th>\n",
       "      <td>-0.094853</td>\n",
       "      <td>-0.027030</td>\n",
       "      <td>-0.025443</td>\n",
       "      <td>-0.027146</td>\n",
       "      <td>-0.058232</td>\n",
       "      <td>0.077835</td>\n",
       "      <td>-0.023395</td>\n",
       "      <td>-0.037130</td>\n",
       "      <td>0.019111</td>\n",
       "      <td>-0.033246</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013484</td>\n",
       "      <td>0.009683</td>\n",
       "      <td>-0.058796</td>\n",
       "      <td>0.015626</td>\n",
       "      <td>-0.036257</td>\n",
       "      <td>-0.049294</td>\n",
       "      <td>0.014164</td>\n",
       "      <td>-0.057705</td>\n",
       "      <td>0.036279</td>\n",
       "      <td>0.064095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <td>0.023191</td>\n",
       "      <td>0.035764</td>\n",
       "      <td>0.031532</td>\n",
       "      <td>0.106800</td>\n",
       "      <td>-0.013417</td>\n",
       "      <td>-0.012939</td>\n",
       "      <td>0.006484</td>\n",
       "      <td>0.015687</td>\n",
       "      <td>0.027089</td>\n",
       "      <td>0.029385</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.221658</td>\n",
       "      <td>-0.033060</td>\n",
       "      <td>-0.049850</td>\n",
       "      <td>-0.003285</td>\n",
       "      <td>0.008113</td>\n",
       "      <td>-0.006562</td>\n",
       "      <td>0.136975</td>\n",
       "      <td>0.106601</td>\n",
       "      <td>0.130492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <td>0.040977</td>\n",
       "      <td>0.026517</td>\n",
       "      <td>0.033199</td>\n",
       "      <td>-0.062669</td>\n",
       "      <td>0.065832</td>\n",
       "      <td>0.035799</td>\n",
       "      <td>0.036198</td>\n",
       "      <td>0.036029</td>\n",
       "      <td>-0.063302</td>\n",
       "      <td>-0.045843</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.221658</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.169515</td>\n",
       "      <td>0.193877</td>\n",
       "      <td>0.157451</td>\n",
       "      <td>0.127111</td>\n",
       "      <td>-0.048187</td>\n",
       "      <td>-0.129839</td>\n",
       "      <td>-0.096989</td>\n",
       "      <td>-0.198171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GenHlth</th>\n",
       "      <td>0.407612</td>\n",
       "      <td>0.320540</td>\n",
       "      <td>0.237778</td>\n",
       "      <td>0.059213</td>\n",
       "      <td>0.267888</td>\n",
       "      <td>0.152416</td>\n",
       "      <td>0.189447</td>\n",
       "      <td>0.275868</td>\n",
       "      <td>-0.273548</td>\n",
       "      <td>-0.098687</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033060</td>\n",
       "      <td>0.169515</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.315077</td>\n",
       "      <td>0.552757</td>\n",
       "      <td>0.476639</td>\n",
       "      <td>-0.014555</td>\n",
       "      <td>0.155624</td>\n",
       "      <td>-0.285420</td>\n",
       "      <td>-0.382969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MentHlth</th>\n",
       "      <td>0.087029</td>\n",
       "      <td>0.064294</td>\n",
       "      <td>0.083881</td>\n",
       "      <td>-0.010660</td>\n",
       "      <td>0.104682</td>\n",
       "      <td>0.091257</td>\n",
       "      <td>0.087303</td>\n",
       "      <td>0.075057</td>\n",
       "      <td>-0.130090</td>\n",
       "      <td>-0.062102</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.049850</td>\n",
       "      <td>0.193877</td>\n",
       "      <td>0.315077</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.380272</td>\n",
       "      <td>0.251489</td>\n",
       "      <td>-0.089204</td>\n",
       "      <td>-0.101746</td>\n",
       "      <td>-0.107005</td>\n",
       "      <td>-0.219070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhysHlth</th>\n",
       "      <td>0.213081</td>\n",
       "      <td>0.173922</td>\n",
       "      <td>0.142610</td>\n",
       "      <td>0.034540</td>\n",
       "      <td>0.161862</td>\n",
       "      <td>0.120698</td>\n",
       "      <td>0.164488</td>\n",
       "      <td>0.198416</td>\n",
       "      <td>-0.234500</td>\n",
       "      <td>-0.048572</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003285</td>\n",
       "      <td>0.157451</td>\n",
       "      <td>0.552757</td>\n",
       "      <td>0.380272</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.487976</td>\n",
       "      <td>-0.045957</td>\n",
       "      <td>0.084852</td>\n",
       "      <td>-0.159317</td>\n",
       "      <td>-0.279326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DiffWalk</th>\n",
       "      <td>0.272646</td>\n",
       "      <td>0.234784</td>\n",
       "      <td>0.162043</td>\n",
       "      <td>0.044430</td>\n",
       "      <td>0.246094</td>\n",
       "      <td>0.119789</td>\n",
       "      <td>0.192266</td>\n",
       "      <td>0.232611</td>\n",
       "      <td>-0.276868</td>\n",
       "      <td>-0.050784</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008113</td>\n",
       "      <td>0.127111</td>\n",
       "      <td>0.476639</td>\n",
       "      <td>0.251489</td>\n",
       "      <td>0.487976</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.082248</td>\n",
       "      <td>0.195265</td>\n",
       "      <td>-0.202590</td>\n",
       "      <td>-0.343245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>0.044413</td>\n",
       "      <td>0.040819</td>\n",
       "      <td>0.017324</td>\n",
       "      <td>-0.007991</td>\n",
       "      <td>0.000827</td>\n",
       "      <td>0.112125</td>\n",
       "      <td>0.003822</td>\n",
       "      <td>0.098161</td>\n",
       "      <td>0.051753</td>\n",
       "      <td>-0.088723</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006562</td>\n",
       "      <td>-0.048187</td>\n",
       "      <td>-0.014555</td>\n",
       "      <td>-0.089204</td>\n",
       "      <td>-0.045957</td>\n",
       "      <td>-0.082248</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.002315</td>\n",
       "      <td>0.043564</td>\n",
       "      <td>0.159654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0.278738</td>\n",
       "      <td>0.338132</td>\n",
       "      <td>0.240338</td>\n",
       "      <td>0.101743</td>\n",
       "      <td>-0.038648</td>\n",
       "      <td>0.105424</td>\n",
       "      <td>0.123879</td>\n",
       "      <td>0.221878</td>\n",
       "      <td>-0.100753</td>\n",
       "      <td>0.061096</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136975</td>\n",
       "      <td>-0.129839</td>\n",
       "      <td>0.155624</td>\n",
       "      <td>-0.101746</td>\n",
       "      <td>0.084852</td>\n",
       "      <td>0.195265</td>\n",
       "      <td>-0.002315</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.107127</td>\n",
       "      <td>-0.130140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Education</th>\n",
       "      <td>-0.170481</td>\n",
       "      <td>-0.141643</td>\n",
       "      <td>-0.084386</td>\n",
       "      <td>-0.008695</td>\n",
       "      <td>-0.100233</td>\n",
       "      <td>-0.140966</td>\n",
       "      <td>-0.073926</td>\n",
       "      <td>-0.096559</td>\n",
       "      <td>0.190271</td>\n",
       "      <td>0.098715</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106601</td>\n",
       "      <td>-0.096989</td>\n",
       "      <td>-0.285420</td>\n",
       "      <td>-0.107005</td>\n",
       "      <td>-0.159317</td>\n",
       "      <td>-0.202590</td>\n",
       "      <td>0.043564</td>\n",
       "      <td>-0.107127</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.460565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Income</th>\n",
       "      <td>-0.224449</td>\n",
       "      <td>-0.187657</td>\n",
       "      <td>-0.107777</td>\n",
       "      <td>0.007550</td>\n",
       "      <td>-0.124878</td>\n",
       "      <td>-0.104725</td>\n",
       "      <td>-0.136577</td>\n",
       "      <td>-0.146748</td>\n",
       "      <td>0.196551</td>\n",
       "      <td>0.079009</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130492</td>\n",
       "      <td>-0.198171</td>\n",
       "      <td>-0.382969</td>\n",
       "      <td>-0.219070</td>\n",
       "      <td>-0.279326</td>\n",
       "      <td>-0.343245</td>\n",
       "      <td>0.159654</td>\n",
       "      <td>-0.130140</td>\n",
       "      <td>0.460565</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Diabetes_binary    HighBP  HighChol  CholCheck  \\\n",
       "Diabetes_binary              1.000000  0.381516  0.289213   0.115382   \n",
       "HighBP                       0.381516  1.000000  0.316515   0.103283   \n",
       "HighChol                     0.289213  0.316515  1.000000   0.085981   \n",
       "CholCheck                    0.115382  0.103283  0.085981   1.000000   \n",
       "BMI                          0.293373  0.241019  0.131309   0.045648   \n",
       "Smoker                       0.085999  0.087438  0.093398  -0.004331   \n",
       "Stroke                       0.125427  0.129060  0.099786   0.022529   \n",
       "HeartDiseaseorAttack         0.211523  0.210750  0.181187   0.043497   \n",
       "PhysActivity                -0.158666 -0.136102 -0.090453  -0.008249   \n",
       "Fruits                      -0.054077 -0.040852 -0.047384   0.017384   \n",
       "Veggies                     -0.079293 -0.066624 -0.042836   0.000349   \n",
       "HvyAlcoholConsump           -0.094853 -0.027030 -0.025443  -0.027146   \n",
       "AnyHealthcare                0.023191  0.035764  0.031532   0.106800   \n",
       "NoDocbcCost                  0.040977  0.026517  0.033199  -0.062669   \n",
       "GenHlth                      0.407612  0.320540  0.237778   0.059213   \n",
       "MentHlth                     0.087029  0.064294  0.083881  -0.010660   \n",
       "PhysHlth                     0.213081  0.173922  0.142610   0.034540   \n",
       "DiffWalk                     0.272646  0.234784  0.162043   0.044430   \n",
       "Sex                          0.044413  0.040819  0.017324  -0.007991   \n",
       "Age                          0.278738  0.338132  0.240338   0.101743   \n",
       "Education                   -0.170481 -0.141643 -0.084386  -0.008695   \n",
       "Income                      -0.224449 -0.187657 -0.107777   0.007550   \n",
       "\n",
       "                           BMI    Smoker    Stroke  HeartDiseaseorAttack  \\\n",
       "Diabetes_binary       0.293373  0.085999  0.125427              0.211523   \n",
       "HighBP                0.241019  0.087438  0.129060              0.210750   \n",
       "HighChol              0.131309  0.093398  0.099786              0.181187   \n",
       "CholCheck             0.045648 -0.004331  0.022529              0.043497   \n",
       "BMI                   1.000000  0.011551  0.022931              0.060355   \n",
       "Smoker                0.011551  1.000000  0.064658              0.124418   \n",
       "Stroke                0.022931  0.064658  1.000000              0.223394   \n",
       "HeartDiseaseorAttack  0.060355  0.124418  0.223394              1.000000   \n",
       "PhysActivity         -0.170936 -0.079823 -0.079985             -0.098223   \n",
       "Fruits               -0.084505 -0.074811 -0.008996             -0.019436   \n",
       "Veggies              -0.056528 -0.029926 -0.047601             -0.036315   \n",
       "HvyAlcoholConsump    -0.058232  0.077835 -0.023395             -0.037130   \n",
       "AnyHealthcare        -0.013417 -0.012939  0.006484              0.015687   \n",
       "NoDocbcCost           0.065832  0.035799  0.036198              0.036029   \n",
       "GenHlth               0.267888  0.152416  0.189447              0.275868   \n",
       "MentHlth              0.104682  0.091257  0.087303              0.075057   \n",
       "PhysHlth              0.161862  0.120698  0.164488              0.198416   \n",
       "DiffWalk              0.246094  0.119789  0.192266              0.232611   \n",
       "Sex                   0.000827  0.112125  0.003822              0.098161   \n",
       "Age                  -0.038648  0.105424  0.123879              0.221878   \n",
       "Education            -0.100233 -0.140966 -0.073926             -0.096559   \n",
       "Income               -0.124878 -0.104725 -0.136577             -0.146748   \n",
       "\n",
       "                      PhysActivity    Fruits  ...  AnyHealthcare  NoDocbcCost  \\\n",
       "Diabetes_binary          -0.158666 -0.054077  ...       0.023191     0.040977   \n",
       "HighBP                   -0.136102 -0.040852  ...       0.035764     0.026517   \n",
       "HighChol                 -0.090453 -0.047384  ...       0.031532     0.033199   \n",
       "CholCheck                -0.008249  0.017384  ...       0.106800    -0.062669   \n",
       "BMI                      -0.170936 -0.084505  ...      -0.013417     0.065832   \n",
       "Smoker                   -0.079823 -0.074811  ...      -0.012939     0.035799   \n",
       "Stroke                   -0.079985 -0.008996  ...       0.006484     0.036198   \n",
       "HeartDiseaseorAttack     -0.098223 -0.019436  ...       0.015687     0.036029   \n",
       "PhysActivity              1.000000  0.133813  ...       0.027089    -0.063302   \n",
       "Fruits                    0.133813  1.000000  ...       0.029385    -0.045843   \n",
       "Veggies                   0.149322  0.238605  ...       0.029152    -0.037146   \n",
       "HvyAlcoholConsump         0.019111 -0.033246  ...      -0.013484     0.009683   \n",
       "AnyHealthcare             0.027089  0.029385  ...       1.000000    -0.221658   \n",
       "NoDocbcCost              -0.063302 -0.045843  ...      -0.221658     1.000000   \n",
       "GenHlth                  -0.273548 -0.098687  ...      -0.033060     0.169515   \n",
       "MentHlth                 -0.130090 -0.062102  ...      -0.049850     0.193877   \n",
       "PhysHlth                 -0.234500 -0.048572  ...      -0.003285     0.157451   \n",
       "DiffWalk                 -0.276868 -0.050784  ...       0.008113     0.127111   \n",
       "Sex                       0.051753 -0.088723  ...      -0.006562    -0.048187   \n",
       "Age                      -0.100753  0.061096  ...       0.136975    -0.129839   \n",
       "Education                 0.190271  0.098715  ...       0.106601    -0.096989   \n",
       "Income                    0.196551  0.079009  ...       0.130492    -0.198171   \n",
       "\n",
       "                       GenHlth  MentHlth  PhysHlth  DiffWalk       Sex  \\\n",
       "Diabetes_binary       0.407612  0.087029  0.213081  0.272646  0.044413   \n",
       "HighBP                0.320540  0.064294  0.173922  0.234784  0.040819   \n",
       "HighChol              0.237778  0.083881  0.142610  0.162043  0.017324   \n",
       "CholCheck             0.059213 -0.010660  0.034540  0.044430 -0.007991   \n",
       "BMI                   0.267888  0.104682  0.161862  0.246094  0.000827   \n",
       "Smoker                0.152416  0.091257  0.120698  0.119789  0.112125   \n",
       "Stroke                0.189447  0.087303  0.164488  0.192266  0.003822   \n",
       "HeartDiseaseorAttack  0.275868  0.075057  0.198416  0.232611  0.098161   \n",
       "PhysActivity         -0.273548 -0.130090 -0.234500 -0.276868  0.051753   \n",
       "Fruits               -0.098687 -0.062102 -0.048572 -0.050784 -0.088723   \n",
       "Veggies              -0.115795 -0.052359 -0.066896 -0.084072 -0.052604   \n",
       "HvyAlcoholConsump    -0.058796  0.015626 -0.036257 -0.049294  0.014164   \n",
       "AnyHealthcare        -0.033060 -0.049850 -0.003285  0.008113 -0.006562   \n",
       "NoDocbcCost           0.169515  0.193877  0.157451  0.127111 -0.048187   \n",
       "GenHlth               1.000000  0.315077  0.552757  0.476639 -0.014555   \n",
       "MentHlth              0.315077  1.000000  0.380272  0.251489 -0.089204   \n",
       "PhysHlth              0.552757  0.380272  1.000000  0.487976 -0.045957   \n",
       "DiffWalk              0.476639  0.251489  0.487976  1.000000 -0.082248   \n",
       "Sex                  -0.014555 -0.089204 -0.045957 -0.082248  1.000000   \n",
       "Age                   0.155624 -0.101746  0.084852  0.195265 -0.002315   \n",
       "Education            -0.285420 -0.107005 -0.159317 -0.202590  0.043564   \n",
       "Income               -0.382969 -0.219070 -0.279326 -0.343245  0.159654   \n",
       "\n",
       "                           Age  Education    Income  \n",
       "Diabetes_binary       0.278738  -0.170481 -0.224449  \n",
       "HighBP                0.338132  -0.141643 -0.187657  \n",
       "HighChol              0.240338  -0.084386 -0.107777  \n",
       "CholCheck             0.101743  -0.008695  0.007550  \n",
       "BMI                  -0.038648  -0.100233 -0.124878  \n",
       "Smoker                0.105424  -0.140966 -0.104725  \n",
       "Stroke                0.123879  -0.073926 -0.136577  \n",
       "HeartDiseaseorAttack  0.221878  -0.096559 -0.146748  \n",
       "PhysActivity         -0.100753   0.190271  0.196551  \n",
       "Fruits                0.061096   0.098715  0.079009  \n",
       "Veggies              -0.018893   0.152512  0.154899  \n",
       "HvyAlcoholConsump    -0.057705   0.036279  0.064095  \n",
       "AnyHealthcare         0.136975   0.106601  0.130492  \n",
       "NoDocbcCost          -0.129839  -0.096989 -0.198171  \n",
       "GenHlth               0.155624  -0.285420 -0.382969  \n",
       "MentHlth             -0.101746  -0.107005 -0.219070  \n",
       "PhysHlth              0.084852  -0.159317 -0.279326  \n",
       "DiffWalk              0.195265  -0.202590 -0.343245  \n",
       "Sex                  -0.002315   0.043564  0.159654  \n",
       "Age                   1.000000  -0.107127 -0.130140  \n",
       "Education            -0.107127   1.000000  0.460565  \n",
       "Income               -0.130140   0.460565  1.000000  \n",
       "\n",
       "[22 rows x 22 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes_binary</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Diabetes_binary  HighBP  HighChol  CholCheck   BMI  Stroke  \\\n",
       "0              0.0     1.0       0.0        1.0  26.0     0.0   \n",
       "1              0.0     1.0       1.0        1.0  26.0     1.0   \n",
       "2              0.0     0.0       0.0        1.0  26.0     0.0   \n",
       "3              0.0     1.0       1.0        1.0  28.0     0.0   \n",
       "4              0.0     0.0       0.0        1.0  29.0     0.0   \n",
       "\n",
       "   HeartDiseaseorAttack  PhysActivity  GenHlth  PhysHlth  DiffWalk   Age  \\\n",
       "0                   0.0           1.0      3.0      30.0       0.0   4.0   \n",
       "1                   0.0           0.0      3.0       0.0       0.0  12.0   \n",
       "2                   0.0           1.0      1.0      10.0       0.0  13.0   \n",
       "3                   0.0           1.0      3.0       3.0       0.0  11.0   \n",
       "4                   0.0           1.0      2.0       0.0       0.0   8.0   \n",
       "\n",
       "   Education  Income  \n",
       "0        6.0     8.0  \n",
       "1        6.0     8.0  \n",
       "2        6.0     8.0  \n",
       "3        6.0     8.0  \n",
       "4        5.0     8.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dropping columns that may not be helpful for analysis, heavy alcohol consumption removed since because it is self reported it may not be as honest\n",
    "columns_to_drop = ['Fruits', 'Veggies', 'MentHlth', 'NoDocbcCost', 'Sex', 'AnyHealthcare', 'HvyAlcoholConsump', 'Smoker']\n",
    "diabetes_df = diabetes.copy()\n",
    "diabetes_df = diabetes_df.drop(columns=columns_to_drop)\n",
    "diabetes_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Grouping (using functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age\n",
    "1. Age 18 to 24\n",
    "2. Age 25 to 29\n",
    "3. Age 30 to 34\n",
    "4. Age 35 to 39\n",
    "5. Age 40 to 44\n",
    "6. Age 45 to 49\n",
    "7. Age 50 to 54\n",
    "8. Age 55 to 59\n",
    "9. Age 60 to 64\n",
    "10. Age 65 to 69\n",
    "11. Age 70 to 74\n",
    "12. Age 75 to 79\n",
    "13. Age 80 or older\n",
    "\n",
    "#### split every three groups\n",
    "#### 1 = 18-34 (1-3), 2 = 35-49 (4-6), 3 = 50-64 (7-9), 4 = 65-79 (10-12), 5 = 80+ (13) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age\n",
       "10.0    10856\n",
       "9.0     10112\n",
       "8.0      8603\n",
       "11.0     8044\n",
       "7.0      6872\n",
       "13.0     5426\n",
       "12.0     5394\n",
       "6.0      4648\n",
       "5.0      3520\n",
       "4.0      2793\n",
       "3.0      2049\n",
       "2.0      1396\n",
       "1.0       979\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_df['Age'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def age_replace(x):\n",
    "#     if x >= 1 and x <= 3:\n",
    "#         return \"Age 18-34\"\n",
    "#     elif x > 3 and x <= 6:\n",
    "#         return \"Age 35-49\"\n",
    "#     elif x > 6 and x <= 9:\n",
    "#         return \"Age 50-64\"\n",
    "#     elif x > 9 and x <= 12:\n",
    "#         return \"Age 65-79\"\n",
    "#     elif x > 12:\n",
    "#         return \"Age 80+\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diabetes_df['Age'] = diabetes_df['Age'].apply(age_replace)\n",
    "# diabetes_df['Age'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDUCATION\n",
    "1. Never attended school or only kindergarten\n",
    "2. Grades 1 through 8 (Elementary)\n",
    "3. Grades 9 through 11 (Some high school)\n",
    "4. Grade 12 or GED (High school graduate)\n",
    "5. College 1 year to 3 years (Some college or technical school)\n",
    "6. College 4 years or more (College graduate)\n",
    "\n",
    "#### split between : higher vs non-higher edu, 5-6 higher, 1-4 lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def edu_replace(x):\n",
    "#     if x >= 1 and x <= 4:\n",
    "#         return \"Lower Education\"\n",
    "#     elif x > 4:\n",
    "#         return \"Higher Education\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diabetes_df['Education'] = diabetes_df['Education'].apply(edu_replace)\n",
    "# diabetes_df['Education'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INCOME\n",
    "1. Less than $10,000\n",
    "2. Less than $15,000 ($10,000 to less than $15,000)\n",
    "3. Less than $20,000 ($15,000 to less than $20,000)\n",
    "4. Less than $25,000 ($20,000 to less than $25,000)\n",
    "5. Less than $35,000 ($25,000 to less than $35,000)\n",
    "6. Less than $50,000 ($35,000 to less than $50,000)\n",
    "7. Less than $75,000 ($50,000 to less than $75,000)\n",
    "8. $75,000 or more\n",
    "\n",
    "#### group 1-3, 4-7, 8 by itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Income\n",
       "8.0    20646\n",
       "7.0    11425\n",
       "6.0    10287\n",
       "5.0     8010\n",
       "4.0     6658\n",
       "3.0     5557\n",
       "2.0     4498\n",
       "1.0     3611\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_df['Income'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def income_replace(x):\n",
    "#     if x >= 1 and x <= 3:\n",
    "#         return \"Less than $20,000\"\n",
    "#     elif x > 3 and x <= 7:\n",
    "#         return \"Between $20,000 and $75,000\"\n",
    "#     elif x > 7:\n",
    "#         return \"More than $75,000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diabetes_df['Income'] = diabetes_df['Income'].apply(income_replace)\n",
    "# diabetes_df['Income'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BMI_classification(x):\n",
    "    if x < 18.5:\n",
    "        return \"Underweight\"\n",
    "    elif x > 18.5 and x <=24.9:\n",
    "        return \"Normal\"\n",
    "    elif x > 24.9 and x <= 29.9:\n",
    "        return \"Overweight\"\n",
    "    elif x > 29.9 and x <= 34.9:\n",
    "        return \"Obesity 1\"\n",
    "    elif x > 34.9 and x <= 39.9:\n",
    "        return \"Obesity 2\"\n",
    "    elif x > 39.9:\n",
    "        return \"Obesity 3\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BMI\n",
       "Overweight     24135\n",
       "Obesity 1      17301\n",
       "Normal         14460\n",
       "Obesity 2       8112\n",
       "Obesity 3       6031\n",
       "Underweight      653\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_df['BMI'] = diabetes_df['BMI'].apply(BMI_classification)\n",
    "diabetes_df['BMI'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin Splitting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = diabetes_df.drop(columns='Diabetes_binary')\n",
    "y = diabetes_df['Diabetes_binary']\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, random_state=12)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding Categorical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BMI    0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "BMI    0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create encoder and fit\n",
    "encode_BMI = OrdinalEncoder(categories=[['Underweight', 'Normal', 'Overweight', 'Obesity 1', 'Obesity 2', 'Obesity 3']], handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "encode_BMI.fit(x_train['BMI'].values.reshape(-1,1))\n",
    "encode_BMI_train = encode_BMI.transform(x_train['BMI'].values.reshape(-1, 1))\n",
    "encode_BMI_test = encode_BMI.transform(x_test['BMI'].values.reshape(-1, 1))\n",
    "\n",
    "# create the df\n",
    "encode_BMI_df_train = pd.DataFrame(encode_BMI_train, columns=['BMI'])\n",
    "encode_BMI_df_test = pd.DataFrame(encode_BMI_test, columns=['BMI'])\n",
    "encode_BMI_df_train.head()\n",
    "display(encode_BMI_df_train.isna().sum())\n",
    "display(encode_BMI_df_test.isna().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create encoder and fit\n",
    "# encode_income = OrdinalEncoder(categories=[['Less than $20,000','Between $20,000 and $75,000','More than $75,000']], handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "# encode_income.fit(x_train['Income'].values.reshape(-1,1))\n",
    "# encode_income_train = encode_income.transform(x_train['Income'].values.reshape(-1, 1))\n",
    "# encode_income_test = encode_income.transform(x_test['Income'].values.reshape(-1, 1))\n",
    "\n",
    "# # create the df\n",
    "# encode_income_df_train = pd.DataFrame(encode_income_train, columns=['Income'])\n",
    "# encode_income_df_test = pd.DataFrame(encode_income_test, columns=['Income'])\n",
    "# display(encode_income_df_train.isna().sum())\n",
    "# display(encode_income_df_test.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create encoder and fit \n",
    "# encode_educ = OrdinalEncoder(categories=[['Lower Education', 'Higher Education']], handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "# encode_educ.fit(x_train['Education'].values.reshape(-1,1))\n",
    "# encode_educ_train = encode_educ.transform(x_train['Education'].values.reshape(-1, 1))\n",
    "# encode_educ_test = encode_educ.transform(x_test['Education'].values.reshape(-1, 1))\n",
    "\n",
    "# # create the df\n",
    "# encode_educ_df_train = pd.DataFrame(encode_educ_train, columns=['Education'])\n",
    "# encode_educ_df_test = pd.DataFrame(encode_educ_test, columns=['Education'])\n",
    "\n",
    "# display(encode_educ_df_train.isna().sum())\n",
    "# display(encode_educ_df_test.isna().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age\n",
       "10.0    8110\n",
       "9.0     7591\n",
       "8.0     6414\n",
       "11.0    5997\n",
       "7.0     5156\n",
       "13.0    4130\n",
       "12.0    4031\n",
       "6.0     3502\n",
       "5.0     2660\n",
       "4.0     2099\n",
       "3.0     1533\n",
       "2.0     1042\n",
       "1.0      754\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the original columns names for the age column\n",
    "#diabetes_df['Age'].value_counts()\n",
    "x_train['Age'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Education\n",
       "6.0    19477\n",
       "5.0    15026\n",
       "4.0    14646\n",
       "3.0     2574\n",
       "2.0     1238\n",
       "1.0       58\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train['Education'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create encoder and fit \n",
    "# encode_age = OrdinalEncoder(categories=[['Age 18-34', 'Age 35-49', 'Age 50-64', 'Age 65-79', 'Age 80+']], handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "# encode_age.fit(x_train['Age'].values.reshape(-1,1))\n",
    "# encode_age_train = encode_age.transform(x_train['Age'].values.reshape(-1, 1))\n",
    "# encode_age_test = encode_age.transform(x_test['Age'].values.reshape(-1, 1))\n",
    "\n",
    "# # create the df\n",
    "# encode_age_df_train = pd.DataFrame(encode_age_train, columns=['Age'])\n",
    "# encode_age_df_test = pd.DataFrame(encode_age_test, columns=['Age'])\n",
    "\n",
    "# display(encode_age_df_train.isna().sum())\n",
    "# display(encode_age_df_test.isna().sum())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Group all encoded_dfs with the main df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HighBP                  0\n",
       "HighChol                0\n",
       "CholCheck               0\n",
       "Stroke                  0\n",
       "HeartDiseaseorAttack    0\n",
       "PhysActivity            0\n",
       "GenHlth                 0\n",
       "PhysHlth                0\n",
       "DiffWalk                0\n",
       "Age                     0\n",
       "Education               0\n",
       "Income                  0\n",
       "BMI                     0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "HighBP                  0\n",
       "HighChol                0\n",
       "CholCheck               0\n",
       "Stroke                  0\n",
       "HeartDiseaseorAttack    0\n",
       "PhysActivity            0\n",
       "GenHlth                 0\n",
       "PhysHlth                0\n",
       "DiffWalk                0\n",
       "Age                     0\n",
       "Education               0\n",
       "Income                  0\n",
       "BMI                     0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create a copy of the df without the unencoded columns\n",
    "# train\n",
    "x_train_unencoded = x_train.copy().drop(columns=['BMI'])\n",
    "x_train_unencoded = x_train_unencoded.reset_index(drop=True)\n",
    "# test\n",
    "x_test_unencoded = x_test.copy().drop(columns=['BMI'])\n",
    "x_test_unencoded = x_test_unencoded.reset_index(drop=True)\n",
    "\n",
    "# add the encoded columns\n",
    "x_train_encoded = pd.concat([x_train_unencoded, encode_BMI_df_train], axis=1)\n",
    "x_test_encoded = pd.concat([x_test_unencoded, encode_BMI_df_test], axis=1)\n",
    "\n",
    "# the results\n",
    "display(x_train_encoded.isna().sum())\n",
    "display(x_test_encoded.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale the data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train_encoded)\n",
    "x_train_encoded = scaler.transform(x_train_encoded)\n",
    "x_test_encoded = scaler.transform(x_test_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the ML Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 1, Train/Test Score: 0.916/0.663\n",
      "k: 3, Train/Test Score: 0.816/0.699\n",
      "k: 5, Train/Test Score: 0.790/0.714\n",
      "k: 7, Train/Test Score: 0.779/0.723\n",
      "k: 9, Train/Test Score: 0.773/0.730\n",
      "k: 11, Train/Test Score: 0.767/0.734\n",
      "k: 13, Train/Test Score: 0.765/0.735\n",
      "k: 15, Train/Test Score: 0.763/0.739\n",
      "k: 17, Train/Test Score: 0.761/0.742\n",
      "k: 19, Train/Test Score: 0.760/0.743\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loop through different k values to find which has the highest accuracy.\n",
    "# Note: We use only odd numbers because we don't want any ties.\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for k in range(1, 20, 2):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(x_train_encoded, y_train)\n",
    "    train_score = knn.score(x_train_encoded, y_train)\n",
    "    test_score = knn.score(x_test_encoded, y_test)\n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "    print(f\"k: {k}, Train/Test Score: {train_score:.3f}/{test_score:.3f}\")\n",
    "    \n",
    "# Plot the results\n",
    "plt.plot(range(1, 20, 2), train_scores, marker='o', label=\"training scores\")\n",
    "plt.plot(range(1, 20, 2), test_scores, marker=\"x\", label=\"testing scores\")\n",
    "plt.xlabel(\"k neighbors\")\n",
    "plt.ylabel(\"accuracy score\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7522209019408137"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.74      0.75      8847\n",
      "         1.0       0.74      0.77      0.76      8826\n",
      "\n",
      "    accuracy                           0.75     17673\n",
      "   macro avg       0.75      0.75      0.75     17673\n",
      "weighted avg       0.75      0.75      0.75     17673\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Create and fit the logistic regression model\n",
    "logistic_regression_model = LogisticRegression(random_state=1, max_iter=1000)\n",
    "logistic_regression_model.fit(x_train_encoded, y_train)\n",
    "\n",
    "#make and save testing predictions with the saved logistic regression model using the test data\n",
    "predictions = logistic_regression_model.predict(x_test_encoded)\n",
    "\n",
    "# Review the accuracy\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "display(accuracy)\n",
    "\n",
    "#print the confusion matrix\n",
    "confusion_matrix(y_test, predictions)\n",
    "\n",
    "#print the classification report\n",
    "print(classification_report(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.751145815650993 (ungrouping age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.6684773383126804\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>6228</td>\n",
       "      <td>2619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>3240</td>\n",
       "      <td>5586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0         6228         2619\n",
       "Actual 1         3240         5586"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.66      0.70      0.68      8847\n",
      "         1.0       0.68      0.63      0.66      8826\n",
      "\n",
      "    accuracy                           0.67     17673\n",
      "   macro avg       0.67      0.67      0.67     17673\n",
      "weighted avg       0.67      0.67      0.67     17673\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create the model\n",
    "tree_model = tree.DecisionTreeClassifier()\n",
    "#fit the model\n",
    "tree_model = tree_model.fit(x_train_encoded, y_train)\n",
    "# Making predictions using the testing data\n",
    "predictions = tree_model.predict(x_test_encoded)\n",
    "# Calculate the accuracy score\n",
    "acc_score = accuracy_score(y_test, predictions)\n",
    "print(f\"Accuracy Score : {acc_score}\")\n",
    "\n",
    "# Display the confusion matrix\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"]\n",
    ")\n",
    "\n",
    "# Displaying results\n",
    "print(\"Confusion Matrix\")\n",
    "display(cm_df)\n",
    "# Display the classification report\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.7765329410211433\n",
      "Testing Score: 0.7536354891642618\n",
      "Accuracy Score : 0.7536354891642618\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>6355</td>\n",
       "      <td>2492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>1862</td>\n",
       "      <td>6964</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0         6355         2492\n",
       "Actual 1         1862         6964"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.72      0.74      8847\n",
      "         1.0       0.74      0.79      0.76      8826\n",
      "\n",
      "    accuracy                           0.75     17673\n",
      "   macro avg       0.75      0.75      0.75     17673\n",
      "weighted avg       0.75      0.75      0.75     17673\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the Random Forest model\n",
    "clf = RandomForestClassifier(random_state=1, n_estimators=500, max_depth=11).fit(x_train_encoded, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "print(f'Training Score: {clf.score(x_train_encoded, y_train)}')\n",
    "print(f'Testing Score: {clf.score(x_test_encoded, y_test)}')\n",
    "\n",
    "# Calculate the accuracy score\n",
    "predictions = clf.predict(x_test_encoded)\n",
    "acc_score = accuracy_score(y_test, predictions)\n",
    "print(f\"Accuracy Score : {acc_score}\")\n",
    "\n",
    "# Display the confusion matrix\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"]\n",
    ")\n",
    "\n",
    "# Displaying results\n",
    "print(\"Confusion Matrix\")\n",
    "display(cm_df)\n",
    "# Display the classification report\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, predictions))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7562949131443445\n",
      "Confusion Matrix: [[6322 2525]\n",
      " [1782 7044]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.71      0.75      8847\n",
      "         1.0       0.74      0.80      0.77      8826\n",
      "\n",
      "    accuracy                           0.76     17673\n",
      "   macro avg       0.76      0.76      0.76     17673\n",
      "weighted avg       0.76      0.76      0.76     17673\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "# Create the XGBClassifier model\n",
    "xgb_model = XGBClassifier(random_state=1, learning_rate=0.05, n_estimators=1000, max_depth=3)\n",
    "# Fit the model\n",
    "xgb_model.fit(x_train_encoded, y_train)\n",
    "# Make predictions\n",
    "predictions = xgb_model.predict(x_test_encoded)\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Create the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, predictions)\n",
    "print(f\"Confusion Matrix: {conf_matrix}\")\n",
    "\n",
    "#create heatmap for confusion matrix\n",
    "sns.heatmap(conf_matrix, annot=True, cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#Create the classification report\n",
    "class_report = classification_report(y_test, predictions)\n",
    "print(f\"Classification Report: \\n{class_report}\")\n",
    "\n",
    "# # Create the ROC curve\n",
    "# RocCurveDisplay.from_estimator(xgb_model, x_test_encoded, y_test)\n",
    "# plt.show()\n",
    "\n",
    "# Create the precision-recall curve\n",
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "\n",
    "# PrecisionRecallDisplay.from_estimator(xgb_model, x_test_encoded, y_test)\n",
    "# plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV 1/5] END .....max_depth=3, n_estimators=100;, score=0.741 total time=   0.5s\n",
      "[CV 2/5] END .....max_depth=3, n_estimators=100;, score=0.727 total time=   0.5s\n",
      "[CV 3/5] END .....max_depth=3, n_estimators=100;, score=0.731 total time=   0.5s\n",
      "[CV 4/5] END .....max_depth=3, n_estimators=100;, score=0.729 total time=   0.5s\n",
      "[CV 5/5] END .....max_depth=3, n_estimators=100;, score=0.741 total time=   0.5s\n",
      "[CV 1/5] END .....max_depth=3, n_estimators=500;, score=0.743 total time=   2.4s\n",
      "[CV 2/5] END .....max_depth=3, n_estimators=500;, score=0.726 total time=   2.4s\n",
      "[CV 3/5] END .....max_depth=3, n_estimators=500;, score=0.732 total time=   2.4s\n",
      "[CV 4/5] END .....max_depth=3, n_estimators=500;, score=0.731 total time=   2.4s\n",
      "[CV 5/5] END .....max_depth=3, n_estimators=500;, score=0.741 total time=   2.4s\n",
      "[CV 1/5] END ....max_depth=3, n_estimators=1000;, score=0.743 total time=   4.8s\n",
      "[CV 2/5] END ....max_depth=3, n_estimators=1000;, score=0.728 total time=   4.7s\n",
      "[CV 3/5] END ....max_depth=3, n_estimators=1000;, score=0.734 total time=   4.8s\n",
      "[CV 4/5] END ....max_depth=3, n_estimators=1000;, score=0.732 total time=   4.7s\n",
      "[CV 5/5] END ....max_depth=3, n_estimators=1000;, score=0.740 total time=   4.8s\n",
      "[CV 1/5] END .....max_depth=7, n_estimators=100;, score=0.752 total time=   0.7s\n",
      "[CV 2/5] END .....max_depth=7, n_estimators=100;, score=0.736 total time=   0.7s\n",
      "[CV 3/5] END .....max_depth=7, n_estimators=100;, score=0.743 total time=   0.7s\n",
      "[CV 4/5] END .....max_depth=7, n_estimators=100;, score=0.740 total time=   0.7s\n",
      "[CV 5/5] END .....max_depth=7, n_estimators=100;, score=0.748 total time=   0.7s\n",
      "[CV 1/5] END .....max_depth=7, n_estimators=500;, score=0.753 total time=   3.6s\n",
      "[CV 2/5] END .....max_depth=7, n_estimators=500;, score=0.738 total time=   3.6s\n",
      "[CV 3/5] END .....max_depth=7, n_estimators=500;, score=0.743 total time=   3.7s\n",
      "[CV 4/5] END .....max_depth=7, n_estimators=500;, score=0.740 total time=   3.7s\n",
      "[CV 5/5] END .....max_depth=7, n_estimators=500;, score=0.747 total time=   3.9s\n",
      "[CV 1/5] END ....max_depth=7, n_estimators=1000;, score=0.752 total time=   7.6s\n",
      "[CV 2/5] END ....max_depth=7, n_estimators=1000;, score=0.738 total time=   7.5s\n",
      "[CV 3/5] END ....max_depth=7, n_estimators=1000;, score=0.741 total time=   7.8s\n",
      "[CV 4/5] END ....max_depth=7, n_estimators=1000;, score=0.740 total time=   8.0s\n",
      "[CV 5/5] END ....max_depth=7, n_estimators=1000;, score=0.746 total time=   7.7s\n",
      "[CV 1/5] END ....max_depth=11, n_estimators=100;, score=0.752 total time=   1.0s\n",
      "[CV 2/5] END ....max_depth=11, n_estimators=100;, score=0.738 total time=   1.0s\n",
      "[CV 3/5] END ....max_depth=11, n_estimators=100;, score=0.745 total time=   1.2s\n",
      "[CV 4/5] END ....max_depth=11, n_estimators=100;, score=0.741 total time=   1.0s\n",
      "[CV 5/5] END ....max_depth=11, n_estimators=100;, score=0.750 total time=   1.0s\n",
      "[CV 1/5] END ....max_depth=11, n_estimators=500;, score=0.754 total time=   5.0s\n",
      "[CV 2/5] END ....max_depth=11, n_estimators=500;, score=0.738 total time=   5.2s\n",
      "[CV 3/5] END ....max_depth=11, n_estimators=500;, score=0.744 total time=   5.1s\n",
      "[CV 4/5] END ....max_depth=11, n_estimators=500;, score=0.742 total time=   5.1s\n",
      "[CV 5/5] END ....max_depth=11, n_estimators=500;, score=0.751 total time=   5.0s\n",
      "[CV 1/5] END ...max_depth=11, n_estimators=1000;, score=0.755 total time=  10.3s\n",
      "[CV 2/5] END ...max_depth=11, n_estimators=1000;, score=0.738 total time=  10.1s\n",
      "[CV 3/5] END ...max_depth=11, n_estimators=1000;, score=0.743 total time=  10.8s\n",
      "[CV 4/5] END ...max_depth=11, n_estimators=1000;, score=0.740 total time=  10.5s\n",
      "[CV 5/5] END ...max_depth=11, n_estimators=1000;, score=0.750 total time=  10.9s\n",
      "Accuracy: 0.7536354891642618\n",
      "{'max_depth': 11, 'n_estimators': 500}\n",
      "0.7458270566257893\n"
     ]
    }
   ],
   "source": [
    "#grid search\n",
    "\n",
    "#%pip install -U xgboost scikit-learn\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create the parameter grid for the GridSearchCV model running random forest\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 500, 1000],\n",
    "    'max_depth': [3, 7, 11]\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "# Create the GridSearchCV model\n",
    "#grid_model = GridSearchCV(logistic_regression_model, param_grid, verbose=3)\n",
    "grid_model = GridSearchCV(RandomForestClassifier(), param_grid, verbose=3)\n",
    "\n",
    "# Fit the model\n",
    "grid_model.fit(x_train_encoded, y_train)\n",
    "\n",
    "# Make predictions\n",
    "predictions = grid_model.predict(x_test_encoded)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Print the best parameters\n",
    "print(grid_model.best_params_)\n",
    "print(grid_model.best_score_)\n",
    "# print(grid_model.best_estimator_)\n",
    "# print(grid_model.cv_results_)\n",
    "# print(grid_model.best_index_)\n",
    "# print(grid_model.scorer_)\n",
    "# print(grid_model.n_splits_)\n",
    "# print(grid_model.refit_time_)\n",
    "# print(grid_model.error_score)\n",
    "# print(grid_model.param_grid)\n",
    "# print(grid_model.pre_dispatch)\n",
    "# print(grid_model.return_train_score)\n",
    "# print(grid_model.multimetric_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy: 0.7536354891642618\n",
    "{'max_depth': 11, 'n_estimators': 500}\n",
    "0.7458270566257893\n",
    "Testing Score: 0.753522322186386\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "[CV 1/5] END C=0.1, max_iter=100, penalty=l1, solver=liblinear;, score=0.752 total time=   0.1s\n",
      "[CV 2/5] END C=0.1, max_iter=100, penalty=l1, solver=liblinear;, score=0.740 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, max_iter=100, penalty=l1, solver=liblinear;, score=0.740 total time=   0.1s\n",
      "[CV 4/5] END C=0.1, max_iter=100, penalty=l1, solver=liblinear;, score=0.739 total time=   0.1s\n",
      "[CV 5/5] END C=0.1, max_iter=100, penalty=l1, solver=liblinear;, score=0.743 total time=   0.0s\n",
      "[CV 1/5] END C=0.1, max_iter=100, penalty=l2, solver=liblinear;, score=0.752 total time=   0.1s\n",
      "[CV 2/5] END C=0.1, max_iter=100, penalty=l2, solver=liblinear;, score=0.739 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, max_iter=100, penalty=l2, solver=liblinear;, score=0.740 total time=   0.1s\n",
      "[CV 4/5] END C=0.1, max_iter=100, penalty=l2, solver=liblinear;, score=0.739 total time=   0.1s\n",
      "[CV 5/5] END C=0.1, max_iter=100, penalty=l2, solver=liblinear;, score=0.743 total time=   0.1s\n",
      "[CV 1/5] END C=0.1, max_iter=1000, penalty=l1, solver=liblinear;, score=0.752 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, max_iter=1000, penalty=l1, solver=liblinear;, score=0.740 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, max_iter=1000, penalty=l1, solver=liblinear;, score=0.740 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, max_iter=1000, penalty=l1, solver=liblinear;, score=0.739 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, max_iter=1000, penalty=l1, solver=liblinear;, score=0.743 total time=   0.1s\n",
      "[CV 1/5] END C=0.1, max_iter=1000, penalty=l2, solver=liblinear;, score=0.752 total time=   0.1s\n",
      "[CV 2/5] END C=0.1, max_iter=1000, penalty=l2, solver=liblinear;, score=0.739 total time=   0.1s\n",
      "[CV 3/5] END C=0.1, max_iter=1000, penalty=l2, solver=liblinear;, score=0.740 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, max_iter=1000, penalty=l2, solver=liblinear;, score=0.739 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, max_iter=1000, penalty=l2, solver=liblinear;, score=0.743 total time=   0.1s\n",
      "[CV 1/5] END C=0.1, max_iter=10000, penalty=l1, solver=liblinear;, score=0.752 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, max_iter=10000, penalty=l1, solver=liblinear;, score=0.740 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, max_iter=10000, penalty=l1, solver=liblinear;, score=0.740 total time=   0.1s\n",
      "[CV 4/5] END C=0.1, max_iter=10000, penalty=l1, solver=liblinear;, score=0.739 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, max_iter=10000, penalty=l1, solver=liblinear;, score=0.743 total time=   0.1s\n",
      "[CV 1/5] END C=0.1, max_iter=10000, penalty=l2, solver=liblinear;, score=0.752 total time=   0.1s\n",
      "[CV 2/5] END C=0.1, max_iter=10000, penalty=l2, solver=liblinear;, score=0.739 total time=   0.1s\n",
      "[CV 3/5] END C=0.1, max_iter=10000, penalty=l2, solver=liblinear;, score=0.740 total time=   0.1s\n",
      "[CV 4/5] END C=0.1, max_iter=10000, penalty=l2, solver=liblinear;, score=0.739 total time=   0.1s\n",
      "[CV 5/5] END C=0.1, max_iter=10000, penalty=l2, solver=liblinear;, score=0.743 total time=   0.1s\n",
      "[CV 1/5] END C=1, max_iter=100, penalty=l1, solver=liblinear;, score=0.752 total time=   0.1s\n",
      "[CV 2/5] END C=1, max_iter=100, penalty=l1, solver=liblinear;, score=0.739 total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=100, penalty=l1, solver=liblinear;, score=0.741 total time=   0.1s\n",
      "[CV 4/5] END C=1, max_iter=100, penalty=l1, solver=liblinear;, score=0.739 total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=100, penalty=l1, solver=liblinear;, score=0.743 total time=   0.1s\n",
      "[CV 1/5] END C=1, max_iter=100, penalty=l2, solver=liblinear;, score=0.752 total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=100, penalty=l2, solver=liblinear;, score=0.739 total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=100, penalty=l2, solver=liblinear;, score=0.740 total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=100, penalty=l2, solver=liblinear;, score=0.739 total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=100, penalty=l2, solver=liblinear;, score=0.743 total time=   0.1s\n",
      "[CV 1/5] END C=1, max_iter=1000, penalty=l1, solver=liblinear;, score=0.752 total time=   0.1s\n",
      "[CV 2/5] END C=1, max_iter=1000, penalty=l1, solver=liblinear;, score=0.739 total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=1000, penalty=l1, solver=liblinear;, score=0.741 total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=1000, penalty=l1, solver=liblinear;, score=0.739 total time=   0.1s\n",
      "[CV 5/5] END C=1, max_iter=1000, penalty=l1, solver=liblinear;, score=0.743 total time=   0.1s\n",
      "[CV 1/5] END C=1, max_iter=1000, penalty=l2, solver=liblinear;, score=0.752 total time=   0.2s\n",
      "[CV 2/5] END C=1, max_iter=1000, penalty=l2, solver=liblinear;, score=0.739 total time=   0.1s\n",
      "[CV 3/5] END C=1, max_iter=1000, penalty=l2, solver=liblinear;, score=0.740 total time=   0.1s\n",
      "[CV 4/5] END C=1, max_iter=1000, penalty=l2, solver=liblinear;, score=0.739 total time=   0.1s\n",
      "[CV 5/5] END C=1, max_iter=1000, penalty=l2, solver=liblinear;, score=0.743 total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=10000, penalty=l1, solver=liblinear;, score=0.752 total time=   0.1s\n",
      "[CV 2/5] END C=1, max_iter=10000, penalty=l1, solver=liblinear;, score=0.739 total time=   0.1s\n",
      "[CV 3/5] END C=1, max_iter=10000, penalty=l1, solver=liblinear;, score=0.740 total time=   0.1s\n",
      "[CV 4/5] END C=1, max_iter=10000, penalty=l1, solver=liblinear;, score=0.739 total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=10000, penalty=l1, solver=liblinear;, score=0.743 total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=10000, penalty=l2, solver=liblinear;, score=0.752 total time=   0.1s\n",
      "[CV 2/5] END C=1, max_iter=10000, penalty=l2, solver=liblinear;, score=0.739 total time=   0.1s\n",
      "[CV 3/5] END C=1, max_iter=10000, penalty=l2, solver=liblinear;, score=0.740 total time=   0.1s\n",
      "[CV 4/5] END C=1, max_iter=10000, penalty=l2, solver=liblinear;, score=0.739 total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=10000, penalty=l2, solver=liblinear;, score=0.743 total time=   0.0s\n",
      "[CV 1/5] END C=10, max_iter=100, penalty=l1, solver=liblinear;, score=0.752 total time=   0.1s\n",
      "[CV 2/5] END C=10, max_iter=100, penalty=l1, solver=liblinear;, score=0.739 total time=   0.1s\n",
      "[CV 3/5] END C=10, max_iter=100, penalty=l1, solver=liblinear;, score=0.740 total time=   0.0s\n",
      "[CV 4/5] END C=10, max_iter=100, penalty=l1, solver=liblinear;, score=0.739 total time=   0.0s\n",
      "[CV 5/5] END C=10, max_iter=100, penalty=l1, solver=liblinear;, score=0.743 total time=   0.0s\n",
      "[CV 1/5] END C=10, max_iter=100, penalty=l2, solver=liblinear;, score=0.752 total time=   0.0s\n",
      "[CV 2/5] END C=10, max_iter=100, penalty=l2, solver=liblinear;, score=0.739 total time=   0.1s\n",
      "[CV 3/5] END C=10, max_iter=100, penalty=l2, solver=liblinear;, score=0.740 total time=   0.1s\n",
      "[CV 4/5] END C=10, max_iter=100, penalty=l2, solver=liblinear;, score=0.739 total time=   0.1s\n",
      "[CV 5/5] END C=10, max_iter=100, penalty=l2, solver=liblinear;, score=0.743 total time=   0.1s\n",
      "[CV 1/5] END C=10, max_iter=1000, penalty=l1, solver=liblinear;, score=0.752 total time=   0.1s\n",
      "[CV 2/5] END C=10, max_iter=1000, penalty=l1, solver=liblinear;, score=0.739 total time=   0.0s\n",
      "[CV 3/5] END C=10, max_iter=1000, penalty=l1, solver=liblinear;, score=0.740 total time=   0.1s\n",
      "[CV 4/5] END C=10, max_iter=1000, penalty=l1, solver=liblinear;, score=0.739 total time=   0.0s\n",
      "[CV 5/5] END C=10, max_iter=1000, penalty=l1, solver=liblinear;, score=0.743 total time=   0.1s\n",
      "[CV 1/5] END C=10, max_iter=1000, penalty=l2, solver=liblinear;, score=0.752 total time=   0.0s\n",
      "[CV 2/5] END C=10, max_iter=1000, penalty=l2, solver=liblinear;, score=0.739 total time=   0.1s\n",
      "[CV 3/5] END C=10, max_iter=1000, penalty=l2, solver=liblinear;, score=0.740 total time=   0.0s\n",
      "[CV 4/5] END C=10, max_iter=1000, penalty=l2, solver=liblinear;, score=0.739 total time=   0.0s\n",
      "[CV 5/5] END C=10, max_iter=1000, penalty=l2, solver=liblinear;, score=0.743 total time=   0.0s\n",
      "[CV 1/5] END C=10, max_iter=10000, penalty=l1, solver=liblinear;, score=0.752 total time=   0.1s\n",
      "[CV 2/5] END C=10, max_iter=10000, penalty=l1, solver=liblinear;, score=0.739 total time=   0.0s\n",
      "[CV 3/5] END C=10, max_iter=10000, penalty=l1, solver=liblinear;, score=0.740 total time=   0.0s\n",
      "[CV 4/5] END C=10, max_iter=10000, penalty=l1, solver=liblinear;, score=0.739 total time=   0.0s\n",
      "[CV 5/5] END C=10, max_iter=10000, penalty=l1, solver=liblinear;, score=0.743 total time=   0.1s\n",
      "[CV 1/5] END C=10, max_iter=10000, penalty=l2, solver=liblinear;, score=0.752 total time=   0.1s\n",
      "[CV 2/5] END C=10, max_iter=10000, penalty=l2, solver=liblinear;, score=0.739 total time=   0.0s\n",
      "[CV 3/5] END C=10, max_iter=10000, penalty=l2, solver=liblinear;, score=0.740 total time=   0.1s\n",
      "[CV 4/5] END C=10, max_iter=10000, penalty=l2, solver=liblinear;, score=0.739 total time=   0.1s\n",
      "[CV 5/5] END C=10, max_iter=10000, penalty=l2, solver=liblinear;, score=0.743 total time=   0.0s\n",
      "[CV 1/5] END C=100, max_iter=100, penalty=l1, solver=liblinear;, score=0.752 total time=   0.0s\n",
      "[CV 2/5] END C=100, max_iter=100, penalty=l1, solver=liblinear;, score=0.739 total time=   0.1s\n",
      "[CV 3/5] END C=100, max_iter=100, penalty=l1, solver=liblinear;, score=0.740 total time=   0.0s\n",
      "[CV 4/5] END C=100, max_iter=100, penalty=l1, solver=liblinear;, score=0.739 total time=   0.0s\n",
      "[CV 5/5] END C=100, max_iter=100, penalty=l1, solver=liblinear;, score=0.743 total time=   0.0s\n",
      "[CV 1/5] END C=100, max_iter=100, penalty=l2, solver=liblinear;, score=0.752 total time=   0.0s\n",
      "[CV 2/5] END C=100, max_iter=100, penalty=l2, solver=liblinear;, score=0.739 total time=   0.0s\n",
      "[CV 3/5] END C=100, max_iter=100, penalty=l2, solver=liblinear;, score=0.740 total time=   0.0s\n",
      "[CV 4/5] END C=100, max_iter=100, penalty=l2, solver=liblinear;, score=0.739 total time=   0.1s\n",
      "[CV 5/5] END C=100, max_iter=100, penalty=l2, solver=liblinear;, score=0.743 total time=   0.1s\n",
      "[CV 1/5] END C=100, max_iter=1000, penalty=l1, solver=liblinear;, score=0.752 total time=   0.0s\n",
      "[CV 2/5] END C=100, max_iter=1000, penalty=l1, solver=liblinear;, score=0.739 total time=   0.0s\n",
      "[CV 3/5] END C=100, max_iter=1000, penalty=l1, solver=liblinear;, score=0.740 total time=   0.1s\n",
      "[CV 4/5] END C=100, max_iter=1000, penalty=l1, solver=liblinear;, score=0.739 total time=   0.1s\n",
      "[CV 5/5] END C=100, max_iter=1000, penalty=l1, solver=liblinear;, score=0.743 total time=   0.1s\n",
      "[CV 1/5] END C=100, max_iter=1000, penalty=l2, solver=liblinear;, score=0.752 total time=   0.1s\n",
      "[CV 2/5] END C=100, max_iter=1000, penalty=l2, solver=liblinear;, score=0.739 total time=   0.1s\n",
      "[CV 3/5] END C=100, max_iter=1000, penalty=l2, solver=liblinear;, score=0.740 total time=   0.1s\n",
      "[CV 4/5] END C=100, max_iter=1000, penalty=l2, solver=liblinear;, score=0.739 total time=   0.1s\n",
      "[CV 5/5] END C=100, max_iter=1000, penalty=l2, solver=liblinear;, score=0.743 total time=   0.1s\n",
      "[CV 1/5] END C=100, max_iter=10000, penalty=l1, solver=liblinear;, score=0.752 total time=   0.1s\n",
      "[CV 2/5] END C=100, max_iter=10000, penalty=l1, solver=liblinear;, score=0.739 total time=   0.0s\n",
      "[CV 3/5] END C=100, max_iter=10000, penalty=l1, solver=liblinear;, score=0.740 total time=   0.0s\n",
      "[CV 4/5] END C=100, max_iter=10000, penalty=l1, solver=liblinear;, score=0.739 total time=   0.1s\n",
      "[CV 5/5] END C=100, max_iter=10000, penalty=l1, solver=liblinear;, score=0.743 total time=   0.0s\n",
      "[CV 1/5] END C=100, max_iter=10000, penalty=l2, solver=liblinear;, score=0.752 total time=   0.0s\n",
      "[CV 2/5] END C=100, max_iter=10000, penalty=l2, solver=liblinear;, score=0.739 total time=   0.0s\n",
      "[CV 3/5] END C=100, max_iter=10000, penalty=l2, solver=liblinear;, score=0.740 total time=   0.0s\n",
      "[CV 4/5] END C=100, max_iter=10000, penalty=l2, solver=liblinear;, score=0.739 total time=   0.1s\n",
      "[CV 5/5] END C=100, max_iter=10000, penalty=l2, solver=liblinear;, score=0.743 total time=   0.1s\n",
      "Accuracy: 0.7509194816952414\n",
      "{'C': 0.1, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.7427714724411463\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create the parameter grid for the GridSearchCV model running logistic regression\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear'], \n",
    "    'max_iter': [100, 1000, 10000]\n",
    "}\n",
    "#C', 'class_weight', 'dual', 'fit_intercept', 'intercept_scaling', 'l1_ratio', 'max_iter', 'multi_class', 'n_jobs', 'penalty', 'random_state', 'solver', 'tol', 'verbose', 'warm_start\n",
    "\n",
    "# Create the GridSearchCV model\n",
    "grid_model = GridSearchCV(LogisticRegression(), param_grid, verbose=3)\n",
    "\n",
    "# Fit the model\n",
    "grid_model.fit(x_train_encoded, y_train)\n",
    "\n",
    "# Make predictions\n",
    "predictions = grid_model.predict(x_test_encoded)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Print the best parameters\n",
    "print(grid_model.best_params_)\n",
    "print(grid_model.best_score_)\n",
    "# print(grid_model.best_estimator_)\n",
    "# print(grid_model.cv_results_)\n",
    "# print(grid_model.best_index_)\n",
    "# print(grid_model.scorer_)\n",
    "# print(grid_model.n_splits_)\n",
    "# print(grid_model.refit_time_)\n",
    "# print(grid_model.error_score)\n",
    "# print(grid_model.param_grid)\n",
    "# print(grid_model.pre_dispatch)\n",
    "# print(grid_model.return_train_score)\n",
    "# print(grid_model.multimetric_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV 1/5] END algorithm=auto, metric=euclidean, n_neighbors=19, weights=uniform;, score=0.742 total time=   1.8s\n",
      "[CV 2/5] END algorithm=auto, metric=euclidean, n_neighbors=19, weights=uniform;, score=0.729 total time=   1.5s\n",
      "[CV 3/5] END algorithm=auto, metric=euclidean, n_neighbors=19, weights=uniform;, score=0.737 total time=   1.4s\n",
      "[CV 4/5] END algorithm=auto, metric=euclidean, n_neighbors=19, weights=uniform;, score=0.729 total time=   1.5s\n",
      "[CV 5/5] END algorithm=auto, metric=euclidean, n_neighbors=19, weights=uniform;, score=0.735 total time=   1.5s\n",
      "[CV 1/5] END algorithm=auto, metric=euclidean, n_neighbors=19, weights=distance;, score=0.720 total time=   1.4s\n",
      "[CV 2/5] END algorithm=auto, metric=euclidean, n_neighbors=19, weights=distance;, score=0.706 total time=   1.3s\n",
      "[CV 3/5] END algorithm=auto, metric=euclidean, n_neighbors=19, weights=distance;, score=0.719 total time=   1.3s\n",
      "[CV 4/5] END algorithm=auto, metric=euclidean, n_neighbors=19, weights=distance;, score=0.708 total time=   1.3s\n",
      "[CV 5/5] END algorithm=auto, metric=euclidean, n_neighbors=19, weights=distance;, score=0.714 total time=   1.4s\n",
      "[CV 1/5] END algorithm=auto, metric=manhattan, n_neighbors=19, weights=uniform;, score=0.742 total time=   1.6s\n",
      "[CV 2/5] END algorithm=auto, metric=manhattan, n_neighbors=19, weights=uniform;, score=0.729 total time=   1.6s\n",
      "[CV 3/5] END algorithm=auto, metric=manhattan, n_neighbors=19, weights=uniform;, score=0.739 total time=   1.6s\n",
      "[CV 4/5] END algorithm=auto, metric=manhattan, n_neighbors=19, weights=uniform;, score=0.733 total time=   1.6s\n",
      "[CV 5/5] END algorithm=auto, metric=manhattan, n_neighbors=19, weights=uniform;, score=0.735 total time=   1.7s\n",
      "[CV 1/5] END algorithm=auto, metric=manhattan, n_neighbors=19, weights=distance;, score=0.719 total time=   1.6s\n",
      "[CV 2/5] END algorithm=auto, metric=manhattan, n_neighbors=19, weights=distance;, score=0.705 total time=   1.5s\n",
      "[CV 3/5] END algorithm=auto, metric=manhattan, n_neighbors=19, weights=distance;, score=0.720 total time=   1.5s\n",
      "[CV 4/5] END algorithm=auto, metric=manhattan, n_neighbors=19, weights=distance;, score=0.710 total time=   1.8s\n",
      "[CV 5/5] END algorithm=auto, metric=manhattan, n_neighbors=19, weights=distance;, score=0.715 total time=   1.5s\n",
      "[CV 1/5] END algorithm=ball_tree, metric=euclidean, n_neighbors=19, weights=uniform;, score=0.742 total time=   2.7s\n",
      "[CV 2/5] END algorithm=ball_tree, metric=euclidean, n_neighbors=19, weights=uniform;, score=0.729 total time=   2.7s\n",
      "[CV 3/5] END algorithm=ball_tree, metric=euclidean, n_neighbors=19, weights=uniform;, score=0.738 total time=   2.7s\n",
      "[CV 4/5] END algorithm=ball_tree, metric=euclidean, n_neighbors=19, weights=uniform;, score=0.730 total time=   2.7s\n",
      "[CV 5/5] END algorithm=ball_tree, metric=euclidean, n_neighbors=19, weights=uniform;, score=0.734 total time=   2.7s\n",
      "[CV 1/5] END algorithm=ball_tree, metric=euclidean, n_neighbors=19, weights=distance;, score=0.720 total time=   2.6s\n",
      "[CV 2/5] END algorithm=ball_tree, metric=euclidean, n_neighbors=19, weights=distance;, score=0.706 total time=   2.8s\n",
      "[CV 3/5] END algorithm=ball_tree, metric=euclidean, n_neighbors=19, weights=distance;, score=0.719 total time=   2.7s\n",
      "[CV 4/5] END algorithm=ball_tree, metric=euclidean, n_neighbors=19, weights=distance;, score=0.707 total time=   2.6s\n",
      "[CV 5/5] END algorithm=ball_tree, metric=euclidean, n_neighbors=19, weights=distance;, score=0.714 total time=   2.7s\n",
      "[CV 1/5] END algorithm=ball_tree, metric=manhattan, n_neighbors=19, weights=uniform;, score=0.741 total time=   2.5s\n",
      "[CV 2/5] END algorithm=ball_tree, metric=manhattan, n_neighbors=19, weights=uniform;, score=0.727 total time=   2.8s\n",
      "[CV 3/5] END algorithm=ball_tree, metric=manhattan, n_neighbors=19, weights=uniform;, score=0.739 total time=   2.5s\n",
      "[CV 4/5] END algorithm=ball_tree, metric=manhattan, n_neighbors=19, weights=uniform;, score=0.732 total time=   2.4s\n",
      "[CV 5/5] END algorithm=ball_tree, metric=manhattan, n_neighbors=19, weights=uniform;, score=0.735 total time=   2.4s\n",
      "[CV 1/5] END algorithm=ball_tree, metric=manhattan, n_neighbors=19, weights=distance;, score=0.720 total time=   2.3s\n",
      "[CV 2/5] END algorithm=ball_tree, metric=manhattan, n_neighbors=19, weights=distance;, score=0.705 total time=   2.3s\n",
      "[CV 3/5] END algorithm=ball_tree, metric=manhattan, n_neighbors=19, weights=distance;, score=0.720 total time=   2.3s\n",
      "[CV 4/5] END algorithm=ball_tree, metric=manhattan, n_neighbors=19, weights=distance;, score=0.710 total time=   2.3s\n",
      "[CV 5/5] END algorithm=ball_tree, metric=manhattan, n_neighbors=19, weights=distance;, score=0.715 total time=   2.3s\n",
      "[CV 1/5] END algorithm=kd_tree, metric=euclidean, n_neighbors=19, weights=uniform;, score=0.742 total time=   1.5s\n",
      "[CV 2/5] END algorithm=kd_tree, metric=euclidean, n_neighbors=19, weights=uniform;, score=0.729 total time=   1.5s\n",
      "[CV 3/5] END algorithm=kd_tree, metric=euclidean, n_neighbors=19, weights=uniform;, score=0.737 total time=   1.5s\n",
      "[CV 4/5] END algorithm=kd_tree, metric=euclidean, n_neighbors=19, weights=uniform;, score=0.729 total time=   1.5s\n",
      "[CV 5/5] END algorithm=kd_tree, metric=euclidean, n_neighbors=19, weights=uniform;, score=0.735 total time=   1.5s\n",
      "[CV 1/5] END algorithm=kd_tree, metric=euclidean, n_neighbors=19, weights=distance;, score=0.720 total time=   1.4s\n",
      "[CV 2/5] END algorithm=kd_tree, metric=euclidean, n_neighbors=19, weights=distance;, score=0.706 total time=   1.4s\n",
      "[CV 3/5] END algorithm=kd_tree, metric=euclidean, n_neighbors=19, weights=distance;, score=0.719 total time=   1.3s\n",
      "[CV 4/5] END algorithm=kd_tree, metric=euclidean, n_neighbors=19, weights=distance;, score=0.708 total time=   1.3s\n",
      "[CV 5/5] END algorithm=kd_tree, metric=euclidean, n_neighbors=19, weights=distance;, score=0.714 total time=   1.4s\n",
      "[CV 1/5] END algorithm=kd_tree, metric=manhattan, n_neighbors=19, weights=uniform;, score=0.742 total time=   1.8s\n",
      "[CV 2/5] END algorithm=kd_tree, metric=manhattan, n_neighbors=19, weights=uniform;, score=0.729 total time=   1.7s\n",
      "[CV 3/5] END algorithm=kd_tree, metric=manhattan, n_neighbors=19, weights=uniform;, score=0.739 total time=   1.7s\n",
      "[CV 4/5] END algorithm=kd_tree, metric=manhattan, n_neighbors=19, weights=uniform;, score=0.733 total time=   1.8s\n",
      "[CV 5/5] END algorithm=kd_tree, metric=manhattan, n_neighbors=19, weights=uniform;, score=0.735 total time=   1.7s\n",
      "[CV 1/5] END algorithm=kd_tree, metric=manhattan, n_neighbors=19, weights=distance;, score=0.719 total time=   1.6s\n",
      "[CV 2/5] END algorithm=kd_tree, metric=manhattan, n_neighbors=19, weights=distance;, score=0.705 total time=   1.5s\n",
      "[CV 3/5] END algorithm=kd_tree, metric=manhattan, n_neighbors=19, weights=distance;, score=0.720 total time=   1.5s\n",
      "[CV 4/5] END algorithm=kd_tree, metric=manhattan, n_neighbors=19, weights=distance;, score=0.710 total time=   1.5s\n",
      "[CV 5/5] END algorithm=kd_tree, metric=manhattan, n_neighbors=19, weights=distance;, score=0.715 total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(82135) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END algorithm=brute, metric=euclidean, n_neighbors=19, weights=uniform;, score=0.743 total time=   0.6s\n",
      "[CV 2/5] END algorithm=brute, metric=euclidean, n_neighbors=19, weights=uniform;, score=0.727 total time=   0.4s\n",
      "[CV 3/5] END algorithm=brute, metric=euclidean, n_neighbors=19, weights=uniform;, score=0.736 total time=   0.4s\n",
      "[CV 4/5] END algorithm=brute, metric=euclidean, n_neighbors=19, weights=uniform;, score=0.728 total time=   0.4s\n",
      "[CV 5/5] END algorithm=brute, metric=euclidean, n_neighbors=19, weights=uniform;, score=0.736 total time=   0.4s\n",
      "[CV 1/5] END algorithm=brute, metric=euclidean, n_neighbors=19, weights=distance;, score=0.722 total time=   0.3s\n",
      "[CV 2/5] END algorithm=brute, metric=euclidean, n_neighbors=19, weights=distance;, score=0.706 total time=   0.3s\n",
      "[CV 3/5] END algorithm=brute, metric=euclidean, n_neighbors=19, weights=distance;, score=0.719 total time=   0.2s\n",
      "[CV 4/5] END algorithm=brute, metric=euclidean, n_neighbors=19, weights=distance;, score=0.708 total time=   0.2s\n",
      "[CV 5/5] END algorithm=brute, metric=euclidean, n_neighbors=19, weights=distance;, score=0.716 total time=   0.3s\n",
      "[CV 1/5] END algorithm=brute, metric=manhattan, n_neighbors=19, weights=uniform;, score=0.741 total time=   0.5s\n",
      "[CV 2/5] END algorithm=brute, metric=manhattan, n_neighbors=19, weights=uniform;, score=0.729 total time=   0.4s\n",
      "[CV 3/5] END algorithm=brute, metric=manhattan, n_neighbors=19, weights=uniform;, score=0.738 total time=   0.5s\n",
      "[CV 4/5] END algorithm=brute, metric=manhattan, n_neighbors=19, weights=uniform;, score=0.732 total time=   0.5s\n",
      "[CV 5/5] END algorithm=brute, metric=manhattan, n_neighbors=19, weights=uniform;, score=0.735 total time=   0.5s\n",
      "[CV 1/5] END algorithm=brute, metric=manhattan, n_neighbors=19, weights=distance;, score=0.720 total time=   0.6s\n",
      "[CV 2/5] END algorithm=brute, metric=manhattan, n_neighbors=19, weights=distance;, score=0.705 total time=   0.6s\n",
      "[CV 3/5] END algorithm=brute, metric=manhattan, n_neighbors=19, weights=distance;, score=0.719 total time=   0.6s\n",
      "[CV 4/5] END algorithm=brute, metric=manhattan, n_neighbors=19, weights=distance;, score=0.709 total time=   0.8s\n",
      "[CV 5/5] END algorithm=brute, metric=manhattan, n_neighbors=19, weights=distance;, score=0.715 total time=   0.6s\n",
      "Accuracy: 0.7380184462173938\n",
      "{'algorithm': 'auto', 'metric': 'manhattan', 'n_neighbors': 19, 'weights': 'uniform'}\n",
      "0.7353024291218407\n"
     ]
    }
   ],
   "source": [
    "# Create the parameter grid for the GridSearchCV model running KNeighborsClassifier\n",
    "param_grid = {\n",
    "    'n_neighbors': [19], \n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan'],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "}\n",
    "\n",
    "# Create the GridSearchCV model\n",
    "grid_model = GridSearchCV(KNeighborsClassifier(), param_grid, verbose=3)\n",
    "\n",
    "# Fit the model\n",
    "grid_model.fit(x_train_encoded, y_train)\n",
    "\n",
    "# Make predictions\n",
    "predictions = grid_model.predict(x_test_encoded)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Print the best parameters\n",
    "print(grid_model.best_params_)\n",
    "print(grid_model.best_score_)\n",
    "# print(grid_model.best_estimator_)\n",
    "# print(grid_model.cv_results_)\n",
    "# print(grid_model.best_index_)\n",
    "# print(grid_model.scorer_)\n",
    "# print(grid_model.n_splits_)\n",
    "# print(grid_model.refit_time_)\n",
    "# print(grid_model.error_score)\n",
    "# print(grid_model.param_grid)\n",
    "# print(grid_model.pre_dispatch)\n",
    "# print(grid_model.return_train_score)\n",
    "# print(grid_model.multimetric_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: scikit-learn\n",
      "Version: 1.2.2\n",
      "Summary: A set of python modules for machine learning and data mining\n",
      "Home-page: http://scikit-learn.org\n",
      "Author: \n",
      "Author-email: \n",
      "License: new BSD\n",
      "Location: /opt/anaconda3/envs/dev/lib/python3.10/site-packages\n",
      "Requires: joblib, numpy, scipy, threadpoolctl\n",
      "Required-by: imbalanced-learn\n",
      "---\n",
      "Name: xgboost\n",
      "Version: 1.6.2\n",
      "Summary: XGBoost Python Package\n",
      "Home-page: https://github.com/dmlc/xgboost\n",
      "Author: \n",
      "Author-email: \n",
      "License: Apache-2.0\n",
      "Location: /opt/anaconda3/envs/dev/lib/python3.10/site-packages\n",
      "Requires: numpy, scipy\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/envs/dev/lib/python3.10/site-packages (1.2.2)\n",
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.6.1-cp310-cp310-macosx_12_0_arm64.whl.metadata (31 kB)\n",
      "Requirement already satisfied: xgboost in /opt/anaconda3/envs/dev/lib/python3.10/site-packages (1.6.2)\n",
      "Collecting xgboost\n",
      "  Using cached xgboost-2.1.3-py3-none-macosx_12_0_arm64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /opt/anaconda3/envs/dev/lib/python3.10/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/anaconda3/envs/dev/lib/python3.10/site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/envs/dev/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/envs/dev/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\n",
      "Using cached scikit_learn-1.6.1-cp310-cp310-macosx_12_0_arm64.whl (11.1 MB)\n",
      "Using cached xgboost-2.1.3-py3-none-macosx_12_0_arm64.whl (1.9 MB)\n",
      "Installing collected packages: xgboost, scikit-learn\n",
      "  Attempting uninstall: xgboost\n",
      "    Found existing installation: xgboost 1.6.2\n",
      "    Uninstalling xgboost-1.6.2:\n",
      "      Successfully uninstalled xgboost-1.6.2\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.2.2\n",
      "    Uninstalling scikit-learn-1.2.2:\n",
      "      Successfully uninstalled scikit-learn-1.2.2\n",
      "Successfully installed scikit-learn-1.6.1 xgboost-2.1.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip show scikit-learn xgboost\n",
    "%pip install --upgrade scikit-learn xgboost\n",
    "\n",
    "#uninstall xgboost and scikit-learn\n",
    "#%pip uninstall xgboost scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'super' object has no attribute '__sklearn_tags__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m grid_model \u001b[38;5;241m=\u001b[39m GridSearchCV(XGBClassifier(), param_grid, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Fit the model\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[43mgrid_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train_encoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[1;32m     16\u001b[0m predictions \u001b[38;5;241m=\u001b[39m grid_model\u001b[38;5;241m.\u001b[39mpredict(x_test_encoded)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dev/lib/python3.10/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dev/lib/python3.10/site-packages/sklearn/model_selection/_search.py:933\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    929\u001b[0m params \u001b[38;5;241m=\u001b[39m _check_method_params(X, params\u001b[38;5;241m=\u001b[39mparams)\n\u001b[1;32m    931\u001b[0m routed_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_routed_params_for_fit(params)\n\u001b[0;32m--> 933\u001b[0m cv_orig \u001b[38;5;241m=\u001b[39m check_cv(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv, y, classifier\u001b[38;5;241m=\u001b[39m\u001b[43mis_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    934\u001b[0m n_splits \u001b[38;5;241m=\u001b[39m cv_orig\u001b[38;5;241m.\u001b[39mget_n_splits(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39msplitter\u001b[38;5;241m.\u001b[39msplit)\n\u001b[1;32m    936\u001b[0m base_estimator \u001b[38;5;241m=\u001b[39m clone(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dev/lib/python3.10/site-packages/sklearn/base.py:1237\u001b[0m, in \u001b[0;36mis_classifier\u001b[0;34m(estimator)\u001b[0m\n\u001b[1;32m   1230\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1231\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassing a class to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mprint\u001b[39m(inspect\u001b[38;5;241m.\u001b[39mstack()[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m3\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is deprecated and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1232\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill be removed in 1.8. Use an instance of the class instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1233\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m   1234\u001b[0m     )\n\u001b[1;32m   1235\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(estimator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_estimator_type\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassifier\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_tags\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mestimator_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassifier\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dev/lib/python3.10/site-packages/sklearn/utils/_tags.py:430\u001b[0m, in \u001b[0;36mget_tags\u001b[0;34m(estimator)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m klass \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39mmro()):\n\u001b[1;32m    429\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__sklearn_tags__\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mvars\u001b[39m(klass):\n\u001b[0;32m--> 430\u001b[0m         sklearn_tags_provider[klass] \u001b[38;5;241m=\u001b[39m \u001b[43mklass\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__sklearn_tags__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    431\u001b[0m         class_order\u001b[38;5;241m.\u001b[39mappend(klass)\n\u001b[1;32m    432\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_more_tags\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mvars\u001b[39m(klass):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dev/lib/python3.10/site-packages/sklearn/base.py:540\u001b[0m, in \u001b[0;36mClassifierMixin.__sklearn_tags__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__sklearn_tags__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 540\u001b[0m     tags \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__sklearn_tags__\u001b[49m()\n\u001b[1;32m    541\u001b[0m     tags\u001b[38;5;241m.\u001b[39mestimator_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassifier\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    542\u001b[0m     tags\u001b[38;5;241m.\u001b[39mclassifier_tags \u001b[38;5;241m=\u001b[39m ClassifierTags()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'super' object has no attribute '__sklearn_tags__'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create the parameter grid for the GridSearchCV model running Xgboost\n",
    "param_grid = {\n",
    "  #random_state=1, learning_rate=0.05, n_estimators=1000, max_depth=3\n",
    "    'learning_rate': [0.05, 0.1, 0.2],\n",
    "    'n_estimators': [100, 500, 1000],\n",
    "    'max_depth': [3, 7, 11]  \n",
    "}\n",
    "\n",
    "# Create the GridSearchCV model\n",
    "grid_model = GridSearchCV(XGBClassifier(), param_grid, verbose=3)\n",
    "\n",
    "# Fit the model\n",
    "grid_model.fit(x_train_encoded, y_train)\n",
    "\n",
    "# Make predictions\n",
    "predictions = grid_model.predict(x_test_encoded)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Print the best parameters\n",
    "print(grid_model.best_params_)\n",
    "print(grid_model.best_score_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
