{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "#%pip install scikit-learn\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, OrdinalEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "# Needed for decision tree visualization\n",
    "import pydotplus\n",
    "from IPython.display import Image\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes_binary</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>...</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Diabetes_binary  HighBP  HighChol  CholCheck   BMI  Smoker  Stroke  \\\n",
       "0              0.0     1.0       0.0        1.0  26.0     0.0     0.0   \n",
       "1              0.0     1.0       1.0        1.0  26.0     1.0     1.0   \n",
       "2              0.0     0.0       0.0        1.0  26.0     0.0     0.0   \n",
       "3              0.0     1.0       1.0        1.0  28.0     1.0     0.0   \n",
       "4              0.0     0.0       0.0        1.0  29.0     1.0     0.0   \n",
       "\n",
       "   HeartDiseaseorAttack  PhysActivity  Fruits  ...  AnyHealthcare  \\\n",
       "0                   0.0           1.0     0.0  ...            1.0   \n",
       "1                   0.0           0.0     1.0  ...            1.0   \n",
       "2                   0.0           1.0     1.0  ...            1.0   \n",
       "3                   0.0           1.0     1.0  ...            1.0   \n",
       "4                   0.0           1.0     1.0  ...            1.0   \n",
       "\n",
       "   NoDocbcCost  GenHlth  MentHlth  PhysHlth  DiffWalk  Sex   Age  Education  \\\n",
       "0          0.0      3.0       5.0      30.0       0.0  1.0   4.0        6.0   \n",
       "1          0.0      3.0       0.0       0.0       0.0  1.0  12.0        6.0   \n",
       "2          0.0      1.0       0.0      10.0       0.0  1.0  13.0        6.0   \n",
       "3          0.0      3.0       0.0       3.0       0.0  1.0  11.0        6.0   \n",
       "4          0.0      2.0       0.0       0.0       0.0  0.0   8.0        5.0   \n",
       "\n",
       "   Income  \n",
       "0     8.0  \n",
       "1     8.0  \n",
       "2     8.0  \n",
       "3     8.0  \n",
       "4     8.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import\n",
    "diabetes = pd.read_csv(\"Resources/diabetes_binary_5050split_health_indicators_BRFSS2015.csv\")\n",
    "\n",
    "# Head\n",
    "diabetes.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Diabetes_binary', 'HighBP', 'HighChol', 'CholCheck', 'BMI', 'Smoker',\n",
       "       'Stroke', 'HeartDiseaseorAttack', 'PhysActivity', 'Fruits', 'Veggies',\n",
       "       'HvyAlcoholConsump', 'AnyHealthcare', 'NoDocbcCost', 'GenHlth',\n",
       "       'MentHlth', 'PhysHlth', 'DiffWalk', 'Sex', 'Age', 'Education',\n",
       "       'Income'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column Descriptions\n",
    "1. Diabetes_binary: 0 = no diabetes 1 = prediabetes or diabetes\n",
    "2. HighBP: 0 = no high BP 1 = high BP\n",
    "3. HighChol: 0 = no high cholesterol 1 = high cholesterol\n",
    "4. CholCheck: 0 = no cholesterol check in 5 years 1 = yes cholesterol check in 5 years\n",
    "5. BMI: Body Mass Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes_binary</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>...</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.563458</td>\n",
       "      <td>0.525703</td>\n",
       "      <td>0.975259</td>\n",
       "      <td>29.856985</td>\n",
       "      <td>0.475273</td>\n",
       "      <td>0.062171</td>\n",
       "      <td>0.147810</td>\n",
       "      <td>0.703036</td>\n",
       "      <td>0.611795</td>\n",
       "      <td>...</td>\n",
       "      <td>0.954960</td>\n",
       "      <td>0.093914</td>\n",
       "      <td>2.837082</td>\n",
       "      <td>3.752037</td>\n",
       "      <td>5.810417</td>\n",
       "      <td>0.252730</td>\n",
       "      <td>0.456997</td>\n",
       "      <td>8.584055</td>\n",
       "      <td>4.920953</td>\n",
       "      <td>5.698311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.500004</td>\n",
       "      <td>0.495960</td>\n",
       "      <td>0.499342</td>\n",
       "      <td>0.155336</td>\n",
       "      <td>7.113954</td>\n",
       "      <td>0.499392</td>\n",
       "      <td>0.241468</td>\n",
       "      <td>0.354914</td>\n",
       "      <td>0.456924</td>\n",
       "      <td>0.487345</td>\n",
       "      <td>...</td>\n",
       "      <td>0.207394</td>\n",
       "      <td>0.291712</td>\n",
       "      <td>1.113565</td>\n",
       "      <td>8.155627</td>\n",
       "      <td>10.062261</td>\n",
       "      <td>0.434581</td>\n",
       "      <td>0.498151</td>\n",
       "      <td>2.852153</td>\n",
       "      <td>1.029081</td>\n",
       "      <td>2.175196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Diabetes_binary        HighBP      HighChol     CholCheck  \\\n",
       "count     70692.000000  70692.000000  70692.000000  70692.000000   \n",
       "mean          0.500000      0.563458      0.525703      0.975259   \n",
       "std           0.500004      0.495960      0.499342      0.155336   \n",
       "min           0.000000      0.000000      0.000000      0.000000   \n",
       "25%           0.000000      0.000000      0.000000      1.000000   \n",
       "50%           0.500000      1.000000      1.000000      1.000000   \n",
       "75%           1.000000      1.000000      1.000000      1.000000   \n",
       "max           1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "                BMI        Smoker        Stroke  HeartDiseaseorAttack  \\\n",
       "count  70692.000000  70692.000000  70692.000000          70692.000000   \n",
       "mean      29.856985      0.475273      0.062171              0.147810   \n",
       "std        7.113954      0.499392      0.241468              0.354914   \n",
       "min       12.000000      0.000000      0.000000              0.000000   \n",
       "25%       25.000000      0.000000      0.000000              0.000000   \n",
       "50%       29.000000      0.000000      0.000000              0.000000   \n",
       "75%       33.000000      1.000000      0.000000              0.000000   \n",
       "max       98.000000      1.000000      1.000000              1.000000   \n",
       "\n",
       "       PhysActivity        Fruits  ...  AnyHealthcare   NoDocbcCost  \\\n",
       "count  70692.000000  70692.000000  ...   70692.000000  70692.000000   \n",
       "mean       0.703036      0.611795  ...       0.954960      0.093914   \n",
       "std        0.456924      0.487345  ...       0.207394      0.291712   \n",
       "min        0.000000      0.000000  ...       0.000000      0.000000   \n",
       "25%        0.000000      0.000000  ...       1.000000      0.000000   \n",
       "50%        1.000000      1.000000  ...       1.000000      0.000000   \n",
       "75%        1.000000      1.000000  ...       1.000000      0.000000   \n",
       "max        1.000000      1.000000  ...       1.000000      1.000000   \n",
       "\n",
       "            GenHlth      MentHlth      PhysHlth      DiffWalk           Sex  \\\n",
       "count  70692.000000  70692.000000  70692.000000  70692.000000  70692.000000   \n",
       "mean       2.837082      3.752037      5.810417      0.252730      0.456997   \n",
       "std        1.113565      8.155627     10.062261      0.434581      0.498151   \n",
       "min        1.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        2.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        3.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        4.000000      2.000000      6.000000      1.000000      1.000000   \n",
       "max        5.000000     30.000000     30.000000      1.000000      1.000000   \n",
       "\n",
       "                Age     Education        Income  \n",
       "count  70692.000000  70692.000000  70692.000000  \n",
       "mean       8.584055      4.920953      5.698311  \n",
       "std        2.852153      1.029081      2.175196  \n",
       "min        1.000000      1.000000      1.000000  \n",
       "25%        7.000000      4.000000      4.000000  \n",
       "50%        9.000000      5.000000      6.000000  \n",
       "75%       11.000000      6.000000      8.000000  \n",
       "max       13.000000      6.000000      8.000000  \n",
       "\n",
       "[8 rows x 22 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Describing the dataset\n",
    "diabetes.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 70692 entries, 0 to 70691\n",
      "Data columns (total 22 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   Diabetes_binary       70692 non-null  float64\n",
      " 1   HighBP                70692 non-null  float64\n",
      " 2   HighChol              70692 non-null  float64\n",
      " 3   CholCheck             70692 non-null  float64\n",
      " 4   BMI                   70692 non-null  float64\n",
      " 5   Smoker                70692 non-null  float64\n",
      " 6   Stroke                70692 non-null  float64\n",
      " 7   HeartDiseaseorAttack  70692 non-null  float64\n",
      " 8   PhysActivity          70692 non-null  float64\n",
      " 9   Fruits                70692 non-null  float64\n",
      " 10  Veggies               70692 non-null  float64\n",
      " 11  HvyAlcoholConsump     70692 non-null  float64\n",
      " 12  AnyHealthcare         70692 non-null  float64\n",
      " 13  NoDocbcCost           70692 non-null  float64\n",
      " 14  GenHlth               70692 non-null  float64\n",
      " 15  MentHlth              70692 non-null  float64\n",
      " 16  PhysHlth              70692 non-null  float64\n",
      " 17  DiffWalk              70692 non-null  float64\n",
      " 18  Sex                   70692 non-null  float64\n",
      " 19  Age                   70692 non-null  float64\n",
      " 20  Education             70692 non-null  float64\n",
      " 21  Income                70692 non-null  float64\n",
      "dtypes: float64(22)\n",
      "memory usage: 11.9 MB\n"
     ]
    }
   ],
   "source": [
    "# info about the dataset\n",
    "diabetes.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes_binary</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>...</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Diabetes_binary</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.381516</td>\n",
       "      <td>0.289213</td>\n",
       "      <td>0.115382</td>\n",
       "      <td>0.293373</td>\n",
       "      <td>0.085999</td>\n",
       "      <td>0.125427</td>\n",
       "      <td>0.211523</td>\n",
       "      <td>-0.158666</td>\n",
       "      <td>-0.054077</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023191</td>\n",
       "      <td>0.040977</td>\n",
       "      <td>0.407612</td>\n",
       "      <td>0.087029</td>\n",
       "      <td>0.213081</td>\n",
       "      <td>0.272646</td>\n",
       "      <td>0.044413</td>\n",
       "      <td>0.278738</td>\n",
       "      <td>-0.170481</td>\n",
       "      <td>-0.224449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HighBP</th>\n",
       "      <td>0.381516</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.316515</td>\n",
       "      <td>0.103283</td>\n",
       "      <td>0.241019</td>\n",
       "      <td>0.087438</td>\n",
       "      <td>0.129060</td>\n",
       "      <td>0.210750</td>\n",
       "      <td>-0.136102</td>\n",
       "      <td>-0.040852</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035764</td>\n",
       "      <td>0.026517</td>\n",
       "      <td>0.320540</td>\n",
       "      <td>0.064294</td>\n",
       "      <td>0.173922</td>\n",
       "      <td>0.234784</td>\n",
       "      <td>0.040819</td>\n",
       "      <td>0.338132</td>\n",
       "      <td>-0.141643</td>\n",
       "      <td>-0.187657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HighChol</th>\n",
       "      <td>0.289213</td>\n",
       "      <td>0.316515</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.085981</td>\n",
       "      <td>0.131309</td>\n",
       "      <td>0.093398</td>\n",
       "      <td>0.099786</td>\n",
       "      <td>0.181187</td>\n",
       "      <td>-0.090453</td>\n",
       "      <td>-0.047384</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031532</td>\n",
       "      <td>0.033199</td>\n",
       "      <td>0.237778</td>\n",
       "      <td>0.083881</td>\n",
       "      <td>0.142610</td>\n",
       "      <td>0.162043</td>\n",
       "      <td>0.017324</td>\n",
       "      <td>0.240338</td>\n",
       "      <td>-0.084386</td>\n",
       "      <td>-0.107777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CholCheck</th>\n",
       "      <td>0.115382</td>\n",
       "      <td>0.103283</td>\n",
       "      <td>0.085981</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.045648</td>\n",
       "      <td>-0.004331</td>\n",
       "      <td>0.022529</td>\n",
       "      <td>0.043497</td>\n",
       "      <td>-0.008249</td>\n",
       "      <td>0.017384</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106800</td>\n",
       "      <td>-0.062669</td>\n",
       "      <td>0.059213</td>\n",
       "      <td>-0.010660</td>\n",
       "      <td>0.034540</td>\n",
       "      <td>0.044430</td>\n",
       "      <td>-0.007991</td>\n",
       "      <td>0.101743</td>\n",
       "      <td>-0.008695</td>\n",
       "      <td>0.007550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMI</th>\n",
       "      <td>0.293373</td>\n",
       "      <td>0.241019</td>\n",
       "      <td>0.131309</td>\n",
       "      <td>0.045648</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.011551</td>\n",
       "      <td>0.022931</td>\n",
       "      <td>0.060355</td>\n",
       "      <td>-0.170936</td>\n",
       "      <td>-0.084505</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013417</td>\n",
       "      <td>0.065832</td>\n",
       "      <td>0.267888</td>\n",
       "      <td>0.104682</td>\n",
       "      <td>0.161862</td>\n",
       "      <td>0.246094</td>\n",
       "      <td>0.000827</td>\n",
       "      <td>-0.038648</td>\n",
       "      <td>-0.100233</td>\n",
       "      <td>-0.124878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Smoker</th>\n",
       "      <td>0.085999</td>\n",
       "      <td>0.087438</td>\n",
       "      <td>0.093398</td>\n",
       "      <td>-0.004331</td>\n",
       "      <td>0.011551</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.064658</td>\n",
       "      <td>0.124418</td>\n",
       "      <td>-0.079823</td>\n",
       "      <td>-0.074811</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012939</td>\n",
       "      <td>0.035799</td>\n",
       "      <td>0.152416</td>\n",
       "      <td>0.091257</td>\n",
       "      <td>0.120698</td>\n",
       "      <td>0.119789</td>\n",
       "      <td>0.112125</td>\n",
       "      <td>0.105424</td>\n",
       "      <td>-0.140966</td>\n",
       "      <td>-0.104725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stroke</th>\n",
       "      <td>0.125427</td>\n",
       "      <td>0.129060</td>\n",
       "      <td>0.099786</td>\n",
       "      <td>0.022529</td>\n",
       "      <td>0.022931</td>\n",
       "      <td>0.064658</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.223394</td>\n",
       "      <td>-0.079985</td>\n",
       "      <td>-0.008996</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006484</td>\n",
       "      <td>0.036198</td>\n",
       "      <td>0.189447</td>\n",
       "      <td>0.087303</td>\n",
       "      <td>0.164488</td>\n",
       "      <td>0.192266</td>\n",
       "      <td>0.003822</td>\n",
       "      <td>0.123879</td>\n",
       "      <td>-0.073926</td>\n",
       "      <td>-0.136577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <td>0.211523</td>\n",
       "      <td>0.210750</td>\n",
       "      <td>0.181187</td>\n",
       "      <td>0.043497</td>\n",
       "      <td>0.060355</td>\n",
       "      <td>0.124418</td>\n",
       "      <td>0.223394</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.098223</td>\n",
       "      <td>-0.019436</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015687</td>\n",
       "      <td>0.036029</td>\n",
       "      <td>0.275868</td>\n",
       "      <td>0.075057</td>\n",
       "      <td>0.198416</td>\n",
       "      <td>0.232611</td>\n",
       "      <td>0.098161</td>\n",
       "      <td>0.221878</td>\n",
       "      <td>-0.096559</td>\n",
       "      <td>-0.146748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhysActivity</th>\n",
       "      <td>-0.158666</td>\n",
       "      <td>-0.136102</td>\n",
       "      <td>-0.090453</td>\n",
       "      <td>-0.008249</td>\n",
       "      <td>-0.170936</td>\n",
       "      <td>-0.079823</td>\n",
       "      <td>-0.079985</td>\n",
       "      <td>-0.098223</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.133813</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027089</td>\n",
       "      <td>-0.063302</td>\n",
       "      <td>-0.273548</td>\n",
       "      <td>-0.130090</td>\n",
       "      <td>-0.234500</td>\n",
       "      <td>-0.276868</td>\n",
       "      <td>0.051753</td>\n",
       "      <td>-0.100753</td>\n",
       "      <td>0.190271</td>\n",
       "      <td>0.196551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fruits</th>\n",
       "      <td>-0.054077</td>\n",
       "      <td>-0.040852</td>\n",
       "      <td>-0.047384</td>\n",
       "      <td>0.017384</td>\n",
       "      <td>-0.084505</td>\n",
       "      <td>-0.074811</td>\n",
       "      <td>-0.008996</td>\n",
       "      <td>-0.019436</td>\n",
       "      <td>0.133813</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029385</td>\n",
       "      <td>-0.045843</td>\n",
       "      <td>-0.098687</td>\n",
       "      <td>-0.062102</td>\n",
       "      <td>-0.048572</td>\n",
       "      <td>-0.050784</td>\n",
       "      <td>-0.088723</td>\n",
       "      <td>0.061096</td>\n",
       "      <td>0.098715</td>\n",
       "      <td>0.079009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Veggies</th>\n",
       "      <td>-0.079293</td>\n",
       "      <td>-0.066624</td>\n",
       "      <td>-0.042836</td>\n",
       "      <td>0.000349</td>\n",
       "      <td>-0.056528</td>\n",
       "      <td>-0.029926</td>\n",
       "      <td>-0.047601</td>\n",
       "      <td>-0.036315</td>\n",
       "      <td>0.149322</td>\n",
       "      <td>0.238605</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029152</td>\n",
       "      <td>-0.037146</td>\n",
       "      <td>-0.115795</td>\n",
       "      <td>-0.052359</td>\n",
       "      <td>-0.066896</td>\n",
       "      <td>-0.084072</td>\n",
       "      <td>-0.052604</td>\n",
       "      <td>-0.018893</td>\n",
       "      <td>0.152512</td>\n",
       "      <td>0.154899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HvyAlcoholConsump</th>\n",
       "      <td>-0.094853</td>\n",
       "      <td>-0.027030</td>\n",
       "      <td>-0.025443</td>\n",
       "      <td>-0.027146</td>\n",
       "      <td>-0.058232</td>\n",
       "      <td>0.077835</td>\n",
       "      <td>-0.023395</td>\n",
       "      <td>-0.037130</td>\n",
       "      <td>0.019111</td>\n",
       "      <td>-0.033246</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013484</td>\n",
       "      <td>0.009683</td>\n",
       "      <td>-0.058796</td>\n",
       "      <td>0.015626</td>\n",
       "      <td>-0.036257</td>\n",
       "      <td>-0.049294</td>\n",
       "      <td>0.014164</td>\n",
       "      <td>-0.057705</td>\n",
       "      <td>0.036279</td>\n",
       "      <td>0.064095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <td>0.023191</td>\n",
       "      <td>0.035764</td>\n",
       "      <td>0.031532</td>\n",
       "      <td>0.106800</td>\n",
       "      <td>-0.013417</td>\n",
       "      <td>-0.012939</td>\n",
       "      <td>0.006484</td>\n",
       "      <td>0.015687</td>\n",
       "      <td>0.027089</td>\n",
       "      <td>0.029385</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.221658</td>\n",
       "      <td>-0.033060</td>\n",
       "      <td>-0.049850</td>\n",
       "      <td>-0.003285</td>\n",
       "      <td>0.008113</td>\n",
       "      <td>-0.006562</td>\n",
       "      <td>0.136975</td>\n",
       "      <td>0.106601</td>\n",
       "      <td>0.130492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <td>0.040977</td>\n",
       "      <td>0.026517</td>\n",
       "      <td>0.033199</td>\n",
       "      <td>-0.062669</td>\n",
       "      <td>0.065832</td>\n",
       "      <td>0.035799</td>\n",
       "      <td>0.036198</td>\n",
       "      <td>0.036029</td>\n",
       "      <td>-0.063302</td>\n",
       "      <td>-0.045843</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.221658</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.169515</td>\n",
       "      <td>0.193877</td>\n",
       "      <td>0.157451</td>\n",
       "      <td>0.127111</td>\n",
       "      <td>-0.048187</td>\n",
       "      <td>-0.129839</td>\n",
       "      <td>-0.096989</td>\n",
       "      <td>-0.198171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GenHlth</th>\n",
       "      <td>0.407612</td>\n",
       "      <td>0.320540</td>\n",
       "      <td>0.237778</td>\n",
       "      <td>0.059213</td>\n",
       "      <td>0.267888</td>\n",
       "      <td>0.152416</td>\n",
       "      <td>0.189447</td>\n",
       "      <td>0.275868</td>\n",
       "      <td>-0.273548</td>\n",
       "      <td>-0.098687</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033060</td>\n",
       "      <td>0.169515</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.315077</td>\n",
       "      <td>0.552757</td>\n",
       "      <td>0.476639</td>\n",
       "      <td>-0.014555</td>\n",
       "      <td>0.155624</td>\n",
       "      <td>-0.285420</td>\n",
       "      <td>-0.382969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MentHlth</th>\n",
       "      <td>0.087029</td>\n",
       "      <td>0.064294</td>\n",
       "      <td>0.083881</td>\n",
       "      <td>-0.010660</td>\n",
       "      <td>0.104682</td>\n",
       "      <td>0.091257</td>\n",
       "      <td>0.087303</td>\n",
       "      <td>0.075057</td>\n",
       "      <td>-0.130090</td>\n",
       "      <td>-0.062102</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.049850</td>\n",
       "      <td>0.193877</td>\n",
       "      <td>0.315077</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.380272</td>\n",
       "      <td>0.251489</td>\n",
       "      <td>-0.089204</td>\n",
       "      <td>-0.101746</td>\n",
       "      <td>-0.107005</td>\n",
       "      <td>-0.219070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhysHlth</th>\n",
       "      <td>0.213081</td>\n",
       "      <td>0.173922</td>\n",
       "      <td>0.142610</td>\n",
       "      <td>0.034540</td>\n",
       "      <td>0.161862</td>\n",
       "      <td>0.120698</td>\n",
       "      <td>0.164488</td>\n",
       "      <td>0.198416</td>\n",
       "      <td>-0.234500</td>\n",
       "      <td>-0.048572</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003285</td>\n",
       "      <td>0.157451</td>\n",
       "      <td>0.552757</td>\n",
       "      <td>0.380272</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.487976</td>\n",
       "      <td>-0.045957</td>\n",
       "      <td>0.084852</td>\n",
       "      <td>-0.159317</td>\n",
       "      <td>-0.279326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DiffWalk</th>\n",
       "      <td>0.272646</td>\n",
       "      <td>0.234784</td>\n",
       "      <td>0.162043</td>\n",
       "      <td>0.044430</td>\n",
       "      <td>0.246094</td>\n",
       "      <td>0.119789</td>\n",
       "      <td>0.192266</td>\n",
       "      <td>0.232611</td>\n",
       "      <td>-0.276868</td>\n",
       "      <td>-0.050784</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008113</td>\n",
       "      <td>0.127111</td>\n",
       "      <td>0.476639</td>\n",
       "      <td>0.251489</td>\n",
       "      <td>0.487976</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.082248</td>\n",
       "      <td>0.195265</td>\n",
       "      <td>-0.202590</td>\n",
       "      <td>-0.343245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>0.044413</td>\n",
       "      <td>0.040819</td>\n",
       "      <td>0.017324</td>\n",
       "      <td>-0.007991</td>\n",
       "      <td>0.000827</td>\n",
       "      <td>0.112125</td>\n",
       "      <td>0.003822</td>\n",
       "      <td>0.098161</td>\n",
       "      <td>0.051753</td>\n",
       "      <td>-0.088723</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006562</td>\n",
       "      <td>-0.048187</td>\n",
       "      <td>-0.014555</td>\n",
       "      <td>-0.089204</td>\n",
       "      <td>-0.045957</td>\n",
       "      <td>-0.082248</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.002315</td>\n",
       "      <td>0.043564</td>\n",
       "      <td>0.159654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0.278738</td>\n",
       "      <td>0.338132</td>\n",
       "      <td>0.240338</td>\n",
       "      <td>0.101743</td>\n",
       "      <td>-0.038648</td>\n",
       "      <td>0.105424</td>\n",
       "      <td>0.123879</td>\n",
       "      <td>0.221878</td>\n",
       "      <td>-0.100753</td>\n",
       "      <td>0.061096</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136975</td>\n",
       "      <td>-0.129839</td>\n",
       "      <td>0.155624</td>\n",
       "      <td>-0.101746</td>\n",
       "      <td>0.084852</td>\n",
       "      <td>0.195265</td>\n",
       "      <td>-0.002315</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.107127</td>\n",
       "      <td>-0.130140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Education</th>\n",
       "      <td>-0.170481</td>\n",
       "      <td>-0.141643</td>\n",
       "      <td>-0.084386</td>\n",
       "      <td>-0.008695</td>\n",
       "      <td>-0.100233</td>\n",
       "      <td>-0.140966</td>\n",
       "      <td>-0.073926</td>\n",
       "      <td>-0.096559</td>\n",
       "      <td>0.190271</td>\n",
       "      <td>0.098715</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106601</td>\n",
       "      <td>-0.096989</td>\n",
       "      <td>-0.285420</td>\n",
       "      <td>-0.107005</td>\n",
       "      <td>-0.159317</td>\n",
       "      <td>-0.202590</td>\n",
       "      <td>0.043564</td>\n",
       "      <td>-0.107127</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.460565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Income</th>\n",
       "      <td>-0.224449</td>\n",
       "      <td>-0.187657</td>\n",
       "      <td>-0.107777</td>\n",
       "      <td>0.007550</td>\n",
       "      <td>-0.124878</td>\n",
       "      <td>-0.104725</td>\n",
       "      <td>-0.136577</td>\n",
       "      <td>-0.146748</td>\n",
       "      <td>0.196551</td>\n",
       "      <td>0.079009</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130492</td>\n",
       "      <td>-0.198171</td>\n",
       "      <td>-0.382969</td>\n",
       "      <td>-0.219070</td>\n",
       "      <td>-0.279326</td>\n",
       "      <td>-0.343245</td>\n",
       "      <td>0.159654</td>\n",
       "      <td>-0.130140</td>\n",
       "      <td>0.460565</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Diabetes_binary    HighBP  HighChol  CholCheck  \\\n",
       "Diabetes_binary              1.000000  0.381516  0.289213   0.115382   \n",
       "HighBP                       0.381516  1.000000  0.316515   0.103283   \n",
       "HighChol                     0.289213  0.316515  1.000000   0.085981   \n",
       "CholCheck                    0.115382  0.103283  0.085981   1.000000   \n",
       "BMI                          0.293373  0.241019  0.131309   0.045648   \n",
       "Smoker                       0.085999  0.087438  0.093398  -0.004331   \n",
       "Stroke                       0.125427  0.129060  0.099786   0.022529   \n",
       "HeartDiseaseorAttack         0.211523  0.210750  0.181187   0.043497   \n",
       "PhysActivity                -0.158666 -0.136102 -0.090453  -0.008249   \n",
       "Fruits                      -0.054077 -0.040852 -0.047384   0.017384   \n",
       "Veggies                     -0.079293 -0.066624 -0.042836   0.000349   \n",
       "HvyAlcoholConsump           -0.094853 -0.027030 -0.025443  -0.027146   \n",
       "AnyHealthcare                0.023191  0.035764  0.031532   0.106800   \n",
       "NoDocbcCost                  0.040977  0.026517  0.033199  -0.062669   \n",
       "GenHlth                      0.407612  0.320540  0.237778   0.059213   \n",
       "MentHlth                     0.087029  0.064294  0.083881  -0.010660   \n",
       "PhysHlth                     0.213081  0.173922  0.142610   0.034540   \n",
       "DiffWalk                     0.272646  0.234784  0.162043   0.044430   \n",
       "Sex                          0.044413  0.040819  0.017324  -0.007991   \n",
       "Age                          0.278738  0.338132  0.240338   0.101743   \n",
       "Education                   -0.170481 -0.141643 -0.084386  -0.008695   \n",
       "Income                      -0.224449 -0.187657 -0.107777   0.007550   \n",
       "\n",
       "                           BMI    Smoker    Stroke  HeartDiseaseorAttack  \\\n",
       "Diabetes_binary       0.293373  0.085999  0.125427              0.211523   \n",
       "HighBP                0.241019  0.087438  0.129060              0.210750   \n",
       "HighChol              0.131309  0.093398  0.099786              0.181187   \n",
       "CholCheck             0.045648 -0.004331  0.022529              0.043497   \n",
       "BMI                   1.000000  0.011551  0.022931              0.060355   \n",
       "Smoker                0.011551  1.000000  0.064658              0.124418   \n",
       "Stroke                0.022931  0.064658  1.000000              0.223394   \n",
       "HeartDiseaseorAttack  0.060355  0.124418  0.223394              1.000000   \n",
       "PhysActivity         -0.170936 -0.079823 -0.079985             -0.098223   \n",
       "Fruits               -0.084505 -0.074811 -0.008996             -0.019436   \n",
       "Veggies              -0.056528 -0.029926 -0.047601             -0.036315   \n",
       "HvyAlcoholConsump    -0.058232  0.077835 -0.023395             -0.037130   \n",
       "AnyHealthcare        -0.013417 -0.012939  0.006484              0.015687   \n",
       "NoDocbcCost           0.065832  0.035799  0.036198              0.036029   \n",
       "GenHlth               0.267888  0.152416  0.189447              0.275868   \n",
       "MentHlth              0.104682  0.091257  0.087303              0.075057   \n",
       "PhysHlth              0.161862  0.120698  0.164488              0.198416   \n",
       "DiffWalk              0.246094  0.119789  0.192266              0.232611   \n",
       "Sex                   0.000827  0.112125  0.003822              0.098161   \n",
       "Age                  -0.038648  0.105424  0.123879              0.221878   \n",
       "Education            -0.100233 -0.140966 -0.073926             -0.096559   \n",
       "Income               -0.124878 -0.104725 -0.136577             -0.146748   \n",
       "\n",
       "                      PhysActivity    Fruits  ...  AnyHealthcare  NoDocbcCost  \\\n",
       "Diabetes_binary          -0.158666 -0.054077  ...       0.023191     0.040977   \n",
       "HighBP                   -0.136102 -0.040852  ...       0.035764     0.026517   \n",
       "HighChol                 -0.090453 -0.047384  ...       0.031532     0.033199   \n",
       "CholCheck                -0.008249  0.017384  ...       0.106800    -0.062669   \n",
       "BMI                      -0.170936 -0.084505  ...      -0.013417     0.065832   \n",
       "Smoker                   -0.079823 -0.074811  ...      -0.012939     0.035799   \n",
       "Stroke                   -0.079985 -0.008996  ...       0.006484     0.036198   \n",
       "HeartDiseaseorAttack     -0.098223 -0.019436  ...       0.015687     0.036029   \n",
       "PhysActivity              1.000000  0.133813  ...       0.027089    -0.063302   \n",
       "Fruits                    0.133813  1.000000  ...       0.029385    -0.045843   \n",
       "Veggies                   0.149322  0.238605  ...       0.029152    -0.037146   \n",
       "HvyAlcoholConsump         0.019111 -0.033246  ...      -0.013484     0.009683   \n",
       "AnyHealthcare             0.027089  0.029385  ...       1.000000    -0.221658   \n",
       "NoDocbcCost              -0.063302 -0.045843  ...      -0.221658     1.000000   \n",
       "GenHlth                  -0.273548 -0.098687  ...      -0.033060     0.169515   \n",
       "MentHlth                 -0.130090 -0.062102  ...      -0.049850     0.193877   \n",
       "PhysHlth                 -0.234500 -0.048572  ...      -0.003285     0.157451   \n",
       "DiffWalk                 -0.276868 -0.050784  ...       0.008113     0.127111   \n",
       "Sex                       0.051753 -0.088723  ...      -0.006562    -0.048187   \n",
       "Age                      -0.100753  0.061096  ...       0.136975    -0.129839   \n",
       "Education                 0.190271  0.098715  ...       0.106601    -0.096989   \n",
       "Income                    0.196551  0.079009  ...       0.130492    -0.198171   \n",
       "\n",
       "                       GenHlth  MentHlth  PhysHlth  DiffWalk       Sex  \\\n",
       "Diabetes_binary       0.407612  0.087029  0.213081  0.272646  0.044413   \n",
       "HighBP                0.320540  0.064294  0.173922  0.234784  0.040819   \n",
       "HighChol              0.237778  0.083881  0.142610  0.162043  0.017324   \n",
       "CholCheck             0.059213 -0.010660  0.034540  0.044430 -0.007991   \n",
       "BMI                   0.267888  0.104682  0.161862  0.246094  0.000827   \n",
       "Smoker                0.152416  0.091257  0.120698  0.119789  0.112125   \n",
       "Stroke                0.189447  0.087303  0.164488  0.192266  0.003822   \n",
       "HeartDiseaseorAttack  0.275868  0.075057  0.198416  0.232611  0.098161   \n",
       "PhysActivity         -0.273548 -0.130090 -0.234500 -0.276868  0.051753   \n",
       "Fruits               -0.098687 -0.062102 -0.048572 -0.050784 -0.088723   \n",
       "Veggies              -0.115795 -0.052359 -0.066896 -0.084072 -0.052604   \n",
       "HvyAlcoholConsump    -0.058796  0.015626 -0.036257 -0.049294  0.014164   \n",
       "AnyHealthcare        -0.033060 -0.049850 -0.003285  0.008113 -0.006562   \n",
       "NoDocbcCost           0.169515  0.193877  0.157451  0.127111 -0.048187   \n",
       "GenHlth               1.000000  0.315077  0.552757  0.476639 -0.014555   \n",
       "MentHlth              0.315077  1.000000  0.380272  0.251489 -0.089204   \n",
       "PhysHlth              0.552757  0.380272  1.000000  0.487976 -0.045957   \n",
       "DiffWalk              0.476639  0.251489  0.487976  1.000000 -0.082248   \n",
       "Sex                  -0.014555 -0.089204 -0.045957 -0.082248  1.000000   \n",
       "Age                   0.155624 -0.101746  0.084852  0.195265 -0.002315   \n",
       "Education            -0.285420 -0.107005 -0.159317 -0.202590  0.043564   \n",
       "Income               -0.382969 -0.219070 -0.279326 -0.343245  0.159654   \n",
       "\n",
       "                           Age  Education    Income  \n",
       "Diabetes_binary       0.278738  -0.170481 -0.224449  \n",
       "HighBP                0.338132  -0.141643 -0.187657  \n",
       "HighChol              0.240338  -0.084386 -0.107777  \n",
       "CholCheck             0.101743  -0.008695  0.007550  \n",
       "BMI                  -0.038648  -0.100233 -0.124878  \n",
       "Smoker                0.105424  -0.140966 -0.104725  \n",
       "Stroke                0.123879  -0.073926 -0.136577  \n",
       "HeartDiseaseorAttack  0.221878  -0.096559 -0.146748  \n",
       "PhysActivity         -0.100753   0.190271  0.196551  \n",
       "Fruits                0.061096   0.098715  0.079009  \n",
       "Veggies              -0.018893   0.152512  0.154899  \n",
       "HvyAlcoholConsump    -0.057705   0.036279  0.064095  \n",
       "AnyHealthcare         0.136975   0.106601  0.130492  \n",
       "NoDocbcCost          -0.129839  -0.096989 -0.198171  \n",
       "GenHlth               0.155624  -0.285420 -0.382969  \n",
       "MentHlth             -0.101746  -0.107005 -0.219070  \n",
       "PhysHlth              0.084852  -0.159317 -0.279326  \n",
       "DiffWalk              0.195265  -0.202590 -0.343245  \n",
       "Sex                  -0.002315   0.043564  0.159654  \n",
       "Age                   1.000000  -0.107127 -0.130140  \n",
       "Education            -0.107127   1.000000  0.460565  \n",
       "Income               -0.130140   0.460565  1.000000  \n",
       "\n",
       "[22 rows x 22 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes_binary</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Diabetes_binary  HighBP  HighChol  CholCheck   BMI  Stroke  \\\n",
       "0              0.0     1.0       0.0        1.0  26.0     0.0   \n",
       "1              0.0     1.0       1.0        1.0  26.0     1.0   \n",
       "2              0.0     0.0       0.0        1.0  26.0     0.0   \n",
       "3              0.0     1.0       1.0        1.0  28.0     0.0   \n",
       "4              0.0     0.0       0.0        1.0  29.0     0.0   \n",
       "\n",
       "   HeartDiseaseorAttack  PhysActivity  GenHlth  PhysHlth  DiffWalk   Age  \\\n",
       "0                   0.0           1.0      3.0      30.0       0.0   4.0   \n",
       "1                   0.0           0.0      3.0       0.0       0.0  12.0   \n",
       "2                   0.0           1.0      1.0      10.0       0.0  13.0   \n",
       "3                   0.0           1.0      3.0       3.0       0.0  11.0   \n",
       "4                   0.0           1.0      2.0       0.0       0.0   8.0   \n",
       "\n",
       "   Education  Income  \n",
       "0        6.0     8.0  \n",
       "1        6.0     8.0  \n",
       "2        6.0     8.0  \n",
       "3        6.0     8.0  \n",
       "4        5.0     8.0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dropping columns that may not be helpful for analysis, heavy alcohol consumption removed since because it is self reported it may not be as honest\n",
    "columns_to_drop = ['Fruits', 'Veggies', 'MentHlth', 'NoDocbcCost', 'Sex', 'AnyHealthcare', 'HvyAlcoholConsump', 'Smoker']\n",
    "diabetes_df = diabetes.copy()\n",
    "diabetes_df = diabetes_df.drop(columns=columns_to_drop)\n",
    "diabetes_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Grouping (using functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age\n",
    "1. Age 18 to 24\n",
    "2. Age 25 to 29\n",
    "3. Age 30 to 34\n",
    "4. Age 35 to 39\n",
    "5. Age 40 to 44\n",
    "6. Age 45 to 49\n",
    "7. Age 50 to 54\n",
    "8. Age 55 to 59\n",
    "9. Age 60 to 64\n",
    "10. Age 65 to 69\n",
    "11. Age 70 to 74\n",
    "12. Age 75 to 79\n",
    "13. Age 80 or older\n",
    "\n",
    "#### split every three groups\n",
    "#### 1 = 18-34 (1-3), 2 = 35-49 (4-6), 3 = 50-64 (7-9), 4 = 65-79 (10-12), 5 = 80+ (13) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age\n",
       "10.0    10856\n",
       "9.0     10112\n",
       "8.0      8603\n",
       "11.0     8044\n",
       "7.0      6872\n",
       "13.0     5426\n",
       "12.0     5394\n",
       "6.0      4648\n",
       "5.0      3520\n",
       "4.0      2793\n",
       "3.0      2049\n",
       "2.0      1396\n",
       "1.0       979\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_df['Age'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def age_replace(x):\n",
    "#     if x >= 1 and x <= 3:\n",
    "#         return \"Age 18-34\"\n",
    "#     elif x > 3 and x <= 6:\n",
    "#         return \"Age 35-49\"\n",
    "#     elif x > 6 and x <= 9:\n",
    "#         return \"Age 50-64\"\n",
    "#     elif x > 9 and x <= 12:\n",
    "#         return \"Age 65-79\"\n",
    "#     elif x > 12:\n",
    "#         return \"Age 80+\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diabetes_df['Age'] = diabetes_df['Age'].apply(age_replace)\n",
    "# diabetes_df['Age'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDUCATION\n",
    "1. Never attended school or only kindergarten\n",
    "2. Grades 1 through 8 (Elementary)\n",
    "3. Grades 9 through 11 (Some high school)\n",
    "4. Grade 12 or GED (High school graduate)\n",
    "5. College 1 year to 3 years (Some college or technical school)\n",
    "6. College 4 years or more (College graduate)\n",
    "\n",
    "#### split between : higher vs non-higher edu, 5-6 higher, 1-4 lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def edu_replace(x):\n",
    "#     if x >= 1 and x <= 4:\n",
    "#         return \"Lower Education\"\n",
    "#     elif x > 4:\n",
    "#         return \"Higher Education\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diabetes_df['Education'] = diabetes_df['Education'].apply(edu_replace)\n",
    "# diabetes_df['Education'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INCOME\n",
    "1. Less than $10,000\n",
    "2. Less than $15,000 ($10,000 to less than $15,000)\n",
    "3. Less than $20,000 ($15,000 to less than $20,000)\n",
    "4. Less than $25,000 ($20,000 to less than $25,000)\n",
    "5. Less than $35,000 ($25,000 to less than $35,000)\n",
    "6. Less than $50,000 ($35,000 to less than $50,000)\n",
    "7. Less than $75,000 ($50,000 to less than $75,000)\n",
    "8. $75,000 or more\n",
    "\n",
    "#### group 1-3, 4-7, 8 by itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Income\n",
       "8.0    20646\n",
       "7.0    11425\n",
       "6.0    10287\n",
       "5.0     8010\n",
       "4.0     6658\n",
       "3.0     5557\n",
       "2.0     4498\n",
       "1.0     3611\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_df['Income'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def income_replace(x):\n",
    "#     if x >= 1 and x <= 3:\n",
    "#         return \"Less than $20,000\"\n",
    "#     elif x > 3 and x <= 7:\n",
    "#         return \"Between $20,000 and $75,000\"\n",
    "#     elif x > 7:\n",
    "#         return \"More than $75,000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diabetes_df['Income'] = diabetes_df['Income'].apply(income_replace)\n",
    "# diabetes_df['Income'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BMI_classification(x):\n",
    "    if x < 18.5:\n",
    "        return \"Underweight\"\n",
    "    elif x > 18.5 and x <=24.9:\n",
    "        return \"Normal\"\n",
    "    elif x > 24.9 and x <= 29.9:\n",
    "        return \"Overweight\"\n",
    "    elif x > 29.9 and x <= 34.9:\n",
    "        return \"Obesity 1\"\n",
    "    elif x > 34.9 and x <= 39.9:\n",
    "        return \"Obesity 2\"\n",
    "    elif x > 39.9:\n",
    "        return \"Obesity 3\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BMI\n",
       "Overweight     24135\n",
       "Obesity 1      17301\n",
       "Normal         14460\n",
       "Obesity 2       8112\n",
       "Obesity 3       6031\n",
       "Underweight      653\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_df['BMI'] = diabetes_df['BMI'].apply(BMI_classification)\n",
    "diabetes_df['BMI'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin Splitting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = diabetes_df.drop(columns='Diabetes_binary')\n",
    "y = diabetes_df['Diabetes_binary']\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, random_state=12)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding Categorical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BMI    0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "BMI    0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create encoder and fit\n",
    "encode_BMI = OrdinalEncoder(categories=[['Underweight', 'Normal', 'Overweight', 'Obesity 1', 'Obesity 2', 'Obesity 3']], handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "encode_BMI.fit(x_train['BMI'].values.reshape(-1,1))\n",
    "encode_BMI_train = encode_BMI.transform(x_train['BMI'].values.reshape(-1, 1))\n",
    "encode_BMI_test = encode_BMI.transform(x_test['BMI'].values.reshape(-1, 1))\n",
    "\n",
    "# create the df\n",
    "encode_BMI_df_train = pd.DataFrame(encode_BMI_train, columns=['BMI'])\n",
    "encode_BMI_df_test = pd.DataFrame(encode_BMI_test, columns=['BMI'])\n",
    "encode_BMI_df_train.head()\n",
    "display(encode_BMI_df_train.isna().sum())\n",
    "display(encode_BMI_df_test.isna().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create encoder and fit\n",
    "# encode_income = OrdinalEncoder(categories=[['Less than $20,000','Between $20,000 and $75,000','More than $75,000']], handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "# encode_income.fit(x_train['Income'].values.reshape(-1,1))\n",
    "# encode_income_train = encode_income.transform(x_train['Income'].values.reshape(-1, 1))\n",
    "# encode_income_test = encode_income.transform(x_test['Income'].values.reshape(-1, 1))\n",
    "\n",
    "# # create the df\n",
    "# encode_income_df_train = pd.DataFrame(encode_income_train, columns=['Income'])\n",
    "# encode_income_df_test = pd.DataFrame(encode_income_test, columns=['Income'])\n",
    "# display(encode_income_df_train.isna().sum())\n",
    "# display(encode_income_df_test.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create encoder and fit \n",
    "# encode_educ = OrdinalEncoder(categories=[['Lower Education', 'Higher Education']], handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "# encode_educ.fit(x_train['Education'].values.reshape(-1,1))\n",
    "# encode_educ_train = encode_educ.transform(x_train['Education'].values.reshape(-1, 1))\n",
    "# encode_educ_test = encode_educ.transform(x_test['Education'].values.reshape(-1, 1))\n",
    "\n",
    "# # create the df\n",
    "# encode_educ_df_train = pd.DataFrame(encode_educ_train, columns=['Education'])\n",
    "# encode_educ_df_test = pd.DataFrame(encode_educ_test, columns=['Education'])\n",
    "\n",
    "# display(encode_educ_df_train.isna().sum())\n",
    "# display(encode_educ_df_test.isna().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age\n",
       "10.0    8110\n",
       "9.0     7591\n",
       "8.0     6414\n",
       "11.0    5997\n",
       "7.0     5156\n",
       "13.0    4130\n",
       "12.0    4031\n",
       "6.0     3502\n",
       "5.0     2660\n",
       "4.0     2099\n",
       "3.0     1533\n",
       "2.0     1042\n",
       "1.0      754\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the original columns names for the age column\n",
    "#diabetes_df['Age'].value_counts()\n",
    "x_train['Age'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Education\n",
       "6.0    19477\n",
       "5.0    15026\n",
       "4.0    14646\n",
       "3.0     2574\n",
       "2.0     1238\n",
       "1.0       58\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train['Education'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create encoder and fit \n",
    "# encode_age = OrdinalEncoder(categories=[['Age 18-34', 'Age 35-49', 'Age 50-64', 'Age 65-79', 'Age 80+']], handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "# encode_age.fit(x_train['Age'].values.reshape(-1,1))\n",
    "# encode_age_train = encode_age.transform(x_train['Age'].values.reshape(-1, 1))\n",
    "# encode_age_test = encode_age.transform(x_test['Age'].values.reshape(-1, 1))\n",
    "\n",
    "# # create the df\n",
    "# encode_age_df_train = pd.DataFrame(encode_age_train, columns=['Age'])\n",
    "# encode_age_df_test = pd.DataFrame(encode_age_test, columns=['Age'])\n",
    "\n",
    "# display(encode_age_df_train.isna().sum())\n",
    "# display(encode_age_df_test.isna().sum())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Group all encoded_dfs with the main df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HighBP                  0\n",
       "HighChol                0\n",
       "CholCheck               0\n",
       "Stroke                  0\n",
       "HeartDiseaseorAttack    0\n",
       "PhysActivity            0\n",
       "GenHlth                 0\n",
       "PhysHlth                0\n",
       "DiffWalk                0\n",
       "Age                     0\n",
       "Education               0\n",
       "Income                  0\n",
       "BMI                     0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "HighBP                  0\n",
       "HighChol                0\n",
       "CholCheck               0\n",
       "Stroke                  0\n",
       "HeartDiseaseorAttack    0\n",
       "PhysActivity            0\n",
       "GenHlth                 0\n",
       "PhysHlth                0\n",
       "DiffWalk                0\n",
       "Age                     0\n",
       "Education               0\n",
       "Income                  0\n",
       "BMI                     0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create a copy of the df without the unencoded columns\n",
    "# train\n",
    "x_train_unencoded = x_train.copy().drop(columns=['BMI'])\n",
    "x_train_unencoded = x_train_unencoded.reset_index(drop=True)\n",
    "# test\n",
    "x_test_unencoded = x_test.copy().drop(columns=['BMI'])\n",
    "x_test_unencoded = x_test_unencoded.reset_index(drop=True)\n",
    "\n",
    "# add the encoded columns\n",
    "x_train_encoded = pd.concat([x_train_unencoded, encode_BMI_df_train], axis=1)\n",
    "x_test_encoded = pd.concat([x_test_unencoded, encode_BMI_df_test], axis=1)\n",
    "\n",
    "# the results\n",
    "display(x_train_encoded.isna().sum())\n",
    "display(x_test_encoded.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale the data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train_encoded)\n",
    "x_train_encoded = scaler.transform(x_train_encoded)\n",
    "x_test_encoded = scaler.transform(x_test_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the ML Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 1, Train/Test Score: 0.916/0.663\n",
      "k: 3, Train/Test Score: 0.816/0.699\n",
      "k: 5, Train/Test Score: 0.790/0.714\n",
      "k: 7, Train/Test Score: 0.779/0.723\n",
      "k: 9, Train/Test Score: 0.773/0.730\n",
      "k: 11, Train/Test Score: 0.767/0.734\n",
      "k: 13, Train/Test Score: 0.765/0.735\n",
      "k: 15, Train/Test Score: 0.763/0.739\n",
      "k: 17, Train/Test Score: 0.761/0.742\n",
      "k: 19, Train/Test Score: 0.760/0.743\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loop through different k values to find which has the highest accuracy.\n",
    "# Note: We use only odd numbers because we don't want any ties.\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for k in range(1, 20, 2):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(x_train_encoded, y_train)\n",
    "    train_score = knn.score(x_train_encoded, y_train)\n",
    "    test_score = knn.score(x_test_encoded, y_test)\n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "    print(f\"k: {k}, Train/Test Score: {train_score:.3f}/{test_score:.3f}\")\n",
    "    \n",
    "# Plot the results\n",
    "plt.plot(range(1, 20, 2), train_scores, marker='o', label=\"training scores\")\n",
    "plt.plot(range(1, 20, 2), test_scores, marker=\"x\", label=\"testing scores\")\n",
    "plt.xlabel(\"k neighbors\")\n",
    "plt.ylabel(\"accuracy score\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7522209019408137"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.74      0.75      8847\n",
      "         1.0       0.74      0.77      0.76      8826\n",
      "\n",
      "    accuracy                           0.75     17673\n",
      "   macro avg       0.75      0.75      0.75     17673\n",
      "weighted avg       0.75      0.75      0.75     17673\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Create and fit the logistic regression model\n",
    "logistic_regression_model = LogisticRegression(random_state=1, max_iter=1000)\n",
    "logistic_regression_model.fit(x_train_encoded, y_train)\n",
    "\n",
    "#make and save testing predictions with the saved logistic regression model using the test data\n",
    "predictions = logistic_regression_model.predict(x_test_encoded)\n",
    "\n",
    "# Review the accuracy\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "display(accuracy)\n",
    "\n",
    "#print the confusion matrix\n",
    "confusion_matrix(y_test, predictions)\n",
    "\n",
    "#print the classification report\n",
    "print(classification_report(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.751145815650993 (ungrouping age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.6714762632263905\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>6258</td>\n",
       "      <td>2589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>3217</td>\n",
       "      <td>5609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0         6258         2589\n",
       "Actual 1         3217         5609"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.66      0.71      0.68      8847\n",
      "         1.0       0.68      0.64      0.66      8826\n",
      "\n",
      "    accuracy                           0.67     17673\n",
      "   macro avg       0.67      0.67      0.67     17673\n",
      "weighted avg       0.67      0.67      0.67     17673\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create the model\n",
    "tree_model = tree.DecisionTreeClassifier()\n",
    "#fit the model\n",
    "tree_model = tree_model.fit(x_train_encoded, y_train)\n",
    "# Making predictions using the testing data\n",
    "predictions = tree_model.predict(x_test_encoded)\n",
    "# Calculate the accuracy score\n",
    "acc_score = accuracy_score(y_test, predictions)\n",
    "print(f\"Accuracy Score : {acc_score}\")\n",
    "\n",
    "# Display the confusion matrix\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"]\n",
    ")\n",
    "\n",
    "# Displaying results\n",
    "print(\"Confusion Matrix\")\n",
    "display(cm_df)\n",
    "# Display the classification report\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.7765329410211433\n",
      "Testing Score: 0.7536354891642618\n",
      "Accuracy Score : 0.7536354891642618\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>6355</td>\n",
       "      <td>2492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>1862</td>\n",
       "      <td>6964</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0         6355         2492\n",
       "Actual 1         1862         6964"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.72      0.74      8847\n",
      "         1.0       0.74      0.79      0.76      8826\n",
      "\n",
      "    accuracy                           0.75     17673\n",
      "   macro avg       0.75      0.75      0.75     17673\n",
      "weighted avg       0.75      0.75      0.75     17673\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the Random Forest model\n",
    "clf = RandomForestClassifier(random_state=1, n_estimators=500, max_depth=11).fit(x_train_encoded, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "print(f'Training Score: {clf.score(x_train_encoded, y_train)}')\n",
    "print(f'Testing Score: {clf.score(x_test_encoded, y_test)}')\n",
    "\n",
    "# Calculate the accuracy score\n",
    "predictions = clf.predict(x_test_encoded)\n",
    "acc_score = accuracy_score(y_test, predictions)\n",
    "print(f\"Accuracy Score : {acc_score}\")\n",
    "\n",
    "# Display the confusion matrix\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"]\n",
    ")\n",
    "\n",
    "# Displaying results\n",
    "print(\"Confusion Matrix\")\n",
    "display(cm_df)\n",
    "# Display the classification report\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, predictions))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7562949131443445\n",
      "Confusion Matrix: [[6322 2525]\n",
      " [1782 7044]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.71      0.75      8847\n",
      "         1.0       0.74      0.80      0.77      8826\n",
      "\n",
      "    accuracy                           0.76     17673\n",
      "   macro avg       0.76      0.76      0.76     17673\n",
      "weighted avg       0.76      0.76      0.76     17673\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#%pip install xgboost\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import classification_report\n",
    "#from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "# Create the XGBClassifier model\n",
    "xgb_model = XGBClassifier(random_state=1, learning_rate=0.05, n_estimators=1000, max_depth=3)\n",
    "# Fit the model\n",
    "xgb_model.fit(x_train_encoded, y_train)\n",
    "# Make predictions\n",
    "predictions = xgb_model.predict(x_test_encoded)\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Create the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, predictions)\n",
    "print(f\"Confusion Matrix: {conf_matrix}\")\n",
    "\n",
    "#create heatmap for confusion matrix\n",
    "sns.heatmap(conf_matrix, annot=True, cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#Create the classification report\n",
    "class_report = classification_report(y_test, predictions)\n",
    "print(f\"Classification Report: \\n{class_report}\")\n",
    "\n",
    "# # Create the ROC curve\n",
    "# RocCurveDisplay.from_estimator(xgb_model, x_test_encoded, y_test)\n",
    "# plt.show()\n",
    "\n",
    "# Create the precision-recall curve\n",
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "\n",
    "# PrecisionRecallDisplay.from_estimator(xgb_model, x_test_encoded, y_test)\n",
    "# plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV 1/5] END .....max_depth=3, n_estimators=100;, score=0.743 total time=   0.5s\n",
      "[CV 2/5] END .....max_depth=3, n_estimators=100;, score=0.728 total time=   0.6s\n",
      "[CV 3/5] END .....max_depth=3, n_estimators=100;, score=0.732 total time=   0.6s\n",
      "[CV 4/5] END .....max_depth=3, n_estimators=100;, score=0.733 total time=   0.5s\n",
      "[CV 5/5] END .....max_depth=3, n_estimators=100;, score=0.740 total time=   0.5s\n",
      "[CV 1/5] END .....max_depth=3, n_estimators=500;, score=0.742 total time=   2.8s\n",
      "[CV 2/5] END .....max_depth=3, n_estimators=500;, score=0.728 total time=   2.7s\n",
      "[CV 3/5] END .....max_depth=3, n_estimators=500;, score=0.733 total time=   2.6s\n",
      "[CV 4/5] END .....max_depth=3, n_estimators=500;, score=0.732 total time=   3.2s\n",
      "[CV 5/5] END .....max_depth=3, n_estimators=500;, score=0.740 total time=   2.8s\n",
      "[CV 1/5] END ....max_depth=3, n_estimators=1000;, score=0.743 total time=   5.3s\n",
      "[CV 2/5] END ....max_depth=3, n_estimators=1000;, score=0.728 total time=   5.1s\n",
      "[CV 3/5] END ....max_depth=3, n_estimators=1000;, score=0.733 total time=   5.2s\n",
      "[CV 4/5] END ....max_depth=3, n_estimators=1000;, score=0.733 total time=   5.3s\n",
      "[CV 5/5] END ....max_depth=3, n_estimators=1000;, score=0.740 total time=   5.5s\n",
      "[CV 1/5] END .....max_depth=7, n_estimators=100;, score=0.751 total time=   0.9s\n",
      "[CV 2/5] END .....max_depth=7, n_estimators=100;, score=0.741 total time=   0.9s\n",
      "[CV 3/5] END .....max_depth=7, n_estimators=100;, score=0.743 total time=   0.9s\n",
      "[CV 4/5] END .....max_depth=7, n_estimators=100;, score=0.741 total time=   0.9s\n",
      "[CV 5/5] END .....max_depth=7, n_estimators=100;, score=0.747 total time=   0.9s\n",
      "[CV 1/5] END .....max_depth=7, n_estimators=500;, score=0.753 total time=   4.6s\n",
      "[CV 2/5] END .....max_depth=7, n_estimators=500;, score=0.740 total time=   4.3s\n",
      "[CV 3/5] END .....max_depth=7, n_estimators=500;, score=0.743 total time=   4.3s\n",
      "[CV 4/5] END .....max_depth=7, n_estimators=500;, score=0.741 total time=   4.3s\n",
      "[CV 5/5] END .....max_depth=7, n_estimators=500;, score=0.748 total time=   4.3s\n",
      "[CV 1/5] END ....max_depth=7, n_estimators=1000;, score=0.753 total time=   9.4s\n",
      "[CV 2/5] END ....max_depth=7, n_estimators=1000;, score=0.740 total time=   8.8s\n",
      "[CV 3/5] END ....max_depth=7, n_estimators=1000;, score=0.743 total time=   8.7s\n",
      "[CV 4/5] END ....max_depth=7, n_estimators=1000;, score=0.741 total time=   8.7s\n",
      "[CV 5/5] END ....max_depth=7, n_estimators=1000;, score=0.748 total time=  10.1s\n",
      "[CV 1/5] END ....max_depth=11, n_estimators=100;, score=0.753 total time=   1.2s\n",
      "[CV 2/5] END ....max_depth=11, n_estimators=100;, score=0.741 total time=   1.1s\n",
      "[CV 3/5] END ....max_depth=11, n_estimators=100;, score=0.744 total time=   1.1s\n",
      "[CV 4/5] END ....max_depth=11, n_estimators=100;, score=0.743 total time=   1.1s\n",
      "[CV 5/5] END ....max_depth=11, n_estimators=100;, score=0.750 total time=   1.1s\n",
      "[CV 1/5] END ....max_depth=11, n_estimators=500;, score=0.753 total time=   5.8s\n",
      "[CV 2/5] END ....max_depth=11, n_estimators=500;, score=0.742 total time=   5.8s\n",
      "[CV 3/5] END ....max_depth=11, n_estimators=500;, score=0.746 total time=   6.0s\n",
      "[CV 4/5] END ....max_depth=11, n_estimators=500;, score=0.744 total time=   5.7s\n",
      "[CV 5/5] END ....max_depth=11, n_estimators=500;, score=0.751 total time=   5.8s\n",
      "[CV 1/5] END ...max_depth=11, n_estimators=1000;, score=0.754 total time=  11.8s\n",
      "[CV 2/5] END ...max_depth=11, n_estimators=1000;, score=0.741 total time=  11.7s\n",
      "[CV 3/5] END ...max_depth=11, n_estimators=1000;, score=0.745 total time=  12.0s\n",
      "[CV 4/5] END ...max_depth=11, n_estimators=1000;, score=0.745 total time=  15.2s\n",
      "[CV 5/5] END ...max_depth=11, n_estimators=1000;, score=0.750 total time=  11.9s\n",
      "Accuracy: 0.7538618231200136\n",
      "{'max_depth': 11, 'n_estimators': 500}\n",
      "0.747053009096555\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "#grid search\n",
    "\n",
    "#%pip install -U xgboost scikit-learn\n",
    "\n",
    "\n",
    "# Create the parameter grid for the GridSearchCV model running random forest\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 500, 1000],\n",
    "    'max_depth': [3, 7, 11]\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "# Create the GridSearchCV model\n",
    "#grid_model = GridSearchCV(logistic_regression_model, param_grid, verbose=3)\n",
    "grid_model = GridSearchCV(RandomForestClassifier(), param_grid, verbose=3)\n",
    "\n",
    "# Fit the model\n",
    "grid_model.fit(x_train_encoded, y_train)\n",
    "\n",
    "# Make predictions\n",
    "predictions = grid_model.predict(x_test_encoded)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Print the best parameters\n",
    "print(grid_model.best_params_)\n",
    "print(grid_model.best_score_)\n",
    "# print(grid_model.best_estimator_)\n",
    "# print(grid_model.cv_results_)\n",
    "# print(grid_model.best_index_)\n",
    "# print(grid_model.scorer_)\n",
    "# print(grid_model.n_splits_)\n",
    "# print(grid_model.refit_time_)\n",
    "# print(grid_model.error_score)\n",
    "# print(grid_model.param_grid)\n",
    "# print(grid_model.pre_dispatch)\n",
    "# print(grid_model.return_train_score)\n",
    "# print(grid_model.multimetric_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy: 0.7536354891642618\n",
    "{'max_depth': 11, 'n_estimators': 500}\n",
    "0.7458270566257893\n",
    "Testing Score: 0.753522322186386\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "[CV 1/5] END C=0.1, max_iter=100, penalty=l1, solver=liblinear;, score=0.753 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, max_iter=100, penalty=l1, solver=liblinear;, score=0.738 total time=   0.1s\n",
      "[CV 3/5] END C=0.1, max_iter=100, penalty=l1, solver=liblinear;, score=0.743 total time=   0.1s\n",
      "[CV 4/5] END C=0.1, max_iter=100, penalty=l1, solver=liblinear;, score=0.743 total time=   0.1s\n",
      "[CV 5/5] END C=0.1, max_iter=100, penalty=l1, solver=liblinear;, score=0.745 total time=   0.0s\n",
      "[CV 1/5] END C=0.1, max_iter=100, penalty=l2, solver=liblinear;, score=0.753 total time=   0.1s\n",
      "[CV 2/5] END C=0.1, max_iter=100, penalty=l2, solver=liblinear;, score=0.738 total time=   0.1s\n",
      "[CV 3/5] END C=0.1, max_iter=100, penalty=l2, solver=liblinear;, score=0.743 total time=   0.1s\n",
      "[CV 4/5] END C=0.1, max_iter=100, penalty=l2, solver=liblinear;, score=0.743 total time=   0.1s\n",
      "[CV 5/5] END C=0.1, max_iter=100, penalty=l2, solver=liblinear;, score=0.746 total time=   0.0s\n",
      "[CV 1/5] END C=0.1, max_iter=1000, penalty=l1, solver=liblinear;, score=0.753 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, max_iter=1000, penalty=l1, solver=liblinear;, score=0.738 total time=   0.1s\n",
      "[CV 3/5] END C=0.1, max_iter=1000, penalty=l1, solver=liblinear;, score=0.743 total time=   0.1s\n",
      "[CV 4/5] END C=0.1, max_iter=1000, penalty=l1, solver=liblinear;, score=0.743 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, max_iter=1000, penalty=l1, solver=liblinear;, score=0.745 total time=   0.0s\n",
      "[CV 1/5] END C=0.1, max_iter=1000, penalty=l2, solver=liblinear;, score=0.753 total time=   0.1s\n",
      "[CV 2/5] END C=0.1, max_iter=1000, penalty=l2, solver=liblinear;, score=0.738 total time=   0.1s\n",
      "[CV 3/5] END C=0.1, max_iter=1000, penalty=l2, solver=liblinear;, score=0.743 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, max_iter=1000, penalty=l2, solver=liblinear;, score=0.743 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, max_iter=1000, penalty=l2, solver=liblinear;, score=0.746 total time=   0.0s\n",
      "[CV 1/5] END C=0.1, max_iter=10000, penalty=l1, solver=liblinear;, score=0.753 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, max_iter=10000, penalty=l1, solver=liblinear;, score=0.738 total time=   0.1s\n",
      "[CV 3/5] END C=0.1, max_iter=10000, penalty=l1, solver=liblinear;, score=0.743 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, max_iter=10000, penalty=l1, solver=liblinear;, score=0.743 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, max_iter=10000, penalty=l1, solver=liblinear;, score=0.745 total time=   0.0s\n",
      "[CV 1/5] END C=0.1, max_iter=10000, penalty=l2, solver=liblinear;, score=0.753 total time=   0.1s\n",
      "[CV 2/5] END C=0.1, max_iter=10000, penalty=l2, solver=liblinear;, score=0.738 total time=   0.1s\n",
      "[CV 3/5] END C=0.1, max_iter=10000, penalty=l2, solver=liblinear;, score=0.743 total time=   0.1s\n",
      "[CV 4/5] END C=0.1, max_iter=10000, penalty=l2, solver=liblinear;, score=0.743 total time=   0.1s\n",
      "[CV 5/5] END C=0.1, max_iter=10000, penalty=l2, solver=liblinear;, score=0.746 total time=   0.1s\n",
      "[CV 1/5] END C=1, max_iter=100, penalty=l1, solver=liblinear;, score=0.753 total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=100, penalty=l1, solver=liblinear;, score=0.738 total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=100, penalty=l1, solver=liblinear;, score=0.743 total time=   0.1s\n",
      "[CV 4/5] END C=1, max_iter=100, penalty=l1, solver=liblinear;, score=0.743 total time=   0.1s\n",
      "[CV 5/5] END C=1, max_iter=100, penalty=l1, solver=liblinear;, score=0.745 total time=   0.1s\n",
      "[CV 1/5] END C=1, max_iter=100, penalty=l2, solver=liblinear;, score=0.753 total time=   0.1s\n",
      "[CV 2/5] END C=1, max_iter=100, penalty=l2, solver=liblinear;, score=0.738 total time=   0.1s\n",
      "[CV 3/5] END C=1, max_iter=100, penalty=l2, solver=liblinear;, score=0.743 total time=   0.1s\n",
      "[CV 4/5] END C=1, max_iter=100, penalty=l2, solver=liblinear;, score=0.743 total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=100, penalty=l2, solver=liblinear;, score=0.745 total time=   0.1s\n",
      "[CV 1/5] END C=1, max_iter=1000, penalty=l1, solver=liblinear;, score=0.753 total time=   0.1s\n",
      "[CV 2/5] END C=1, max_iter=1000, penalty=l1, solver=liblinear;, score=0.738 total time=   0.1s\n",
      "[CV 3/5] END C=1, max_iter=1000, penalty=l1, solver=liblinear;, score=0.743 total time=   0.1s\n",
      "[CV 4/5] END C=1, max_iter=1000, penalty=l1, solver=liblinear;, score=0.743 total time=   0.1s\n",
      "[CV 5/5] END C=1, max_iter=1000, penalty=l1, solver=liblinear;, score=0.745 total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=1000, penalty=l2, solver=liblinear;, score=0.753 total time=   0.1s\n",
      "[CV 2/5] END C=1, max_iter=1000, penalty=l2, solver=liblinear;, score=0.738 total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=1000, penalty=l2, solver=liblinear;, score=0.743 total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=1000, penalty=l2, solver=liblinear;, score=0.743 total time=   0.1s\n",
      "[CV 5/5] END C=1, max_iter=1000, penalty=l2, solver=liblinear;, score=0.745 total time=   0.1s\n",
      "[CV 1/5] END C=1, max_iter=10000, penalty=l1, solver=liblinear;, score=0.753 total time=   0.1s\n",
      "[CV 2/5] END C=1, max_iter=10000, penalty=l1, solver=liblinear;, score=0.738 total time=   0.1s\n",
      "[CV 3/5] END C=1, max_iter=10000, penalty=l1, solver=liblinear;, score=0.743 total time=   0.1s\n",
      "[CV 4/5] END C=1, max_iter=10000, penalty=l1, solver=liblinear;, score=0.743 total time=   0.1s\n",
      "[CV 5/5] END C=1, max_iter=10000, penalty=l1, solver=liblinear;, score=0.745 total time=   0.1s\n",
      "[CV 1/5] END C=1, max_iter=10000, penalty=l2, solver=liblinear;, score=0.753 total time=   0.1s\n",
      "[CV 2/5] END C=1, max_iter=10000, penalty=l2, solver=liblinear;, score=0.738 total time=   0.1s\n",
      "[CV 3/5] END C=1, max_iter=10000, penalty=l2, solver=liblinear;, score=0.743 total time=   0.1s\n",
      "[CV 4/5] END C=1, max_iter=10000, penalty=l2, solver=liblinear;, score=0.743 total time=   0.1s\n",
      "[CV 5/5] END C=1, max_iter=10000, penalty=l2, solver=liblinear;, score=0.745 total time=   0.0s\n",
      "[CV 1/5] END C=10, max_iter=100, penalty=l1, solver=liblinear;, score=0.753 total time=   0.1s\n",
      "[CV 2/5] END C=10, max_iter=100, penalty=l1, solver=liblinear;, score=0.738 total time=   0.1s\n",
      "[CV 3/5] END C=10, max_iter=100, penalty=l1, solver=liblinear;, score=0.743 total time=   0.0s\n",
      "[CV 4/5] END C=10, max_iter=100, penalty=l1, solver=liblinear;, score=0.743 total time=   0.0s\n",
      "[CV 5/5] END C=10, max_iter=100, penalty=l1, solver=liblinear;, score=0.745 total time=   0.1s\n",
      "[CV 1/5] END C=10, max_iter=100, penalty=l2, solver=liblinear;, score=0.753 total time=   0.1s\n",
      "[CV 2/5] END C=10, max_iter=100, penalty=l2, solver=liblinear;, score=0.738 total time=   0.1s\n",
      "[CV 3/5] END C=10, max_iter=100, penalty=l2, solver=liblinear;, score=0.743 total time=   0.1s\n",
      "[CV 4/5] END C=10, max_iter=100, penalty=l2, solver=liblinear;, score=0.743 total time=   0.0s\n",
      "[CV 5/5] END C=10, max_iter=100, penalty=l2, solver=liblinear;, score=0.745 total time=   0.1s\n",
      "[CV 1/5] END C=10, max_iter=1000, penalty=l1, solver=liblinear;, score=0.753 total time=   0.1s\n",
      "[CV 2/5] END C=10, max_iter=1000, penalty=l1, solver=liblinear;, score=0.738 total time=   0.0s\n",
      "[CV 3/5] END C=10, max_iter=1000, penalty=l1, solver=liblinear;, score=0.743 total time=   0.0s\n",
      "[CV 4/5] END C=10, max_iter=1000, penalty=l1, solver=liblinear;, score=0.743 total time=   0.1s\n",
      "[CV 5/5] END C=10, max_iter=1000, penalty=l1, solver=liblinear;, score=0.745 total time=   0.0s\n",
      "[CV 1/5] END C=10, max_iter=1000, penalty=l2, solver=liblinear;, score=0.753 total time=   0.1s\n",
      "[CV 2/5] END C=10, max_iter=1000, penalty=l2, solver=liblinear;, score=0.738 total time=   0.1s\n",
      "[CV 3/5] END C=10, max_iter=1000, penalty=l2, solver=liblinear;, score=0.743 total time=   0.1s\n",
      "[CV 4/5] END C=10, max_iter=1000, penalty=l2, solver=liblinear;, score=0.743 total time=   0.0s\n",
      "[CV 5/5] END C=10, max_iter=1000, penalty=l2, solver=liblinear;, score=0.745 total time=   0.0s\n",
      "[CV 1/5] END C=10, max_iter=10000, penalty=l1, solver=liblinear;, score=0.753 total time=   0.0s\n",
      "[CV 2/5] END C=10, max_iter=10000, penalty=l1, solver=liblinear;, score=0.738 total time=   0.1s\n",
      "[CV 3/5] END C=10, max_iter=10000, penalty=l1, solver=liblinear;, score=0.743 total time=   0.0s\n",
      "[CV 4/5] END C=10, max_iter=10000, penalty=l1, solver=liblinear;, score=0.743 total time=   0.1s\n",
      "[CV 5/5] END C=10, max_iter=10000, penalty=l1, solver=liblinear;, score=0.745 total time=   0.1s\n",
      "[CV 1/5] END C=10, max_iter=10000, penalty=l2, solver=liblinear;, score=0.753 total time=   0.1s\n",
      "[CV 2/5] END C=10, max_iter=10000, penalty=l2, solver=liblinear;, score=0.738 total time=   0.0s\n",
      "[CV 3/5] END C=10, max_iter=10000, penalty=l2, solver=liblinear;, score=0.743 total time=   0.1s\n",
      "[CV 4/5] END C=10, max_iter=10000, penalty=l2, solver=liblinear;, score=0.743 total time=   0.0s\n",
      "[CV 5/5] END C=10, max_iter=10000, penalty=l2, solver=liblinear;, score=0.745 total time=   0.1s\n",
      "[CV 1/5] END C=100, max_iter=100, penalty=l1, solver=liblinear;, score=0.753 total time=   0.1s\n",
      "[CV 2/5] END C=100, max_iter=100, penalty=l1, solver=liblinear;, score=0.738 total time=   0.1s\n",
      "[CV 3/5] END C=100, max_iter=100, penalty=l1, solver=liblinear;, score=0.743 total time=   0.1s\n",
      "[CV 4/5] END C=100, max_iter=100, penalty=l1, solver=liblinear;, score=0.743 total time=   0.1s\n",
      "[CV 5/5] END C=100, max_iter=100, penalty=l1, solver=liblinear;, score=0.745 total time=   0.1s\n",
      "[CV 1/5] END C=100, max_iter=100, penalty=l2, solver=liblinear;, score=0.753 total time=   0.1s\n",
      "[CV 2/5] END C=100, max_iter=100, penalty=l2, solver=liblinear;, score=0.738 total time=   0.0s\n",
      "[CV 3/5] END C=100, max_iter=100, penalty=l2, solver=liblinear;, score=0.743 total time=   0.1s\n",
      "[CV 4/5] END C=100, max_iter=100, penalty=l2, solver=liblinear;, score=0.743 total time=   0.1s\n",
      "[CV 5/5] END C=100, max_iter=100, penalty=l2, solver=liblinear;, score=0.745 total time=   0.1s\n",
      "[CV 1/5] END C=100, max_iter=1000, penalty=l1, solver=liblinear;, score=0.753 total time=   0.0s\n",
      "[CV 2/5] END C=100, max_iter=1000, penalty=l1, solver=liblinear;, score=0.738 total time=   0.0s\n",
      "[CV 3/5] END C=100, max_iter=1000, penalty=l1, solver=liblinear;, score=0.743 total time=   0.1s\n",
      "[CV 4/5] END C=100, max_iter=1000, penalty=l1, solver=liblinear;, score=0.743 total time=   0.1s\n",
      "[CV 5/5] END C=100, max_iter=1000, penalty=l1, solver=liblinear;, score=0.745 total time=   0.1s\n",
      "[CV 1/5] END C=100, max_iter=1000, penalty=l2, solver=liblinear;, score=0.753 total time=   0.1s\n",
      "[CV 2/5] END C=100, max_iter=1000, penalty=l2, solver=liblinear;, score=0.738 total time=   0.1s\n",
      "[CV 3/5] END C=100, max_iter=1000, penalty=l2, solver=liblinear;, score=0.743 total time=   0.1s\n",
      "[CV 4/5] END C=100, max_iter=1000, penalty=l2, solver=liblinear;, score=0.743 total time=   0.1s\n",
      "[CV 5/5] END C=100, max_iter=1000, penalty=l2, solver=liblinear;, score=0.745 total time=   0.1s\n",
      "[CV 1/5] END C=100, max_iter=10000, penalty=l1, solver=liblinear;, score=0.753 total time=   0.1s\n",
      "[CV 2/5] END C=100, max_iter=10000, penalty=l1, solver=liblinear;, score=0.738 total time=   0.0s\n",
      "[CV 3/5] END C=100, max_iter=10000, penalty=l1, solver=liblinear;, score=0.743 total time=   0.0s\n",
      "[CV 4/5] END C=100, max_iter=10000, penalty=l1, solver=liblinear;, score=0.743 total time=   0.1s\n",
      "[CV 5/5] END C=100, max_iter=10000, penalty=l1, solver=liblinear;, score=0.745 total time=   0.1s\n",
      "[CV 1/5] END C=100, max_iter=10000, penalty=l2, solver=liblinear;, score=0.753 total time=   0.1s\n",
      "[CV 2/5] END C=100, max_iter=10000, penalty=l2, solver=liblinear;, score=0.738 total time=   0.0s\n",
      "[CV 3/5] END C=100, max_iter=10000, penalty=l2, solver=liblinear;, score=0.743 total time=   0.0s\n",
      "[CV 4/5] END C=100, max_iter=10000, penalty=l2, solver=liblinear;, score=0.743 total time=   0.0s\n",
      "[CV 5/5] END C=100, max_iter=10000, penalty=l2, solver=liblinear;, score=0.745 total time=   0.0s\n",
      "Accuracy: 0.7522209019408137\n",
      "{'C': 0.1, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.7444312626124867\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create the parameter grid for the GridSearchCV model running logistic regression\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear'], \n",
    "    'max_iter': [100, 1000, 10000]\n",
    "}\n",
    "#C', 'class_weight', 'dual', 'fit_intercept', 'intercept_scaling', 'l1_ratio', 'max_iter', 'multi_class', 'n_jobs', 'penalty', 'random_state', 'solver', 'tol', 'verbose', 'warm_start\n",
    "\n",
    "# Create the GridSearchCV model\n",
    "grid_model = GridSearchCV(LogisticRegression(), param_grid, verbose=3)\n",
    "\n",
    "# Fit the model\n",
    "grid_model.fit(x_train_encoded, y_train)\n",
    "\n",
    "# Make predictions\n",
    "predictions = grid_model.predict(x_test_encoded)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Print the best parameters\n",
    "print(grid_model.best_params_)\n",
    "print(grid_model.best_score_)\n",
    "# print(grid_model.best_estimator_)\n",
    "# print(grid_model.cv_results_)\n",
    "# print(grid_model.best_index_)\n",
    "# print(grid_model.scorer_)\n",
    "# print(grid_model.n_splits_)\n",
    "# print(grid_model.refit_time_)\n",
    "# print(grid_model.error_score)\n",
    "# print(grid_model.param_grid)\n",
    "# print(grid_model.pre_dispatch)\n",
    "# print(grid_model.return_train_score)\n",
    "# print(grid_model.multimetric_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV 1/5] END algorithm=auto, metric=euclidean, n_neighbors=19, weights=uniform;, score=0.740 total time=   1.7s\n",
      "[CV 2/5] END algorithm=auto, metric=euclidean, n_neighbors=19, weights=uniform;, score=0.729 total time=   1.5s\n",
      "[CV 3/5] END algorithm=auto, metric=euclidean, n_neighbors=19, weights=uniform;, score=0.733 total time=   1.5s\n",
      "[CV 4/5] END algorithm=auto, metric=euclidean, n_neighbors=19, weights=uniform;, score=0.729 total time=   1.6s\n",
      "[CV 5/5] END algorithm=auto, metric=euclidean, n_neighbors=19, weights=uniform;, score=0.738 total time=   1.6s\n",
      "[CV 1/5] END algorithm=auto, metric=euclidean, n_neighbors=19, weights=distance;, score=0.723 total time=   1.4s\n",
      "[CV 2/5] END algorithm=auto, metric=euclidean, n_neighbors=19, weights=distance;, score=0.715 total time=   1.9s\n",
      "[CV 3/5] END algorithm=auto, metric=euclidean, n_neighbors=19, weights=distance;, score=0.718 total time=   1.5s\n",
      "[CV 4/5] END algorithm=auto, metric=euclidean, n_neighbors=19, weights=distance;, score=0.711 total time=   1.4s\n",
      "[CV 5/5] END algorithm=auto, metric=euclidean, n_neighbors=19, weights=distance;, score=0.721 total time=   1.4s\n",
      "[CV 1/5] END algorithm=auto, metric=manhattan, n_neighbors=19, weights=uniform;, score=0.742 total time=   1.9s\n",
      "[CV 2/5] END algorithm=auto, metric=manhattan, n_neighbors=19, weights=uniform;, score=0.730 total time=   1.8s\n",
      "[CV 3/5] END algorithm=auto, metric=manhattan, n_neighbors=19, weights=uniform;, score=0.735 total time=   1.8s\n",
      "[CV 4/5] END algorithm=auto, metric=manhattan, n_neighbors=19, weights=uniform;, score=0.732 total time=   1.8s\n",
      "[CV 5/5] END algorithm=auto, metric=manhattan, n_neighbors=19, weights=uniform;, score=0.739 total time=   2.0s\n",
      "[CV 1/5] END algorithm=auto, metric=manhattan, n_neighbors=19, weights=distance;, score=0.725 total time=   2.5s\n",
      "[CV 2/5] END algorithm=auto, metric=manhattan, n_neighbors=19, weights=distance;, score=0.715 total time=   1.8s\n",
      "[CV 3/5] END algorithm=auto, metric=manhattan, n_neighbors=19, weights=distance;, score=0.720 total time=   1.7s\n",
      "[CV 4/5] END algorithm=auto, metric=manhattan, n_neighbors=19, weights=distance;, score=0.714 total time=   1.7s\n",
      "[CV 5/5] END algorithm=auto, metric=manhattan, n_neighbors=19, weights=distance;, score=0.720 total time=   1.8s\n",
      "[CV 1/5] END algorithm=ball_tree, metric=euclidean, n_neighbors=19, weights=uniform;, score=0.740 total time=   2.6s\n",
      "[CV 2/5] END algorithm=ball_tree, metric=euclidean, n_neighbors=19, weights=uniform;, score=0.729 total time=   2.6s\n",
      "[CV 3/5] END algorithm=ball_tree, metric=euclidean, n_neighbors=19, weights=uniform;, score=0.734 total time=   2.8s\n",
      "[CV 4/5] END algorithm=ball_tree, metric=euclidean, n_neighbors=19, weights=uniform;, score=0.729 total time=   2.7s\n",
      "[CV 5/5] END algorithm=ball_tree, metric=euclidean, n_neighbors=19, weights=uniform;, score=0.738 total time=   2.6s\n",
      "[CV 1/5] END algorithm=ball_tree, metric=euclidean, n_neighbors=19, weights=distance;, score=0.722 total time=   2.4s\n",
      "[CV 2/5] END algorithm=ball_tree, metric=euclidean, n_neighbors=19, weights=distance;, score=0.714 total time=   2.5s\n",
      "[CV 3/5] END algorithm=ball_tree, metric=euclidean, n_neighbors=19, weights=distance;, score=0.718 total time=   2.6s\n",
      "[CV 4/5] END algorithm=ball_tree, metric=euclidean, n_neighbors=19, weights=distance;, score=0.711 total time=   2.6s\n",
      "[CV 5/5] END algorithm=ball_tree, metric=euclidean, n_neighbors=19, weights=distance;, score=0.722 total time=   2.6s\n",
      "[CV 1/5] END algorithm=ball_tree, metric=manhattan, n_neighbors=19, weights=uniform;, score=0.742 total time=   2.5s\n",
      "[CV 2/5] END algorithm=ball_tree, metric=manhattan, n_neighbors=19, weights=uniform;, score=0.729 total time=   2.5s\n",
      "[CV 3/5] END algorithm=ball_tree, metric=manhattan, n_neighbors=19, weights=uniform;, score=0.735 total time=   2.6s\n",
      "[CV 4/5] END algorithm=ball_tree, metric=manhattan, n_neighbors=19, weights=uniform;, score=0.731 total time=   2.5s\n",
      "[CV 5/5] END algorithm=ball_tree, metric=manhattan, n_neighbors=19, weights=uniform;, score=0.738 total time=   2.6s\n",
      "[CV 1/5] END algorithm=ball_tree, metric=manhattan, n_neighbors=19, weights=distance;, score=0.725 total time=   2.3s\n",
      "[CV 2/5] END algorithm=ball_tree, metric=manhattan, n_neighbors=19, weights=distance;, score=0.715 total time=   2.3s\n",
      "[CV 3/5] END algorithm=ball_tree, metric=manhattan, n_neighbors=19, weights=distance;, score=0.719 total time=   2.5s\n",
      "[CV 4/5] END algorithm=ball_tree, metric=manhattan, n_neighbors=19, weights=distance;, score=0.714 total time=   2.4s\n",
      "[CV 5/5] END algorithm=ball_tree, metric=manhattan, n_neighbors=19, weights=distance;, score=0.720 total time=   2.3s\n",
      "[CV 1/5] END algorithm=kd_tree, metric=euclidean, n_neighbors=19, weights=uniform;, score=0.740 total time=   1.9s\n",
      "[CV 2/5] END algorithm=kd_tree, metric=euclidean, n_neighbors=19, weights=uniform;, score=0.729 total time=   1.4s\n",
      "[CV 3/5] END algorithm=kd_tree, metric=euclidean, n_neighbors=19, weights=uniform;, score=0.733 total time=   1.4s\n",
      "[CV 4/5] END algorithm=kd_tree, metric=euclidean, n_neighbors=19, weights=uniform;, score=0.729 total time=   1.4s\n",
      "[CV 5/5] END algorithm=kd_tree, metric=euclidean, n_neighbors=19, weights=uniform;, score=0.738 total time=   1.4s\n",
      "[CV 1/5] END algorithm=kd_tree, metric=euclidean, n_neighbors=19, weights=distance;, score=0.723 total time=   1.3s\n",
      "[CV 2/5] END algorithm=kd_tree, metric=euclidean, n_neighbors=19, weights=distance;, score=0.715 total time=   1.4s\n",
      "[CV 3/5] END algorithm=kd_tree, metric=euclidean, n_neighbors=19, weights=distance;, score=0.718 total time=   1.3s\n",
      "[CV 4/5] END algorithm=kd_tree, metric=euclidean, n_neighbors=19, weights=distance;, score=0.711 total time=   1.3s\n",
      "[CV 5/5] END algorithm=kd_tree, metric=euclidean, n_neighbors=19, weights=distance;, score=0.721 total time=   1.3s\n",
      "[CV 1/5] END algorithm=kd_tree, metric=manhattan, n_neighbors=19, weights=uniform;, score=0.742 total time=   1.8s\n",
      "[CV 2/5] END algorithm=kd_tree, metric=manhattan, n_neighbors=19, weights=uniform;, score=0.730 total time=   1.7s\n",
      "[CV 3/5] END algorithm=kd_tree, metric=manhattan, n_neighbors=19, weights=uniform;, score=0.735 total time=   2.1s\n",
      "[CV 4/5] END algorithm=kd_tree, metric=manhattan, n_neighbors=19, weights=uniform;, score=0.732 total time=   1.7s\n",
      "[CV 5/5] END algorithm=kd_tree, metric=manhattan, n_neighbors=19, weights=uniform;, score=0.739 total time=   1.8s\n",
      "[CV 1/5] END algorithm=kd_tree, metric=manhattan, n_neighbors=19, weights=distance;, score=0.725 total time=   1.7s\n",
      "[CV 2/5] END algorithm=kd_tree, metric=manhattan, n_neighbors=19, weights=distance;, score=0.715 total time=   1.8s\n",
      "[CV 3/5] END algorithm=kd_tree, metric=manhattan, n_neighbors=19, weights=distance;, score=0.720 total time=   1.8s\n",
      "[CV 4/5] END algorithm=kd_tree, metric=manhattan, n_neighbors=19, weights=distance;, score=0.714 total time=   1.6s\n",
      "[CV 5/5] END algorithm=kd_tree, metric=manhattan, n_neighbors=19, weights=distance;, score=0.720 total time=   1.6s\n",
      "[CV 1/5] END algorithm=brute, metric=euclidean, n_neighbors=19, weights=uniform;, score=0.742 total time=   0.5s\n",
      "[CV 2/5] END algorithm=brute, metric=euclidean, n_neighbors=19, weights=uniform;, score=0.729 total time=   0.4s\n",
      "[CV 3/5] END algorithm=brute, metric=euclidean, n_neighbors=19, weights=uniform;, score=0.735 total time=   0.3s\n",
      "[CV 4/5] END algorithm=brute, metric=euclidean, n_neighbors=19, weights=uniform;, score=0.730 total time=   0.3s\n",
      "[CV 5/5] END algorithm=brute, metric=euclidean, n_neighbors=19, weights=uniform;, score=0.738 total time=   0.3s\n",
      "[CV 1/5] END algorithm=brute, metric=euclidean, n_neighbors=19, weights=distance;, score=0.723 total time=   0.2s\n",
      "[CV 2/5] END algorithm=brute, metric=euclidean, n_neighbors=19, weights=distance;, score=0.714 total time=   0.2s\n",
      "[CV 3/5] END algorithm=brute, metric=euclidean, n_neighbors=19, weights=distance;, score=0.719 total time=   0.2s\n",
      "[CV 4/5] END algorithm=brute, metric=euclidean, n_neighbors=19, weights=distance;, score=0.712 total time=   0.2s\n",
      "[CV 5/5] END algorithm=brute, metric=euclidean, n_neighbors=19, weights=distance;, score=0.721 total time=   0.2s\n",
      "[CV 1/5] END algorithm=brute, metric=manhattan, n_neighbors=19, weights=uniform;, score=0.742 total time=   0.4s\n",
      "[CV 2/5] END algorithm=brute, metric=manhattan, n_neighbors=19, weights=uniform;, score=0.731 total time=   0.4s\n",
      "[CV 3/5] END algorithm=brute, metric=manhattan, n_neighbors=19, weights=uniform;, score=0.735 total time=   0.4s\n",
      "[CV 4/5] END algorithm=brute, metric=manhattan, n_neighbors=19, weights=uniform;, score=0.733 total time=   0.4s\n",
      "[CV 5/5] END algorithm=brute, metric=manhattan, n_neighbors=19, weights=uniform;, score=0.739 total time=   0.4s\n",
      "[CV 1/5] END algorithm=brute, metric=manhattan, n_neighbors=19, weights=distance;, score=0.725 total time=   0.5s\n",
      "[CV 2/5] END algorithm=brute, metric=manhattan, n_neighbors=19, weights=distance;, score=0.715 total time=   0.6s\n",
      "[CV 3/5] END algorithm=brute, metric=manhattan, n_neighbors=19, weights=distance;, score=0.719 total time=   0.6s\n",
      "[CV 4/5] END algorithm=brute, metric=manhattan, n_neighbors=19, weights=distance;, score=0.713 total time=   0.5s\n",
      "[CV 5/5] END algorithm=brute, metric=manhattan, n_neighbors=19, weights=distance;, score=0.720 total time=   0.5s\n",
      "Accuracy: 0.741752956487297\n",
      "{'algorithm': 'brute', 'metric': 'manhattan', 'n_neighbors': 19, 'weights': 'uniform'}\n",
      "0.7358306046561699\n"
     ]
    }
   ],
   "source": [
    "# Create the parameter grid for the GridSearchCV model running KNeighborsClassifier\n",
    "param_grid = {\n",
    "    'n_neighbors': [19], \n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan'],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "}\n",
    "\n",
    "# Create the GridSearchCV model\n",
    "grid_model = GridSearchCV(KNeighborsClassifier(), param_grid, verbose=3)\n",
    "\n",
    "# Fit the model\n",
    "grid_model.fit(x_train_encoded, y_train)\n",
    "\n",
    "# Make predictions\n",
    "predictions = grid_model.predict(x_test_encoded)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Print the best parameters\n",
    "print(grid_model.best_params_)\n",
    "print(grid_model.best_score_)\n",
    "# print(grid_model.best_estimator_)\n",
    "# print(grid_model.cv_results_)\n",
    "# print(grid_model.best_index_)\n",
    "# print(grid_model.scorer_)\n",
    "# print(grid_model.n_splits_)\n",
    "# print(grid_model.refit_time_)\n",
    "# print(grid_model.error_score)\n",
    "# print(grid_model.param_grid)\n",
    "# print(grid_model.pre_dispatch)\n",
    "# print(grid_model.return_train_score)\n",
    "# print(grid_model.multimetric_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=3, n_estimators=100;, score=0.754 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=3, n_estimators=100;, score=0.743 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=3, n_estimators=100;, score=0.746 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=3, n_estimators=100;, score=0.742 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=3, n_estimators=100;, score=0.748 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=3, n_estimators=500;, score=0.756 total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=3, n_estimators=500;, score=0.743 total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=3, n_estimators=500;, score=0.747 total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=3, n_estimators=500;, score=0.744 total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=3, n_estimators=500;, score=0.749 total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=3, n_estimators=1000;, score=0.756 total time=   0.9s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=3, n_estimators=1000;, score=0.743 total time=   0.9s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=3, n_estimators=1000;, score=0.747 total time=   0.9s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=3, n_estimators=1000;, score=0.744 total time=   0.9s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=3, n_estimators=1000;, score=0.747 total time=   1.0s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=7, n_estimators=100;, score=0.755 total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=7, n_estimators=100;, score=0.743 total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=7, n_estimators=100;, score=0.746 total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=7, n_estimators=100;, score=0.743 total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=7, n_estimators=100;, score=0.751 total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=7, n_estimators=500;, score=0.743 total time=   1.0s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=7, n_estimators=500;, score=0.738 total time=   1.0s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=7, n_estimators=500;, score=0.740 total time=   0.9s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=7, n_estimators=500;, score=0.741 total time=   1.1s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=7, n_estimators=500;, score=0.747 total time=   1.0s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=7, n_estimators=1000;, score=0.740 total time=   2.0s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=7, n_estimators=1000;, score=0.731 total time=   2.0s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=7, n_estimators=1000;, score=0.735 total time=   1.9s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=7, n_estimators=1000;, score=0.734 total time=   3.1s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=7, n_estimators=1000;, score=0.739 total time=   3.5s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=11, n_estimators=100;, score=0.743 total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=11, n_estimators=100;, score=0.738 total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=11, n_estimators=100;, score=0.738 total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=11, n_estimators=100;, score=0.738 total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=11, n_estimators=100;, score=0.742 total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=11, n_estimators=500;, score=0.726 total time=   1.7s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=11, n_estimators=500;, score=0.719 total time=   1.7s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=11, n_estimators=500;, score=0.728 total time=   1.6s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=11, n_estimators=500;, score=0.725 total time=   1.6s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=11, n_estimators=500;, score=0.729 total time=   1.7s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=11, n_estimators=1000;, score=0.717 total time=   3.3s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=11, n_estimators=1000;, score=0.708 total time=   3.6s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=11, n_estimators=1000;, score=0.718 total time=   3.5s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=11, n_estimators=1000;, score=0.712 total time=   3.4s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=11, n_estimators=1000;, score=0.718 total time=   3.3s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=100;, score=0.757 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=100;, score=0.742 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=100;, score=0.746 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=100;, score=0.744 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=100;, score=0.748 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=500;, score=0.756 total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=500;, score=0.742 total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=500;, score=0.748 total time=   0.8s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=500;, score=0.744 total time=   1.5s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=500;, score=0.748 total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=1000;, score=0.754 total time=   0.9s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=1000;, score=0.742 total time=   0.9s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=1000;, score=0.747 total time=   1.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=1000;, score=0.742 total time=   0.9s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=1000;, score=0.746 total time=   1.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=7, n_estimators=100;, score=0.751 total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=7, n_estimators=100;, score=0.741 total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=7, n_estimators=100;, score=0.747 total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=7, n_estimators=100;, score=0.744 total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=7, n_estimators=100;, score=0.749 total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=7, n_estimators=500;, score=0.741 total time=   1.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=7, n_estimators=500;, score=0.732 total time=   1.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=7, n_estimators=500;, score=0.736 total time=   1.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=7, n_estimators=500;, score=0.736 total time=   1.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=7, n_estimators=500;, score=0.738 total time=   1.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=7, n_estimators=1000;, score=0.732 total time=   1.9s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=7, n_estimators=1000;, score=0.724 total time=   2.3s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=7, n_estimators=1000;, score=0.728 total time=   2.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=7, n_estimators=1000;, score=0.725 total time=   2.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=7, n_estimators=1000;, score=0.732 total time=   2.7s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=11, n_estimators=100;, score=0.737 total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=11, n_estimators=100;, score=0.731 total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=11, n_estimators=100;, score=0.735 total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=11, n_estimators=100;, score=0.731 total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=11, n_estimators=100;, score=0.736 total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=11, n_estimators=500;, score=0.713 total time=   1.7s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=11, n_estimators=500;, score=0.705 total time=   1.8s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=11, n_estimators=500;, score=0.716 total time=   2.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=11, n_estimators=500;, score=0.712 total time=   1.8s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=11, n_estimators=500;, score=0.721 total time=   1.9s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=11, n_estimators=1000;, score=0.704 total time=   3.3s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=11, n_estimators=1000;, score=0.699 total time=   3.5s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=11, n_estimators=1000;, score=0.706 total time=   3.3s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create the parameter grid for the GridSearchCV model running Xgboost\n",
    "param_grid = {\n",
    "  #random_state=1, learning_rate=0.05, n_estimators=1000, max_depth=3\n",
    "    'learning_rate': [0.05, 0.1, 0.2],\n",
    "    'n_estimators': [100, 500, 1000],\n",
    "    'max_depth': [3, 7, 11]  \n",
    "}\n",
    "#parameters used above: (random_state=1, learning_rate=0.05, n_estimators=1000, max_depth=3)\n",
    "\n",
    "# Create the GridSearchCV model\n",
    "grid_model = GridSearchCV(XGBClassifier(), param_grid, verbose=3)\n",
    "\n",
    "# Fit the model\n",
    "grid_model.fit(x_train_encoded, y_train)\n",
    "\n",
    "# Make predictions\n",
    "predictions = grid_model.predict(x_test_encoded)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Print the best parameters\n",
    "print(grid_model.best_params_)\n",
    "print(grid_model.best_score_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
