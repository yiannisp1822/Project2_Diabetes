{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, OrdinalEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Needed for decision tree visualization\n",
    "import pydotplus\n",
    "from IPython.display import Image\n",
    "from sklearn import tree\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes_binary</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>...</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Diabetes_binary  HighBP  HighChol  CholCheck   BMI  Smoker  Stroke  \\\n",
       "0              0.0     1.0       0.0        1.0  26.0     0.0     0.0   \n",
       "1              0.0     1.0       1.0        1.0  26.0     1.0     1.0   \n",
       "2              0.0     0.0       0.0        1.0  26.0     0.0     0.0   \n",
       "3              0.0     1.0       1.0        1.0  28.0     1.0     0.0   \n",
       "4              0.0     0.0       0.0        1.0  29.0     1.0     0.0   \n",
       "\n",
       "   HeartDiseaseorAttack  PhysActivity  Fruits  ...  AnyHealthcare  \\\n",
       "0                   0.0           1.0     0.0  ...            1.0   \n",
       "1                   0.0           0.0     1.0  ...            1.0   \n",
       "2                   0.0           1.0     1.0  ...            1.0   \n",
       "3                   0.0           1.0     1.0  ...            1.0   \n",
       "4                   0.0           1.0     1.0  ...            1.0   \n",
       "\n",
       "   NoDocbcCost  GenHlth  MentHlth  PhysHlth  DiffWalk  Sex   Age  Education  \\\n",
       "0          0.0      3.0       5.0      30.0       0.0  1.0   4.0        6.0   \n",
       "1          0.0      3.0       0.0       0.0       0.0  1.0  12.0        6.0   \n",
       "2          0.0      1.0       0.0      10.0       0.0  1.0  13.0        6.0   \n",
       "3          0.0      3.0       0.0       3.0       0.0  1.0  11.0        6.0   \n",
       "4          0.0      2.0       0.0       0.0       0.0  0.0   8.0        5.0   \n",
       "\n",
       "   Income  \n",
       "0     8.0  \n",
       "1     8.0  \n",
       "2     8.0  \n",
       "3     8.0  \n",
       "4     8.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import\n",
    "diabetes = pd.read_csv(\"Resources/diabetes_binary_5050split_health_indicators_BRFSS2015.csv\")\n",
    "\n",
    "# Head\n",
    "diabetes.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Diabetes_binary', 'HighBP', 'HighChol', 'CholCheck', 'BMI', 'Smoker',\n",
       "       'Stroke', 'HeartDiseaseorAttack', 'PhysActivity', 'Fruits', 'Veggies',\n",
       "       'HvyAlcoholConsump', 'AnyHealthcare', 'NoDocbcCost', 'GenHlth',\n",
       "       'MentHlth', 'PhysHlth', 'DiffWalk', 'Sex', 'Age', 'Education',\n",
       "       'Income'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column Descriptions\n",
    "1. Diabetes_binary: 0 = no diabetes 1 = prediabetes or diabetes\n",
    "2. HighBP: 0 = no high BP 1 = high BP\n",
    "3. HighChol: 0 = no high cholesterol 1 = high cholesterol\n",
    "4. CholCheck: 0 = no cholesterol check in 5 years 1 = yes cholesterol check in 5 years\n",
    "5. BMI: Body Mass Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes_binary</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>...</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.563458</td>\n",
       "      <td>0.525703</td>\n",
       "      <td>0.975259</td>\n",
       "      <td>29.856985</td>\n",
       "      <td>0.475273</td>\n",
       "      <td>0.062171</td>\n",
       "      <td>0.147810</td>\n",
       "      <td>0.703036</td>\n",
       "      <td>0.611795</td>\n",
       "      <td>...</td>\n",
       "      <td>0.954960</td>\n",
       "      <td>0.093914</td>\n",
       "      <td>2.837082</td>\n",
       "      <td>3.752037</td>\n",
       "      <td>5.810417</td>\n",
       "      <td>0.252730</td>\n",
       "      <td>0.456997</td>\n",
       "      <td>8.584055</td>\n",
       "      <td>4.920953</td>\n",
       "      <td>5.698311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.500004</td>\n",
       "      <td>0.495960</td>\n",
       "      <td>0.499342</td>\n",
       "      <td>0.155336</td>\n",
       "      <td>7.113954</td>\n",
       "      <td>0.499392</td>\n",
       "      <td>0.241468</td>\n",
       "      <td>0.354914</td>\n",
       "      <td>0.456924</td>\n",
       "      <td>0.487345</td>\n",
       "      <td>...</td>\n",
       "      <td>0.207394</td>\n",
       "      <td>0.291712</td>\n",
       "      <td>1.113565</td>\n",
       "      <td>8.155627</td>\n",
       "      <td>10.062261</td>\n",
       "      <td>0.434581</td>\n",
       "      <td>0.498151</td>\n",
       "      <td>2.852153</td>\n",
       "      <td>1.029081</td>\n",
       "      <td>2.175196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Diabetes_binary        HighBP      HighChol     CholCheck  \\\n",
       "count     70692.000000  70692.000000  70692.000000  70692.000000   \n",
       "mean          0.500000      0.563458      0.525703      0.975259   \n",
       "std           0.500004      0.495960      0.499342      0.155336   \n",
       "min           0.000000      0.000000      0.000000      0.000000   \n",
       "25%           0.000000      0.000000      0.000000      1.000000   \n",
       "50%           0.500000      1.000000      1.000000      1.000000   \n",
       "75%           1.000000      1.000000      1.000000      1.000000   \n",
       "max           1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "                BMI        Smoker        Stroke  HeartDiseaseorAttack  \\\n",
       "count  70692.000000  70692.000000  70692.000000          70692.000000   \n",
       "mean      29.856985      0.475273      0.062171              0.147810   \n",
       "std        7.113954      0.499392      0.241468              0.354914   \n",
       "min       12.000000      0.000000      0.000000              0.000000   \n",
       "25%       25.000000      0.000000      0.000000              0.000000   \n",
       "50%       29.000000      0.000000      0.000000              0.000000   \n",
       "75%       33.000000      1.000000      0.000000              0.000000   \n",
       "max       98.000000      1.000000      1.000000              1.000000   \n",
       "\n",
       "       PhysActivity        Fruits  ...  AnyHealthcare   NoDocbcCost  \\\n",
       "count  70692.000000  70692.000000  ...   70692.000000  70692.000000   \n",
       "mean       0.703036      0.611795  ...       0.954960      0.093914   \n",
       "std        0.456924      0.487345  ...       0.207394      0.291712   \n",
       "min        0.000000      0.000000  ...       0.000000      0.000000   \n",
       "25%        0.000000      0.000000  ...       1.000000      0.000000   \n",
       "50%        1.000000      1.000000  ...       1.000000      0.000000   \n",
       "75%        1.000000      1.000000  ...       1.000000      0.000000   \n",
       "max        1.000000      1.000000  ...       1.000000      1.000000   \n",
       "\n",
       "            GenHlth      MentHlth      PhysHlth      DiffWalk           Sex  \\\n",
       "count  70692.000000  70692.000000  70692.000000  70692.000000  70692.000000   \n",
       "mean       2.837082      3.752037      5.810417      0.252730      0.456997   \n",
       "std        1.113565      8.155627     10.062261      0.434581      0.498151   \n",
       "min        1.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        2.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        3.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        4.000000      2.000000      6.000000      1.000000      1.000000   \n",
       "max        5.000000     30.000000     30.000000      1.000000      1.000000   \n",
       "\n",
       "                Age     Education        Income  \n",
       "count  70692.000000  70692.000000  70692.000000  \n",
       "mean       8.584055      4.920953      5.698311  \n",
       "std        2.852153      1.029081      2.175196  \n",
       "min        1.000000      1.000000      1.000000  \n",
       "25%        7.000000      4.000000      4.000000  \n",
       "50%        9.000000      5.000000      6.000000  \n",
       "75%       11.000000      6.000000      8.000000  \n",
       "max       13.000000      6.000000      8.000000  \n",
       "\n",
       "[8 rows x 22 columns]"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Describing the dataset\n",
    "diabetes.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 70692 entries, 0 to 70691\n",
      "Data columns (total 22 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   Diabetes_binary       70692 non-null  float64\n",
      " 1   HighBP                70692 non-null  float64\n",
      " 2   HighChol              70692 non-null  float64\n",
      " 3   CholCheck             70692 non-null  float64\n",
      " 4   BMI                   70692 non-null  float64\n",
      " 5   Smoker                70692 non-null  float64\n",
      " 6   Stroke                70692 non-null  float64\n",
      " 7   HeartDiseaseorAttack  70692 non-null  float64\n",
      " 8   PhysActivity          70692 non-null  float64\n",
      " 9   Fruits                70692 non-null  float64\n",
      " 10  Veggies               70692 non-null  float64\n",
      " 11  HvyAlcoholConsump     70692 non-null  float64\n",
      " 12  AnyHealthcare         70692 non-null  float64\n",
      " 13  NoDocbcCost           70692 non-null  float64\n",
      " 14  GenHlth               70692 non-null  float64\n",
      " 15  MentHlth              70692 non-null  float64\n",
      " 16  PhysHlth              70692 non-null  float64\n",
      " 17  DiffWalk              70692 non-null  float64\n",
      " 18  Sex                   70692 non-null  float64\n",
      " 19  Age                   70692 non-null  float64\n",
      " 20  Education             70692 non-null  float64\n",
      " 21  Income                70692 non-null  float64\n",
      "dtypes: float64(22)\n",
      "memory usage: 11.9 MB\n"
     ]
    }
   ],
   "source": [
    "# info about the dataset\n",
    "diabetes.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes_binary</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>...</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Diabetes_binary</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.381516</td>\n",
       "      <td>0.289213</td>\n",
       "      <td>0.115382</td>\n",
       "      <td>0.293373</td>\n",
       "      <td>0.085999</td>\n",
       "      <td>0.125427</td>\n",
       "      <td>0.211523</td>\n",
       "      <td>-0.158666</td>\n",
       "      <td>-0.054077</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023191</td>\n",
       "      <td>0.040977</td>\n",
       "      <td>0.407612</td>\n",
       "      <td>0.087029</td>\n",
       "      <td>0.213081</td>\n",
       "      <td>0.272646</td>\n",
       "      <td>0.044413</td>\n",
       "      <td>0.278738</td>\n",
       "      <td>-0.170481</td>\n",
       "      <td>-0.224449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HighBP</th>\n",
       "      <td>0.381516</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.316515</td>\n",
       "      <td>0.103283</td>\n",
       "      <td>0.241019</td>\n",
       "      <td>0.087438</td>\n",
       "      <td>0.129060</td>\n",
       "      <td>0.210750</td>\n",
       "      <td>-0.136102</td>\n",
       "      <td>-0.040852</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035764</td>\n",
       "      <td>0.026517</td>\n",
       "      <td>0.320540</td>\n",
       "      <td>0.064294</td>\n",
       "      <td>0.173922</td>\n",
       "      <td>0.234784</td>\n",
       "      <td>0.040819</td>\n",
       "      <td>0.338132</td>\n",
       "      <td>-0.141643</td>\n",
       "      <td>-0.187657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HighChol</th>\n",
       "      <td>0.289213</td>\n",
       "      <td>0.316515</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.085981</td>\n",
       "      <td>0.131309</td>\n",
       "      <td>0.093398</td>\n",
       "      <td>0.099786</td>\n",
       "      <td>0.181187</td>\n",
       "      <td>-0.090453</td>\n",
       "      <td>-0.047384</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031532</td>\n",
       "      <td>0.033199</td>\n",
       "      <td>0.237778</td>\n",
       "      <td>0.083881</td>\n",
       "      <td>0.142610</td>\n",
       "      <td>0.162043</td>\n",
       "      <td>0.017324</td>\n",
       "      <td>0.240338</td>\n",
       "      <td>-0.084386</td>\n",
       "      <td>-0.107777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CholCheck</th>\n",
       "      <td>0.115382</td>\n",
       "      <td>0.103283</td>\n",
       "      <td>0.085981</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.045648</td>\n",
       "      <td>-0.004331</td>\n",
       "      <td>0.022529</td>\n",
       "      <td>0.043497</td>\n",
       "      <td>-0.008249</td>\n",
       "      <td>0.017384</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106800</td>\n",
       "      <td>-0.062669</td>\n",
       "      <td>0.059213</td>\n",
       "      <td>-0.010660</td>\n",
       "      <td>0.034540</td>\n",
       "      <td>0.044430</td>\n",
       "      <td>-0.007991</td>\n",
       "      <td>0.101743</td>\n",
       "      <td>-0.008695</td>\n",
       "      <td>0.007550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMI</th>\n",
       "      <td>0.293373</td>\n",
       "      <td>0.241019</td>\n",
       "      <td>0.131309</td>\n",
       "      <td>0.045648</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.011551</td>\n",
       "      <td>0.022931</td>\n",
       "      <td>0.060355</td>\n",
       "      <td>-0.170936</td>\n",
       "      <td>-0.084505</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013417</td>\n",
       "      <td>0.065832</td>\n",
       "      <td>0.267888</td>\n",
       "      <td>0.104682</td>\n",
       "      <td>0.161862</td>\n",
       "      <td>0.246094</td>\n",
       "      <td>0.000827</td>\n",
       "      <td>-0.038648</td>\n",
       "      <td>-0.100233</td>\n",
       "      <td>-0.124878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Smoker</th>\n",
       "      <td>0.085999</td>\n",
       "      <td>0.087438</td>\n",
       "      <td>0.093398</td>\n",
       "      <td>-0.004331</td>\n",
       "      <td>0.011551</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.064658</td>\n",
       "      <td>0.124418</td>\n",
       "      <td>-0.079823</td>\n",
       "      <td>-0.074811</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012939</td>\n",
       "      <td>0.035799</td>\n",
       "      <td>0.152416</td>\n",
       "      <td>0.091257</td>\n",
       "      <td>0.120698</td>\n",
       "      <td>0.119789</td>\n",
       "      <td>0.112125</td>\n",
       "      <td>0.105424</td>\n",
       "      <td>-0.140966</td>\n",
       "      <td>-0.104725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stroke</th>\n",
       "      <td>0.125427</td>\n",
       "      <td>0.129060</td>\n",
       "      <td>0.099786</td>\n",
       "      <td>0.022529</td>\n",
       "      <td>0.022931</td>\n",
       "      <td>0.064658</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.223394</td>\n",
       "      <td>-0.079985</td>\n",
       "      <td>-0.008996</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006484</td>\n",
       "      <td>0.036198</td>\n",
       "      <td>0.189447</td>\n",
       "      <td>0.087303</td>\n",
       "      <td>0.164488</td>\n",
       "      <td>0.192266</td>\n",
       "      <td>0.003822</td>\n",
       "      <td>0.123879</td>\n",
       "      <td>-0.073926</td>\n",
       "      <td>-0.136577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <td>0.211523</td>\n",
       "      <td>0.210750</td>\n",
       "      <td>0.181187</td>\n",
       "      <td>0.043497</td>\n",
       "      <td>0.060355</td>\n",
       "      <td>0.124418</td>\n",
       "      <td>0.223394</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.098223</td>\n",
       "      <td>-0.019436</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015687</td>\n",
       "      <td>0.036029</td>\n",
       "      <td>0.275868</td>\n",
       "      <td>0.075057</td>\n",
       "      <td>0.198416</td>\n",
       "      <td>0.232611</td>\n",
       "      <td>0.098161</td>\n",
       "      <td>0.221878</td>\n",
       "      <td>-0.096559</td>\n",
       "      <td>-0.146748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhysActivity</th>\n",
       "      <td>-0.158666</td>\n",
       "      <td>-0.136102</td>\n",
       "      <td>-0.090453</td>\n",
       "      <td>-0.008249</td>\n",
       "      <td>-0.170936</td>\n",
       "      <td>-0.079823</td>\n",
       "      <td>-0.079985</td>\n",
       "      <td>-0.098223</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.133813</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027089</td>\n",
       "      <td>-0.063302</td>\n",
       "      <td>-0.273548</td>\n",
       "      <td>-0.130090</td>\n",
       "      <td>-0.234500</td>\n",
       "      <td>-0.276868</td>\n",
       "      <td>0.051753</td>\n",
       "      <td>-0.100753</td>\n",
       "      <td>0.190271</td>\n",
       "      <td>0.196551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fruits</th>\n",
       "      <td>-0.054077</td>\n",
       "      <td>-0.040852</td>\n",
       "      <td>-0.047384</td>\n",
       "      <td>0.017384</td>\n",
       "      <td>-0.084505</td>\n",
       "      <td>-0.074811</td>\n",
       "      <td>-0.008996</td>\n",
       "      <td>-0.019436</td>\n",
       "      <td>0.133813</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029385</td>\n",
       "      <td>-0.045843</td>\n",
       "      <td>-0.098687</td>\n",
       "      <td>-0.062102</td>\n",
       "      <td>-0.048572</td>\n",
       "      <td>-0.050784</td>\n",
       "      <td>-0.088723</td>\n",
       "      <td>0.061096</td>\n",
       "      <td>0.098715</td>\n",
       "      <td>0.079009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Veggies</th>\n",
       "      <td>-0.079293</td>\n",
       "      <td>-0.066624</td>\n",
       "      <td>-0.042836</td>\n",
       "      <td>0.000349</td>\n",
       "      <td>-0.056528</td>\n",
       "      <td>-0.029926</td>\n",
       "      <td>-0.047601</td>\n",
       "      <td>-0.036315</td>\n",
       "      <td>0.149322</td>\n",
       "      <td>0.238605</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029152</td>\n",
       "      <td>-0.037146</td>\n",
       "      <td>-0.115795</td>\n",
       "      <td>-0.052359</td>\n",
       "      <td>-0.066896</td>\n",
       "      <td>-0.084072</td>\n",
       "      <td>-0.052604</td>\n",
       "      <td>-0.018893</td>\n",
       "      <td>0.152512</td>\n",
       "      <td>0.154899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HvyAlcoholConsump</th>\n",
       "      <td>-0.094853</td>\n",
       "      <td>-0.027030</td>\n",
       "      <td>-0.025443</td>\n",
       "      <td>-0.027146</td>\n",
       "      <td>-0.058232</td>\n",
       "      <td>0.077835</td>\n",
       "      <td>-0.023395</td>\n",
       "      <td>-0.037130</td>\n",
       "      <td>0.019111</td>\n",
       "      <td>-0.033246</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013484</td>\n",
       "      <td>0.009683</td>\n",
       "      <td>-0.058796</td>\n",
       "      <td>0.015626</td>\n",
       "      <td>-0.036257</td>\n",
       "      <td>-0.049294</td>\n",
       "      <td>0.014164</td>\n",
       "      <td>-0.057705</td>\n",
       "      <td>0.036279</td>\n",
       "      <td>0.064095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <td>0.023191</td>\n",
       "      <td>0.035764</td>\n",
       "      <td>0.031532</td>\n",
       "      <td>0.106800</td>\n",
       "      <td>-0.013417</td>\n",
       "      <td>-0.012939</td>\n",
       "      <td>0.006484</td>\n",
       "      <td>0.015687</td>\n",
       "      <td>0.027089</td>\n",
       "      <td>0.029385</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.221658</td>\n",
       "      <td>-0.033060</td>\n",
       "      <td>-0.049850</td>\n",
       "      <td>-0.003285</td>\n",
       "      <td>0.008113</td>\n",
       "      <td>-0.006562</td>\n",
       "      <td>0.136975</td>\n",
       "      <td>0.106601</td>\n",
       "      <td>0.130492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <td>0.040977</td>\n",
       "      <td>0.026517</td>\n",
       "      <td>0.033199</td>\n",
       "      <td>-0.062669</td>\n",
       "      <td>0.065832</td>\n",
       "      <td>0.035799</td>\n",
       "      <td>0.036198</td>\n",
       "      <td>0.036029</td>\n",
       "      <td>-0.063302</td>\n",
       "      <td>-0.045843</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.221658</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.169515</td>\n",
       "      <td>0.193877</td>\n",
       "      <td>0.157451</td>\n",
       "      <td>0.127111</td>\n",
       "      <td>-0.048187</td>\n",
       "      <td>-0.129839</td>\n",
       "      <td>-0.096989</td>\n",
       "      <td>-0.198171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GenHlth</th>\n",
       "      <td>0.407612</td>\n",
       "      <td>0.320540</td>\n",
       "      <td>0.237778</td>\n",
       "      <td>0.059213</td>\n",
       "      <td>0.267888</td>\n",
       "      <td>0.152416</td>\n",
       "      <td>0.189447</td>\n",
       "      <td>0.275868</td>\n",
       "      <td>-0.273548</td>\n",
       "      <td>-0.098687</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033060</td>\n",
       "      <td>0.169515</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.315077</td>\n",
       "      <td>0.552757</td>\n",
       "      <td>0.476639</td>\n",
       "      <td>-0.014555</td>\n",
       "      <td>0.155624</td>\n",
       "      <td>-0.285420</td>\n",
       "      <td>-0.382969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MentHlth</th>\n",
       "      <td>0.087029</td>\n",
       "      <td>0.064294</td>\n",
       "      <td>0.083881</td>\n",
       "      <td>-0.010660</td>\n",
       "      <td>0.104682</td>\n",
       "      <td>0.091257</td>\n",
       "      <td>0.087303</td>\n",
       "      <td>0.075057</td>\n",
       "      <td>-0.130090</td>\n",
       "      <td>-0.062102</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.049850</td>\n",
       "      <td>0.193877</td>\n",
       "      <td>0.315077</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.380272</td>\n",
       "      <td>0.251489</td>\n",
       "      <td>-0.089204</td>\n",
       "      <td>-0.101746</td>\n",
       "      <td>-0.107005</td>\n",
       "      <td>-0.219070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhysHlth</th>\n",
       "      <td>0.213081</td>\n",
       "      <td>0.173922</td>\n",
       "      <td>0.142610</td>\n",
       "      <td>0.034540</td>\n",
       "      <td>0.161862</td>\n",
       "      <td>0.120698</td>\n",
       "      <td>0.164488</td>\n",
       "      <td>0.198416</td>\n",
       "      <td>-0.234500</td>\n",
       "      <td>-0.048572</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003285</td>\n",
       "      <td>0.157451</td>\n",
       "      <td>0.552757</td>\n",
       "      <td>0.380272</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.487976</td>\n",
       "      <td>-0.045957</td>\n",
       "      <td>0.084852</td>\n",
       "      <td>-0.159317</td>\n",
       "      <td>-0.279326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DiffWalk</th>\n",
       "      <td>0.272646</td>\n",
       "      <td>0.234784</td>\n",
       "      <td>0.162043</td>\n",
       "      <td>0.044430</td>\n",
       "      <td>0.246094</td>\n",
       "      <td>0.119789</td>\n",
       "      <td>0.192266</td>\n",
       "      <td>0.232611</td>\n",
       "      <td>-0.276868</td>\n",
       "      <td>-0.050784</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008113</td>\n",
       "      <td>0.127111</td>\n",
       "      <td>0.476639</td>\n",
       "      <td>0.251489</td>\n",
       "      <td>0.487976</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.082248</td>\n",
       "      <td>0.195265</td>\n",
       "      <td>-0.202590</td>\n",
       "      <td>-0.343245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>0.044413</td>\n",
       "      <td>0.040819</td>\n",
       "      <td>0.017324</td>\n",
       "      <td>-0.007991</td>\n",
       "      <td>0.000827</td>\n",
       "      <td>0.112125</td>\n",
       "      <td>0.003822</td>\n",
       "      <td>0.098161</td>\n",
       "      <td>0.051753</td>\n",
       "      <td>-0.088723</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006562</td>\n",
       "      <td>-0.048187</td>\n",
       "      <td>-0.014555</td>\n",
       "      <td>-0.089204</td>\n",
       "      <td>-0.045957</td>\n",
       "      <td>-0.082248</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.002315</td>\n",
       "      <td>0.043564</td>\n",
       "      <td>0.159654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0.278738</td>\n",
       "      <td>0.338132</td>\n",
       "      <td>0.240338</td>\n",
       "      <td>0.101743</td>\n",
       "      <td>-0.038648</td>\n",
       "      <td>0.105424</td>\n",
       "      <td>0.123879</td>\n",
       "      <td>0.221878</td>\n",
       "      <td>-0.100753</td>\n",
       "      <td>0.061096</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136975</td>\n",
       "      <td>-0.129839</td>\n",
       "      <td>0.155624</td>\n",
       "      <td>-0.101746</td>\n",
       "      <td>0.084852</td>\n",
       "      <td>0.195265</td>\n",
       "      <td>-0.002315</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.107127</td>\n",
       "      <td>-0.130140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Education</th>\n",
       "      <td>-0.170481</td>\n",
       "      <td>-0.141643</td>\n",
       "      <td>-0.084386</td>\n",
       "      <td>-0.008695</td>\n",
       "      <td>-0.100233</td>\n",
       "      <td>-0.140966</td>\n",
       "      <td>-0.073926</td>\n",
       "      <td>-0.096559</td>\n",
       "      <td>0.190271</td>\n",
       "      <td>0.098715</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106601</td>\n",
       "      <td>-0.096989</td>\n",
       "      <td>-0.285420</td>\n",
       "      <td>-0.107005</td>\n",
       "      <td>-0.159317</td>\n",
       "      <td>-0.202590</td>\n",
       "      <td>0.043564</td>\n",
       "      <td>-0.107127</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.460565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Income</th>\n",
       "      <td>-0.224449</td>\n",
       "      <td>-0.187657</td>\n",
       "      <td>-0.107777</td>\n",
       "      <td>0.007550</td>\n",
       "      <td>-0.124878</td>\n",
       "      <td>-0.104725</td>\n",
       "      <td>-0.136577</td>\n",
       "      <td>-0.146748</td>\n",
       "      <td>0.196551</td>\n",
       "      <td>0.079009</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130492</td>\n",
       "      <td>-0.198171</td>\n",
       "      <td>-0.382969</td>\n",
       "      <td>-0.219070</td>\n",
       "      <td>-0.279326</td>\n",
       "      <td>-0.343245</td>\n",
       "      <td>0.159654</td>\n",
       "      <td>-0.130140</td>\n",
       "      <td>0.460565</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Diabetes_binary    HighBP  HighChol  CholCheck  \\\n",
       "Diabetes_binary              1.000000  0.381516  0.289213   0.115382   \n",
       "HighBP                       0.381516  1.000000  0.316515   0.103283   \n",
       "HighChol                     0.289213  0.316515  1.000000   0.085981   \n",
       "CholCheck                    0.115382  0.103283  0.085981   1.000000   \n",
       "BMI                          0.293373  0.241019  0.131309   0.045648   \n",
       "Smoker                       0.085999  0.087438  0.093398  -0.004331   \n",
       "Stroke                       0.125427  0.129060  0.099786   0.022529   \n",
       "HeartDiseaseorAttack         0.211523  0.210750  0.181187   0.043497   \n",
       "PhysActivity                -0.158666 -0.136102 -0.090453  -0.008249   \n",
       "Fruits                      -0.054077 -0.040852 -0.047384   0.017384   \n",
       "Veggies                     -0.079293 -0.066624 -0.042836   0.000349   \n",
       "HvyAlcoholConsump           -0.094853 -0.027030 -0.025443  -0.027146   \n",
       "AnyHealthcare                0.023191  0.035764  0.031532   0.106800   \n",
       "NoDocbcCost                  0.040977  0.026517  0.033199  -0.062669   \n",
       "GenHlth                      0.407612  0.320540  0.237778   0.059213   \n",
       "MentHlth                     0.087029  0.064294  0.083881  -0.010660   \n",
       "PhysHlth                     0.213081  0.173922  0.142610   0.034540   \n",
       "DiffWalk                     0.272646  0.234784  0.162043   0.044430   \n",
       "Sex                          0.044413  0.040819  0.017324  -0.007991   \n",
       "Age                          0.278738  0.338132  0.240338   0.101743   \n",
       "Education                   -0.170481 -0.141643 -0.084386  -0.008695   \n",
       "Income                      -0.224449 -0.187657 -0.107777   0.007550   \n",
       "\n",
       "                           BMI    Smoker    Stroke  HeartDiseaseorAttack  \\\n",
       "Diabetes_binary       0.293373  0.085999  0.125427              0.211523   \n",
       "HighBP                0.241019  0.087438  0.129060              0.210750   \n",
       "HighChol              0.131309  0.093398  0.099786              0.181187   \n",
       "CholCheck             0.045648 -0.004331  0.022529              0.043497   \n",
       "BMI                   1.000000  0.011551  0.022931              0.060355   \n",
       "Smoker                0.011551  1.000000  0.064658              0.124418   \n",
       "Stroke                0.022931  0.064658  1.000000              0.223394   \n",
       "HeartDiseaseorAttack  0.060355  0.124418  0.223394              1.000000   \n",
       "PhysActivity         -0.170936 -0.079823 -0.079985             -0.098223   \n",
       "Fruits               -0.084505 -0.074811 -0.008996             -0.019436   \n",
       "Veggies              -0.056528 -0.029926 -0.047601             -0.036315   \n",
       "HvyAlcoholConsump    -0.058232  0.077835 -0.023395             -0.037130   \n",
       "AnyHealthcare        -0.013417 -0.012939  0.006484              0.015687   \n",
       "NoDocbcCost           0.065832  0.035799  0.036198              0.036029   \n",
       "GenHlth               0.267888  0.152416  0.189447              0.275868   \n",
       "MentHlth              0.104682  0.091257  0.087303              0.075057   \n",
       "PhysHlth              0.161862  0.120698  0.164488              0.198416   \n",
       "DiffWalk              0.246094  0.119789  0.192266              0.232611   \n",
       "Sex                   0.000827  0.112125  0.003822              0.098161   \n",
       "Age                  -0.038648  0.105424  0.123879              0.221878   \n",
       "Education            -0.100233 -0.140966 -0.073926             -0.096559   \n",
       "Income               -0.124878 -0.104725 -0.136577             -0.146748   \n",
       "\n",
       "                      PhysActivity    Fruits  ...  AnyHealthcare  NoDocbcCost  \\\n",
       "Diabetes_binary          -0.158666 -0.054077  ...       0.023191     0.040977   \n",
       "HighBP                   -0.136102 -0.040852  ...       0.035764     0.026517   \n",
       "HighChol                 -0.090453 -0.047384  ...       0.031532     0.033199   \n",
       "CholCheck                -0.008249  0.017384  ...       0.106800    -0.062669   \n",
       "BMI                      -0.170936 -0.084505  ...      -0.013417     0.065832   \n",
       "Smoker                   -0.079823 -0.074811  ...      -0.012939     0.035799   \n",
       "Stroke                   -0.079985 -0.008996  ...       0.006484     0.036198   \n",
       "HeartDiseaseorAttack     -0.098223 -0.019436  ...       0.015687     0.036029   \n",
       "PhysActivity              1.000000  0.133813  ...       0.027089    -0.063302   \n",
       "Fruits                    0.133813  1.000000  ...       0.029385    -0.045843   \n",
       "Veggies                   0.149322  0.238605  ...       0.029152    -0.037146   \n",
       "HvyAlcoholConsump         0.019111 -0.033246  ...      -0.013484     0.009683   \n",
       "AnyHealthcare             0.027089  0.029385  ...       1.000000    -0.221658   \n",
       "NoDocbcCost              -0.063302 -0.045843  ...      -0.221658     1.000000   \n",
       "GenHlth                  -0.273548 -0.098687  ...      -0.033060     0.169515   \n",
       "MentHlth                 -0.130090 -0.062102  ...      -0.049850     0.193877   \n",
       "PhysHlth                 -0.234500 -0.048572  ...      -0.003285     0.157451   \n",
       "DiffWalk                 -0.276868 -0.050784  ...       0.008113     0.127111   \n",
       "Sex                       0.051753 -0.088723  ...      -0.006562    -0.048187   \n",
       "Age                      -0.100753  0.061096  ...       0.136975    -0.129839   \n",
       "Education                 0.190271  0.098715  ...       0.106601    -0.096989   \n",
       "Income                    0.196551  0.079009  ...       0.130492    -0.198171   \n",
       "\n",
       "                       GenHlth  MentHlth  PhysHlth  DiffWalk       Sex  \\\n",
       "Diabetes_binary       0.407612  0.087029  0.213081  0.272646  0.044413   \n",
       "HighBP                0.320540  0.064294  0.173922  0.234784  0.040819   \n",
       "HighChol              0.237778  0.083881  0.142610  0.162043  0.017324   \n",
       "CholCheck             0.059213 -0.010660  0.034540  0.044430 -0.007991   \n",
       "BMI                   0.267888  0.104682  0.161862  0.246094  0.000827   \n",
       "Smoker                0.152416  0.091257  0.120698  0.119789  0.112125   \n",
       "Stroke                0.189447  0.087303  0.164488  0.192266  0.003822   \n",
       "HeartDiseaseorAttack  0.275868  0.075057  0.198416  0.232611  0.098161   \n",
       "PhysActivity         -0.273548 -0.130090 -0.234500 -0.276868  0.051753   \n",
       "Fruits               -0.098687 -0.062102 -0.048572 -0.050784 -0.088723   \n",
       "Veggies              -0.115795 -0.052359 -0.066896 -0.084072 -0.052604   \n",
       "HvyAlcoholConsump    -0.058796  0.015626 -0.036257 -0.049294  0.014164   \n",
       "AnyHealthcare        -0.033060 -0.049850 -0.003285  0.008113 -0.006562   \n",
       "NoDocbcCost           0.169515  0.193877  0.157451  0.127111 -0.048187   \n",
       "GenHlth               1.000000  0.315077  0.552757  0.476639 -0.014555   \n",
       "MentHlth              0.315077  1.000000  0.380272  0.251489 -0.089204   \n",
       "PhysHlth              0.552757  0.380272  1.000000  0.487976 -0.045957   \n",
       "DiffWalk              0.476639  0.251489  0.487976  1.000000 -0.082248   \n",
       "Sex                  -0.014555 -0.089204 -0.045957 -0.082248  1.000000   \n",
       "Age                   0.155624 -0.101746  0.084852  0.195265 -0.002315   \n",
       "Education            -0.285420 -0.107005 -0.159317 -0.202590  0.043564   \n",
       "Income               -0.382969 -0.219070 -0.279326 -0.343245  0.159654   \n",
       "\n",
       "                           Age  Education    Income  \n",
       "Diabetes_binary       0.278738  -0.170481 -0.224449  \n",
       "HighBP                0.338132  -0.141643 -0.187657  \n",
       "HighChol              0.240338  -0.084386 -0.107777  \n",
       "CholCheck             0.101743  -0.008695  0.007550  \n",
       "BMI                  -0.038648  -0.100233 -0.124878  \n",
       "Smoker                0.105424  -0.140966 -0.104725  \n",
       "Stroke                0.123879  -0.073926 -0.136577  \n",
       "HeartDiseaseorAttack  0.221878  -0.096559 -0.146748  \n",
       "PhysActivity         -0.100753   0.190271  0.196551  \n",
       "Fruits                0.061096   0.098715  0.079009  \n",
       "Veggies              -0.018893   0.152512  0.154899  \n",
       "HvyAlcoholConsump    -0.057705   0.036279  0.064095  \n",
       "AnyHealthcare         0.136975   0.106601  0.130492  \n",
       "NoDocbcCost          -0.129839  -0.096989 -0.198171  \n",
       "GenHlth               0.155624  -0.285420 -0.382969  \n",
       "MentHlth             -0.101746  -0.107005 -0.219070  \n",
       "PhysHlth              0.084852  -0.159317 -0.279326  \n",
       "DiffWalk              0.195265  -0.202590 -0.343245  \n",
       "Sex                  -0.002315   0.043564  0.159654  \n",
       "Age                   1.000000  -0.107127 -0.130140  \n",
       "Education            -0.107127   1.000000  0.460565  \n",
       "Income               -0.130140   0.460565  1.000000  \n",
       "\n",
       "[22 rows x 22 columns]"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes_binary</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Diabetes_binary  HighBP  HighChol  CholCheck   BMI  Stroke  \\\n",
       "0              0.0     1.0       0.0        1.0  26.0     0.0   \n",
       "1              0.0     1.0       1.0        1.0  26.0     1.0   \n",
       "2              0.0     0.0       0.0        1.0  26.0     0.0   \n",
       "3              0.0     1.0       1.0        1.0  28.0     0.0   \n",
       "4              0.0     0.0       0.0        1.0  29.0     0.0   \n",
       "\n",
       "   HeartDiseaseorAttack  PhysActivity  GenHlth  PhysHlth  DiffWalk   Age  \\\n",
       "0                   0.0           1.0      3.0      30.0       0.0   4.0   \n",
       "1                   0.0           0.0      3.0       0.0       0.0  12.0   \n",
       "2                   0.0           1.0      1.0      10.0       0.0  13.0   \n",
       "3                   0.0           1.0      3.0       3.0       0.0  11.0   \n",
       "4                   0.0           1.0      2.0       0.0       0.0   8.0   \n",
       "\n",
       "   Education  Income  \n",
       "0        6.0     8.0  \n",
       "1        6.0     8.0  \n",
       "2        6.0     8.0  \n",
       "3        6.0     8.0  \n",
       "4        5.0     8.0  "
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dropping columns that may not be helpful for analysis, heavy alcohol consumption removed since because it is self reported it may not be as honest\n",
    "columns_to_drop = ['Fruits', 'Veggies', 'MentHlth', 'NoDocbcCost', 'Sex', 'AnyHealthcare', 'HvyAlcoholConsump', 'Smoker']\n",
    "diabetes_df = diabetes.copy()\n",
    "diabetes_df = diabetes_df.drop(columns=columns_to_drop)\n",
    "diabetes_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Grouping (using functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age\n",
    "1. Age 18 to 24\n",
    "2. Age 25 to 29\n",
    "3. Age 30 to 34\n",
    "4. Age 35 to 39\n",
    "5. Age 40 to 44\n",
    "6. Age 45 to 49\n",
    "7. Age 50 to 54\n",
    "8. Age 55 to 59\n",
    "9. Age 60 to 64\n",
    "10. Age 65 to 69\n",
    "11. Age 70 to 74\n",
    "12. Age 75 to 79\n",
    "13. Age 80 or older\n",
    "\n",
    "#### split every three groups\n",
    "#### 1 = 18-34 (1-3), 2 = 35-49 (4-6), 3 = 50-64 (7-9), 4 = 65-79 (10-12), 5 = 80+ (13) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age\n",
       "10.0    10856\n",
       "9.0     10112\n",
       "8.0      8603\n",
       "11.0     8044\n",
       "7.0      6872\n",
       "13.0     5426\n",
       "12.0     5394\n",
       "6.0      4648\n",
       "5.0      3520\n",
       "4.0      2793\n",
       "3.0      2049\n",
       "2.0      1396\n",
       "1.0       979\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_df['Age'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def age_replace(x):\n",
    "#     if x >= 1 and x <= 3:\n",
    "#         return \"Age 18-34\"\n",
    "#     elif x > 3 and x <= 6:\n",
    "#         return \"Age 35-49\"\n",
    "#     elif x > 6 and x <= 9:\n",
    "#         return \"Age 50-64\"\n",
    "#     elif x > 9 and x <= 12:\n",
    "#         return \"Age 65-79\"\n",
    "#     elif x > 12:\n",
    "#         return \"Age 80+\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diabetes_df['Age'] = diabetes_df['Age'].apply(age_replace)\n",
    "# diabetes_df['Age'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDUCATION\n",
    "1. Never attended school or only kindergarten\n",
    "2. Grades 1 through 8 (Elementary)\n",
    "3. Grades 9 through 11 (Some high school)\n",
    "4. Grade 12 or GED (High school graduate)\n",
    "5. College 1 year to 3 years (Some college or technical school)\n",
    "6. College 4 years or more (College graduate)\n",
    "\n",
    "#### split between : higher vs non-higher edu, 5-6 higher, 1-4 lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def edu_replace(x):\n",
    "#     if x >= 1 and x <= 4:\n",
    "#         return \"Lower Education\"\n",
    "#     elif x > 4:\n",
    "#         return \"Higher Education\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diabetes_df['Education'] = diabetes_df['Education'].apply(edu_replace)\n",
    "# diabetes_df['Education'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INCOME\n",
    "1. Less than $10,000\n",
    "2. Less than $15,000 ($10,000 to less than $15,000)\n",
    "3. Less than $20,000 ($15,000 to less than $20,000)\n",
    "4. Less than $25,000 ($20,000 to less than $25,000)\n",
    "5. Less than $35,000 ($25,000 to less than $35,000)\n",
    "6. Less than $50,000 ($35,000 to less than $50,000)\n",
    "7. Less than $75,000 ($50,000 to less than $75,000)\n",
    "8. $75,000 or more\n",
    "\n",
    "#### group 1-3, 4-7, 8 by itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Income\n",
       "8.0    20646\n",
       "7.0    11425\n",
       "6.0    10287\n",
       "5.0     8010\n",
       "4.0     6658\n",
       "3.0     5557\n",
       "2.0     4498\n",
       "1.0     3611\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_df['Income'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def income_replace(x):\n",
    "#     if x >= 1 and x <= 3:\n",
    "#         return \"Less than $20,000\"\n",
    "#     elif x > 3 and x <= 7:\n",
    "#         return \"Between $20,000 and $75,000\"\n",
    "#     elif x > 7:\n",
    "#         return \"More than $75,000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diabetes_df['Income'] = diabetes_df['Income'].apply(income_replace)\n",
    "# diabetes_df['Income'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BMI_classification(x):\n",
    "    if x < 18.5:\n",
    "        return \"Underweight\"\n",
    "    elif x > 18.5 and x <=24.9:\n",
    "        return \"Normal\"\n",
    "    elif x > 24.9 and x <= 29.9:\n",
    "        return \"Overweight\"\n",
    "    elif x > 29.9 and x <= 34.9:\n",
    "        return \"Obesity 1\"\n",
    "    elif x > 34.9 and x <= 39.9:\n",
    "        return \"Obesity 2\"\n",
    "    elif x > 39.9:\n",
    "        return \"Obesity 3\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BMI\n",
       "Overweight     24135\n",
       "Obesity 1      17301\n",
       "Normal         14460\n",
       "Obesity 2       8112\n",
       "Obesity 3       6031\n",
       "Underweight      653\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_df['BMI'] = diabetes_df['BMI'].apply(BMI_classification)\n",
    "diabetes_df['BMI'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin Splitting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = diabetes_df.drop(columns='Diabetes_binary')\n",
    "y = diabetes_df['Diabetes_binary']\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, random_state=12)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding Categorical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BMI    0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "BMI    0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create encoder and fit\n",
    "encode_BMI = OrdinalEncoder(categories=[['Underweight', 'Normal', 'Overweight', 'Obesity 1', 'Obesity 2', 'Obesity 3']], handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "encode_BMI.fit(x_train['BMI'].values.reshape(-1,1))\n",
    "encode_BMI_train = encode_BMI.transform(x_train['BMI'].values.reshape(-1, 1))\n",
    "encode_BMI_test = encode_BMI.transform(x_test['BMI'].values.reshape(-1, 1))\n",
    "\n",
    "# create the df\n",
    "encode_BMI_df_train = pd.DataFrame(encode_BMI_train, columns=['BMI'])\n",
    "encode_BMI_df_test = pd.DataFrame(encode_BMI_test, columns=['BMI'])\n",
    "encode_BMI_df_train.head()\n",
    "display(encode_BMI_df_train.isna().sum())\n",
    "display(encode_BMI_df_test.isna().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create encoder and fit\n",
    "# encode_income = OrdinalEncoder(categories=[['Less than $20,000','Between $20,000 and $75,000','More than $75,000']], handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "# encode_income.fit(x_train['Income'].values.reshape(-1,1))\n",
    "# encode_income_train = encode_income.transform(x_train['Income'].values.reshape(-1, 1))\n",
    "# encode_income_test = encode_income.transform(x_test['Income'].values.reshape(-1, 1))\n",
    "\n",
    "# # create the df\n",
    "# encode_income_df_train = pd.DataFrame(encode_income_train, columns=['Income'])\n",
    "# encode_income_df_test = pd.DataFrame(encode_income_test, columns=['Income'])\n",
    "# display(encode_income_df_train.isna().sum())\n",
    "# display(encode_income_df_test.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create encoder and fit \n",
    "# encode_educ = OrdinalEncoder(categories=[['Lower Education', 'Higher Education']], handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "# encode_educ.fit(x_train['Education'].values.reshape(-1,1))\n",
    "# encode_educ_train = encode_educ.transform(x_train['Education'].values.reshape(-1, 1))\n",
    "# encode_educ_test = encode_educ.transform(x_test['Education'].values.reshape(-1, 1))\n",
    "\n",
    "# # create the df\n",
    "# encode_educ_df_train = pd.DataFrame(encode_educ_train, columns=['Education'])\n",
    "# encode_educ_df_test = pd.DataFrame(encode_educ_test, columns=['Education'])\n",
    "\n",
    "# display(encode_educ_df_train.isna().sum())\n",
    "# display(encode_educ_df_test.isna().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age\n",
       "10.0    8110\n",
       "9.0     7591\n",
       "8.0     6414\n",
       "11.0    5997\n",
       "7.0     5156\n",
       "13.0    4130\n",
       "12.0    4031\n",
       "6.0     3502\n",
       "5.0     2660\n",
       "4.0     2099\n",
       "3.0     1533\n",
       "2.0     1042\n",
       "1.0      754\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the original columns names for the age column\n",
    "#diabetes_df['Age'].value_counts()\n",
    "x_train['Age'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Education\n",
       "6.0    19477\n",
       "5.0    15026\n",
       "4.0    14646\n",
       "3.0     2574\n",
       "2.0     1238\n",
       "1.0       58\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train['Education'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create encoder and fit \n",
    "# encode_age = OrdinalEncoder(categories=[['Age 18-34', 'Age 35-49', 'Age 50-64', 'Age 65-79', 'Age 80+']], handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "# encode_age.fit(x_train['Age'].values.reshape(-1,1))\n",
    "# encode_age_train = encode_age.transform(x_train['Age'].values.reshape(-1, 1))\n",
    "# encode_age_test = encode_age.transform(x_test['Age'].values.reshape(-1, 1))\n",
    "\n",
    "# # create the df\n",
    "# encode_age_df_train = pd.DataFrame(encode_age_train, columns=['Age'])\n",
    "# encode_age_df_test = pd.DataFrame(encode_age_test, columns=['Age'])\n",
    "\n",
    "# display(encode_age_df_train.isna().sum())\n",
    "# display(encode_age_df_test.isna().sum())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Group all encoded_dfs with the main df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HighBP                  0\n",
       "HighChol                0\n",
       "CholCheck               0\n",
       "Stroke                  0\n",
       "HeartDiseaseorAttack    0\n",
       "PhysActivity            0\n",
       "GenHlth                 0\n",
       "PhysHlth                0\n",
       "DiffWalk                0\n",
       "BMI                     0\n",
       "Income                  0\n",
       "Education               0\n",
       "Age                     0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "HighBP                  0\n",
       "HighChol                0\n",
       "CholCheck               0\n",
       "Stroke                  0\n",
       "HeartDiseaseorAttack    0\n",
       "PhysActivity            0\n",
       "GenHlth                 0\n",
       "PhysHlth                0\n",
       "DiffWalk                0\n",
       "BMI                     0\n",
       "Income                  0\n",
       "Education               0\n",
       "Age                     0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create a copy of the df without the unencoded columns\n",
    "# train\n",
    "x_train_unencoded = x_train.copy().drop(columns=['Age', 'Education', 'Income', 'BMI'])\n",
    "x_train_unencoded = x_train_unencoded.reset_index(drop=True)\n",
    "# test\n",
    "x_test_unencoded = x_test.copy().drop(columns=['Age', 'Education', 'Income', 'BMI'])\n",
    "x_test_unencoded = x_test_unencoded.reset_index(drop=True)\n",
    "\n",
    "# add the encoded columns\n",
    "x_train_encoded = pd.concat([x_train_unencoded, encode_BMI_df_train, encode_income_df_train, encode_educ_df_train, encode_age_df_train], axis=1)\n",
    "x_test_encoded = pd.concat([x_test_unencoded, encode_BMI_df_test, encode_income_df_test, encode_educ_df_test, encode_age_df_test], axis=1)\n",
    "\n",
    "# the results\n",
    "display(x_train_encoded.isna().sum())\n",
    "display(x_test_encoded.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale the data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train_encoded)\n",
    "x_train_encoded = scaler.transform(x_train_encoded)\n",
    "x_test_encoded = scaler.transform(x_test_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the ML Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 1, Train/Test Score: 0.822/0.673\n",
      "k: 3, Train/Test Score: 0.785/0.703\n",
      "k: 5, Train/Test Score: 0.772/0.718\n",
      "k: 7, Train/Test Score: 0.766/0.724\n",
      "k: 9, Train/Test Score: 0.763/0.727\n",
      "k: 11, Train/Test Score: 0.759/0.729\n",
      "k: 13, Train/Test Score: 0.759/0.732\n",
      "k: 15, Train/Test Score: 0.757/0.736\n",
      "k: 17, Train/Test Score: 0.757/0.735\n",
      "k: 19, Train/Test Score: 0.756/0.740\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loop through different k values to find which has the highest accuracy.\n",
    "# Note: We use only odd numbers because we don't want any ties.\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for k in range(1, 20, 2):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(x_train_encoded, y_train)\n",
    "    train_score = knn.score(x_train_encoded, y_train)\n",
    "    test_score = knn.score(x_test_encoded, y_test)\n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "    print(f\"k: {k}, Train/Test Score: {train_score:.3f}/{test_score:.3f}\")\n",
    "    \n",
    "# Plot the results\n",
    "plt.plot(range(1, 20, 2), train_scores, marker='o', label=\"training scores\")\n",
    "plt.plot(range(1, 20, 2), test_scores, marker=\"x\", label=\"testing scores\")\n",
    "plt.xlabel(\"k neighbors\")\n",
    "plt.ylabel(\"accuracy score\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.751145815650993"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Create and fit the logistic regression model\n",
    "logistic_regression_model = LogisticRegression(random_state=1, max_iter=1000)\n",
    "logistic_regression_model.fit(x_train_encoded, y_train)\n",
    "\n",
    "#make and save testing predictions with the saved logistic regression model using the test data\n",
    "predictions = logistic_regression_model.predict(x_test_encoded)\n",
    "\n",
    "# Review the accuracy\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "display(accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.751145815650993 (ungrouping age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.6912239008657274\n"
     ]
    }
   ],
   "source": [
    "# create the model\n",
    "tree_model = tree.DecisionTreeClassifier()\n",
    "#fit the model\n",
    "tree_model = tree_model.fit(x_train_encoded, y_train)\n",
    "# Making predictions using the testing data\n",
    "predictions = tree_model.predict(x_test_encoded)\n",
    "# Calculate the accuracy score\n",
    "acc_score = accuracy_score(y_test, predictions)\n",
    "print(f\"Accuracy Score : {acc_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.7707614251494748\n",
      "Testing Score: 0.753522322186386\n",
      "Accuracy Score : 0.753522322186386\n"
     ]
    }
   ],
   "source": [
    "# Train the Random Forest model\n",
    "clf = RandomForestClassifier(random_state=1, n_estimators=1000, max_depth=11).fit(x_train_encoded, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "print(f'Training Score: {clf.score(x_train_encoded, y_train)}')\n",
    "print(f'Testing Score: {clf.score(x_test_encoded, y_test)}')\n",
    "\n",
    "# Calculate the accuracy score\n",
    "predictions = clf.predict(x_test_encoded)\n",
    "acc_score = accuracy_score(y_test, predictions)\n",
    "print(f\"Accuracy Score : {acc_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.753465738697448\n",
      "Confusion Matrix: [[6304 2543]\n",
      " [1814 7012]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.71      0.74      8847\n",
      "         1.0       0.73      0.79      0.76      8826\n",
      "\n",
      "    accuracy                           0.75     17673\n",
      "   macro avg       0.76      0.75      0.75     17673\n",
      "weighted avg       0.76      0.75      0.75     17673\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "# Create the XGBClassifier model\n",
    "xgb_model = XGBClassifier(random_state=1, learning_rate=0.05, n_estimators=1000, max_depth=3)\n",
    "# Fit the model\n",
    "xgb_model.fit(x_train_encoded, y_train)\n",
    "# Make predictions\n",
    "predictions = xgb_model.predict(x_test_encoded)\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Create the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, predictions)\n",
    "print(f\"Confusion Matrix: {conf_matrix}\")\n",
    "\n",
    "#create heatmap for confusion matrix\n",
    "sns.heatmap(conf_matrix, annot=True, cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#Create the classification report\n",
    "class_report = classification_report(y_test, predictions)\n",
    "print(f\"Classification Report: \\n{class_report}\")\n",
    "\n",
    "# # Create the ROC curve\n",
    "# RocCurveDisplay.from_estimator(xgb_model, x_test_encoded, y_test)\n",
    "# plt.show()\n",
    "\n",
    "# Create the precision-recall curve\n",
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "\n",
    "# PrecisionRecallDisplay.from_estimator(xgb_model, x_test_encoded, y_test)\n",
    "# plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV 1/5] END .....max_depth=3, n_estimators=100;, score=0.741 total time=   0.5s\n",
      "[CV 2/5] END .....max_depth=3, n_estimators=100;, score=0.727 total time=   0.5s\n",
      "[CV 3/5] END .....max_depth=3, n_estimators=100;, score=0.731 total time=   0.5s\n",
      "[CV 4/5] END .....max_depth=3, n_estimators=100;, score=0.729 total time=   0.5s\n",
      "[CV 5/5] END .....max_depth=3, n_estimators=100;, score=0.741 total time=   0.5s\n",
      "[CV 1/5] END .....max_depth=3, n_estimators=500;, score=0.743 total time=   2.4s\n",
      "[CV 2/5] END .....max_depth=3, n_estimators=500;, score=0.726 total time=   2.4s\n",
      "[CV 3/5] END .....max_depth=3, n_estimators=500;, score=0.732 total time=   2.4s\n",
      "[CV 4/5] END .....max_depth=3, n_estimators=500;, score=0.731 total time=   2.4s\n",
      "[CV 5/5] END .....max_depth=3, n_estimators=500;, score=0.741 total time=   2.4s\n",
      "[CV 1/5] END ....max_depth=3, n_estimators=1000;, score=0.743 total time=   4.8s\n",
      "[CV 2/5] END ....max_depth=3, n_estimators=1000;, score=0.728 total time=   4.7s\n",
      "[CV 3/5] END ....max_depth=3, n_estimators=1000;, score=0.734 total time=   4.8s\n",
      "[CV 4/5] END ....max_depth=3, n_estimators=1000;, score=0.732 total time=   4.7s\n",
      "[CV 5/5] END ....max_depth=3, n_estimators=1000;, score=0.740 total time=   4.8s\n",
      "[CV 1/5] END .....max_depth=7, n_estimators=100;, score=0.752 total time=   0.7s\n",
      "[CV 2/5] END .....max_depth=7, n_estimators=100;, score=0.736 total time=   0.7s\n",
      "[CV 3/5] END .....max_depth=7, n_estimators=100;, score=0.743 total time=   0.7s\n",
      "[CV 4/5] END .....max_depth=7, n_estimators=100;, score=0.740 total time=   0.7s\n",
      "[CV 5/5] END .....max_depth=7, n_estimators=100;, score=0.748 total time=   0.7s\n",
      "[CV 1/5] END .....max_depth=7, n_estimators=500;, score=0.753 total time=   3.6s\n",
      "[CV 2/5] END .....max_depth=7, n_estimators=500;, score=0.738 total time=   3.6s\n",
      "[CV 3/5] END .....max_depth=7, n_estimators=500;, score=0.743 total time=   3.7s\n",
      "[CV 4/5] END .....max_depth=7, n_estimators=500;, score=0.740 total time=   3.7s\n",
      "[CV 5/5] END .....max_depth=7, n_estimators=500;, score=0.747 total time=   3.9s\n",
      "[CV 1/5] END ....max_depth=7, n_estimators=1000;, score=0.752 total time=   7.6s\n",
      "[CV 2/5] END ....max_depth=7, n_estimators=1000;, score=0.738 total time=   7.5s\n",
      "[CV 3/5] END ....max_depth=7, n_estimators=1000;, score=0.741 total time=   7.8s\n",
      "[CV 4/5] END ....max_depth=7, n_estimators=1000;, score=0.740 total time=   8.0s\n",
      "[CV 5/5] END ....max_depth=7, n_estimators=1000;, score=0.746 total time=   7.7s\n",
      "[CV 1/5] END ....max_depth=11, n_estimators=100;, score=0.752 total time=   1.0s\n",
      "[CV 2/5] END ....max_depth=11, n_estimators=100;, score=0.738 total time=   1.0s\n",
      "[CV 3/5] END ....max_depth=11, n_estimators=100;, score=0.745 total time=   1.2s\n",
      "[CV 4/5] END ....max_depth=11, n_estimators=100;, score=0.741 total time=   1.0s\n",
      "[CV 5/5] END ....max_depth=11, n_estimators=100;, score=0.750 total time=   1.0s\n",
      "[CV 1/5] END ....max_depth=11, n_estimators=500;, score=0.754 total time=   5.0s\n",
      "[CV 2/5] END ....max_depth=11, n_estimators=500;, score=0.738 total time=   5.2s\n",
      "[CV 3/5] END ....max_depth=11, n_estimators=500;, score=0.744 total time=   5.1s\n",
      "[CV 4/5] END ....max_depth=11, n_estimators=500;, score=0.742 total time=   5.1s\n",
      "[CV 5/5] END ....max_depth=11, n_estimators=500;, score=0.751 total time=   5.0s\n",
      "[CV 1/5] END ...max_depth=11, n_estimators=1000;, score=0.755 total time=  10.3s\n",
      "[CV 2/5] END ...max_depth=11, n_estimators=1000;, score=0.738 total time=  10.1s\n",
      "[CV 3/5] END ...max_depth=11, n_estimators=1000;, score=0.743 total time=  10.8s\n",
      "[CV 4/5] END ...max_depth=11, n_estimators=1000;, score=0.740 total time=  10.5s\n",
      "[CV 5/5] END ...max_depth=11, n_estimators=1000;, score=0.750 total time=  10.9s\n",
      "Accuracy: 0.7536354891642618\n",
      "{'max_depth': 11, 'n_estimators': 500}\n",
      "0.7458270566257893\n"
     ]
    }
   ],
   "source": [
    "#grid search\n",
    "\n",
    "#%pip install -U xgboost scikit-learn\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create the parameter grid for the GridSearchCV model running random forest\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 500, 1000],\n",
    "    'max_depth': [3, 7, 11]\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "# Create the GridSearchCV model\n",
    "#grid_model = GridSearchCV(logistic_regression_model, param_grid, verbose=3)\n",
    "grid_model = GridSearchCV(RandomForestClassifier(), param_grid, verbose=3)\n",
    "\n",
    "# Fit the model\n",
    "grid_model.fit(x_train_encoded, y_train)\n",
    "\n",
    "# Make predictions\n",
    "predictions = grid_model.predict(x_test_encoded)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Print the best parameters\n",
    "print(grid_model.best_params_)\n",
    "print(grid_model.best_score_)\n",
    "# print(grid_model.best_estimator_)\n",
    "# print(grid_model.cv_results_)\n",
    "# print(grid_model.best_index_)\n",
    "# print(grid_model.scorer_)\n",
    "# print(grid_model.n_splits_)\n",
    "# print(grid_model.refit_time_)\n",
    "# print(grid_model.error_score)\n",
    "# print(grid_model.param_grid)\n",
    "# print(grid_model.pre_dispatch)\n",
    "# print(grid_model.return_train_score)\n",
    "# print(grid_model.multimetric_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy: 0.7536354891642618\n",
    "{'max_depth': 11, 'n_estimators': 500}\n",
    "0.7458270566257893\n",
    "Testing Score: 0.753522322186386\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "[CV 1/5] END C=0.1, max_iter=100, penalty=l1, solver=liblinear;, score=0.752 total time=   0.1s\n",
      "[CV 2/5] END C=0.1, max_iter=100, penalty=l1, solver=liblinear;, score=0.740 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, max_iter=100, penalty=l1, solver=liblinear;, score=0.740 total time=   0.1s\n",
      "[CV 4/5] END C=0.1, max_iter=100, penalty=l1, solver=liblinear;, score=0.739 total time=   0.1s\n",
      "[CV 5/5] END C=0.1, max_iter=100, penalty=l1, solver=liblinear;, score=0.743 total time=   0.0s\n",
      "[CV 1/5] END C=0.1, max_iter=100, penalty=l2, solver=liblinear;, score=0.752 total time=   0.1s\n",
      "[CV 2/5] END C=0.1, max_iter=100, penalty=l2, solver=liblinear;, score=0.739 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, max_iter=100, penalty=l2, solver=liblinear;, score=0.740 total time=   0.1s\n",
      "[CV 4/5] END C=0.1, max_iter=100, penalty=l2, solver=liblinear;, score=0.739 total time=   0.1s\n",
      "[CV 5/5] END C=0.1, max_iter=100, penalty=l2, solver=liblinear;, score=0.743 total time=   0.1s\n",
      "[CV 1/5] END C=0.1, max_iter=1000, penalty=l1, solver=liblinear;, score=0.752 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, max_iter=1000, penalty=l1, solver=liblinear;, score=0.740 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, max_iter=1000, penalty=l1, solver=liblinear;, score=0.740 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, max_iter=1000, penalty=l1, solver=liblinear;, score=0.739 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, max_iter=1000, penalty=l1, solver=liblinear;, score=0.743 total time=   0.1s\n",
      "[CV 1/5] END C=0.1, max_iter=1000, penalty=l2, solver=liblinear;, score=0.752 total time=   0.1s\n",
      "[CV 2/5] END C=0.1, max_iter=1000, penalty=l2, solver=liblinear;, score=0.739 total time=   0.1s\n",
      "[CV 3/5] END C=0.1, max_iter=1000, penalty=l2, solver=liblinear;, score=0.740 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, max_iter=1000, penalty=l2, solver=liblinear;, score=0.739 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, max_iter=1000, penalty=l2, solver=liblinear;, score=0.743 total time=   0.1s\n",
      "[CV 1/5] END C=0.1, max_iter=10000, penalty=l1, solver=liblinear;, score=0.752 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, max_iter=10000, penalty=l1, solver=liblinear;, score=0.740 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, max_iter=10000, penalty=l1, solver=liblinear;, score=0.740 total time=   0.1s\n",
      "[CV 4/5] END C=0.1, max_iter=10000, penalty=l1, solver=liblinear;, score=0.739 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, max_iter=10000, penalty=l1, solver=liblinear;, score=0.743 total time=   0.1s\n",
      "[CV 1/5] END C=0.1, max_iter=10000, penalty=l2, solver=liblinear;, score=0.752 total time=   0.1s\n",
      "[CV 2/5] END C=0.1, max_iter=10000, penalty=l2, solver=liblinear;, score=0.739 total time=   0.1s\n",
      "[CV 3/5] END C=0.1, max_iter=10000, penalty=l2, solver=liblinear;, score=0.740 total time=   0.1s\n",
      "[CV 4/5] END C=0.1, max_iter=10000, penalty=l2, solver=liblinear;, score=0.739 total time=   0.1s\n",
      "[CV 5/5] END C=0.1, max_iter=10000, penalty=l2, solver=liblinear;, score=0.743 total time=   0.1s\n",
      "[CV 1/5] END C=1, max_iter=100, penalty=l1, solver=liblinear;, score=0.752 total time=   0.1s\n",
      "[CV 2/5] END C=1, max_iter=100, penalty=l1, solver=liblinear;, score=0.739 total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=100, penalty=l1, solver=liblinear;, score=0.741 total time=   0.1s\n",
      "[CV 4/5] END C=1, max_iter=100, penalty=l1, solver=liblinear;, score=0.739 total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=100, penalty=l1, solver=liblinear;, score=0.743 total time=   0.1s\n",
      "[CV 1/5] END C=1, max_iter=100, penalty=l2, solver=liblinear;, score=0.752 total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=100, penalty=l2, solver=liblinear;, score=0.739 total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=100, penalty=l2, solver=liblinear;, score=0.740 total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=100, penalty=l2, solver=liblinear;, score=0.739 total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=100, penalty=l2, solver=liblinear;, score=0.743 total time=   0.1s\n",
      "[CV 1/5] END C=1, max_iter=1000, penalty=l1, solver=liblinear;, score=0.752 total time=   0.1s\n",
      "[CV 2/5] END C=1, max_iter=1000, penalty=l1, solver=liblinear;, score=0.739 total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=1000, penalty=l1, solver=liblinear;, score=0.741 total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=1000, penalty=l1, solver=liblinear;, score=0.739 total time=   0.1s\n",
      "[CV 5/5] END C=1, max_iter=1000, penalty=l1, solver=liblinear;, score=0.743 total time=   0.1s\n",
      "[CV 1/5] END C=1, max_iter=1000, penalty=l2, solver=liblinear;, score=0.752 total time=   0.2s\n",
      "[CV 2/5] END C=1, max_iter=1000, penalty=l2, solver=liblinear;, score=0.739 total time=   0.1s\n",
      "[CV 3/5] END C=1, max_iter=1000, penalty=l2, solver=liblinear;, score=0.740 total time=   0.1s\n",
      "[CV 4/5] END C=1, max_iter=1000, penalty=l2, solver=liblinear;, score=0.739 total time=   0.1s\n",
      "[CV 5/5] END C=1, max_iter=1000, penalty=l2, solver=liblinear;, score=0.743 total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=10000, penalty=l1, solver=liblinear;, score=0.752 total time=   0.1s\n",
      "[CV 2/5] END C=1, max_iter=10000, penalty=l1, solver=liblinear;, score=0.739 total time=   0.1s\n",
      "[CV 3/5] END C=1, max_iter=10000, penalty=l1, solver=liblinear;, score=0.740 total time=   0.1s\n",
      "[CV 4/5] END C=1, max_iter=10000, penalty=l1, solver=liblinear;, score=0.739 total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=10000, penalty=l1, solver=liblinear;, score=0.743 total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=10000, penalty=l2, solver=liblinear;, score=0.752 total time=   0.1s\n",
      "[CV 2/5] END C=1, max_iter=10000, penalty=l2, solver=liblinear;, score=0.739 total time=   0.1s\n",
      "[CV 3/5] END C=1, max_iter=10000, penalty=l2, solver=liblinear;, score=0.740 total time=   0.1s\n",
      "[CV 4/5] END C=1, max_iter=10000, penalty=l2, solver=liblinear;, score=0.739 total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=10000, penalty=l2, solver=liblinear;, score=0.743 total time=   0.0s\n",
      "[CV 1/5] END C=10, max_iter=100, penalty=l1, solver=liblinear;, score=0.752 total time=   0.1s\n",
      "[CV 2/5] END C=10, max_iter=100, penalty=l1, solver=liblinear;, score=0.739 total time=   0.1s\n",
      "[CV 3/5] END C=10, max_iter=100, penalty=l1, solver=liblinear;, score=0.740 total time=   0.0s\n",
      "[CV 4/5] END C=10, max_iter=100, penalty=l1, solver=liblinear;, score=0.739 total time=   0.0s\n",
      "[CV 5/5] END C=10, max_iter=100, penalty=l1, solver=liblinear;, score=0.743 total time=   0.0s\n",
      "[CV 1/5] END C=10, max_iter=100, penalty=l2, solver=liblinear;, score=0.752 total time=   0.0s\n",
      "[CV 2/5] END C=10, max_iter=100, penalty=l2, solver=liblinear;, score=0.739 total time=   0.1s\n",
      "[CV 3/5] END C=10, max_iter=100, penalty=l2, solver=liblinear;, score=0.740 total time=   0.1s\n",
      "[CV 4/5] END C=10, max_iter=100, penalty=l2, solver=liblinear;, score=0.739 total time=   0.1s\n",
      "[CV 5/5] END C=10, max_iter=100, penalty=l2, solver=liblinear;, score=0.743 total time=   0.1s\n",
      "[CV 1/5] END C=10, max_iter=1000, penalty=l1, solver=liblinear;, score=0.752 total time=   0.1s\n",
      "[CV 2/5] END C=10, max_iter=1000, penalty=l1, solver=liblinear;, score=0.739 total time=   0.0s\n",
      "[CV 3/5] END C=10, max_iter=1000, penalty=l1, solver=liblinear;, score=0.740 total time=   0.1s\n",
      "[CV 4/5] END C=10, max_iter=1000, penalty=l1, solver=liblinear;, score=0.739 total time=   0.0s\n",
      "[CV 5/5] END C=10, max_iter=1000, penalty=l1, solver=liblinear;, score=0.743 total time=   0.1s\n",
      "[CV 1/5] END C=10, max_iter=1000, penalty=l2, solver=liblinear;, score=0.752 total time=   0.0s\n",
      "[CV 2/5] END C=10, max_iter=1000, penalty=l2, solver=liblinear;, score=0.739 total time=   0.1s\n",
      "[CV 3/5] END C=10, max_iter=1000, penalty=l2, solver=liblinear;, score=0.740 total time=   0.0s\n",
      "[CV 4/5] END C=10, max_iter=1000, penalty=l2, solver=liblinear;, score=0.739 total time=   0.0s\n",
      "[CV 5/5] END C=10, max_iter=1000, penalty=l2, solver=liblinear;, score=0.743 total time=   0.0s\n",
      "[CV 1/5] END C=10, max_iter=10000, penalty=l1, solver=liblinear;, score=0.752 total time=   0.1s\n",
      "[CV 2/5] END C=10, max_iter=10000, penalty=l1, solver=liblinear;, score=0.739 total time=   0.0s\n",
      "[CV 3/5] END C=10, max_iter=10000, penalty=l1, solver=liblinear;, score=0.740 total time=   0.0s\n",
      "[CV 4/5] END C=10, max_iter=10000, penalty=l1, solver=liblinear;, score=0.739 total time=   0.0s\n",
      "[CV 5/5] END C=10, max_iter=10000, penalty=l1, solver=liblinear;, score=0.743 total time=   0.1s\n",
      "[CV 1/5] END C=10, max_iter=10000, penalty=l2, solver=liblinear;, score=0.752 total time=   0.1s\n",
      "[CV 2/5] END C=10, max_iter=10000, penalty=l2, solver=liblinear;, score=0.739 total time=   0.0s\n",
      "[CV 3/5] END C=10, max_iter=10000, penalty=l2, solver=liblinear;, score=0.740 total time=   0.1s\n",
      "[CV 4/5] END C=10, max_iter=10000, penalty=l2, solver=liblinear;, score=0.739 total time=   0.1s\n",
      "[CV 5/5] END C=10, max_iter=10000, penalty=l2, solver=liblinear;, score=0.743 total time=   0.0s\n",
      "[CV 1/5] END C=100, max_iter=100, penalty=l1, solver=liblinear;, score=0.752 total time=   0.0s\n",
      "[CV 2/5] END C=100, max_iter=100, penalty=l1, solver=liblinear;, score=0.739 total time=   0.1s\n",
      "[CV 3/5] END C=100, max_iter=100, penalty=l1, solver=liblinear;, score=0.740 total time=   0.0s\n",
      "[CV 4/5] END C=100, max_iter=100, penalty=l1, solver=liblinear;, score=0.739 total time=   0.0s\n",
      "[CV 5/5] END C=100, max_iter=100, penalty=l1, solver=liblinear;, score=0.743 total time=   0.0s\n",
      "[CV 1/5] END C=100, max_iter=100, penalty=l2, solver=liblinear;, score=0.752 total time=   0.0s\n",
      "[CV 2/5] END C=100, max_iter=100, penalty=l2, solver=liblinear;, score=0.739 total time=   0.0s\n",
      "[CV 3/5] END C=100, max_iter=100, penalty=l2, solver=liblinear;, score=0.740 total time=   0.0s\n",
      "[CV 4/5] END C=100, max_iter=100, penalty=l2, solver=liblinear;, score=0.739 total time=   0.1s\n",
      "[CV 5/5] END C=100, max_iter=100, penalty=l2, solver=liblinear;, score=0.743 total time=   0.1s\n",
      "[CV 1/5] END C=100, max_iter=1000, penalty=l1, solver=liblinear;, score=0.752 total time=   0.0s\n",
      "[CV 2/5] END C=100, max_iter=1000, penalty=l1, solver=liblinear;, score=0.739 total time=   0.0s\n",
      "[CV 3/5] END C=100, max_iter=1000, penalty=l1, solver=liblinear;, score=0.740 total time=   0.1s\n",
      "[CV 4/5] END C=100, max_iter=1000, penalty=l1, solver=liblinear;, score=0.739 total time=   0.1s\n",
      "[CV 5/5] END C=100, max_iter=1000, penalty=l1, solver=liblinear;, score=0.743 total time=   0.1s\n",
      "[CV 1/5] END C=100, max_iter=1000, penalty=l2, solver=liblinear;, score=0.752 total time=   0.1s\n",
      "[CV 2/5] END C=100, max_iter=1000, penalty=l2, solver=liblinear;, score=0.739 total time=   0.1s\n",
      "[CV 3/5] END C=100, max_iter=1000, penalty=l2, solver=liblinear;, score=0.740 total time=   0.1s\n",
      "[CV 4/5] END C=100, max_iter=1000, penalty=l2, solver=liblinear;, score=0.739 total time=   0.1s\n",
      "[CV 5/5] END C=100, max_iter=1000, penalty=l2, solver=liblinear;, score=0.743 total time=   0.1s\n",
      "[CV 1/5] END C=100, max_iter=10000, penalty=l1, solver=liblinear;, score=0.752 total time=   0.1s\n",
      "[CV 2/5] END C=100, max_iter=10000, penalty=l1, solver=liblinear;, score=0.739 total time=   0.0s\n",
      "[CV 3/5] END C=100, max_iter=10000, penalty=l1, solver=liblinear;, score=0.740 total time=   0.0s\n",
      "[CV 4/5] END C=100, max_iter=10000, penalty=l1, solver=liblinear;, score=0.739 total time=   0.1s\n",
      "[CV 5/5] END C=100, max_iter=10000, penalty=l1, solver=liblinear;, score=0.743 total time=   0.0s\n",
      "[CV 1/5] END C=100, max_iter=10000, penalty=l2, solver=liblinear;, score=0.752 total time=   0.0s\n",
      "[CV 2/5] END C=100, max_iter=10000, penalty=l2, solver=liblinear;, score=0.739 total time=   0.0s\n",
      "[CV 3/5] END C=100, max_iter=10000, penalty=l2, solver=liblinear;, score=0.740 total time=   0.0s\n",
      "[CV 4/5] END C=100, max_iter=10000, penalty=l2, solver=liblinear;, score=0.739 total time=   0.1s\n",
      "[CV 5/5] END C=100, max_iter=10000, penalty=l2, solver=liblinear;, score=0.743 total time=   0.1s\n",
      "Accuracy: 0.7509194816952414\n",
      "{'C': 0.1, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.7427714724411463\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create the parameter grid for the GridSearchCV model running logistic regression\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear'], \n",
    "    'max_iter': [100, 1000, 10000]\n",
    "}\n",
    "#C', 'class_weight', 'dual', 'fit_intercept', 'intercept_scaling', 'l1_ratio', 'max_iter', 'multi_class', 'n_jobs', 'penalty', 'random_state', 'solver', 'tol', 'verbose', 'warm_start\n",
    "\n",
    "# Create the GridSearchCV model\n",
    "grid_model = GridSearchCV(LogisticRegression(), param_grid, verbose=3)\n",
    "\n",
    "# Fit the model\n",
    "grid_model.fit(x_train_encoded, y_train)\n",
    "\n",
    "# Make predictions\n",
    "predictions = grid_model.predict(x_test_encoded)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Print the best parameters\n",
    "print(grid_model.best_params_)\n",
    "print(grid_model.best_score_)\n",
    "# print(grid_model.best_estimator_)\n",
    "# print(grid_model.cv_results_)\n",
    "# print(grid_model.best_index_)\n",
    "# print(grid_model.scorer_)\n",
    "# print(grid_model.n_splits_)\n",
    "# print(grid_model.refit_time_)\n",
    "# print(grid_model.error_score)\n",
    "# print(grid_model.param_grid)\n",
    "# print(grid_model.pre_dispatch)\n",
    "# print(grid_model.return_train_score)\n",
    "# print(grid_model.multimetric_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV 1/5] END algorithm=auto, metric=euclidean, n_neighbors=19, weights=uniform;, score=0.742 total time=   1.8s\n",
      "[CV 2/5] END algorithm=auto, metric=euclidean, n_neighbors=19, weights=uniform;, score=0.729 total time=   1.5s\n",
      "[CV 3/5] END algorithm=auto, metric=euclidean, n_neighbors=19, weights=uniform;, score=0.737 total time=   1.4s\n",
      "[CV 4/5] END algorithm=auto, metric=euclidean, n_neighbors=19, weights=uniform;, score=0.729 total time=   1.5s\n",
      "[CV 5/5] END algorithm=auto, metric=euclidean, n_neighbors=19, weights=uniform;, score=0.735 total time=   1.5s\n",
      "[CV 1/5] END algorithm=auto, metric=euclidean, n_neighbors=19, weights=distance;, score=0.720 total time=   1.4s\n",
      "[CV 2/5] END algorithm=auto, metric=euclidean, n_neighbors=19, weights=distance;, score=0.706 total time=   1.3s\n",
      "[CV 3/5] END algorithm=auto, metric=euclidean, n_neighbors=19, weights=distance;, score=0.719 total time=   1.3s\n",
      "[CV 4/5] END algorithm=auto, metric=euclidean, n_neighbors=19, weights=distance;, score=0.708 total time=   1.3s\n",
      "[CV 5/5] END algorithm=auto, metric=euclidean, n_neighbors=19, weights=distance;, score=0.714 total time=   1.4s\n",
      "[CV 1/5] END algorithm=auto, metric=manhattan, n_neighbors=19, weights=uniform;, score=0.742 total time=   1.6s\n",
      "[CV 2/5] END algorithm=auto, metric=manhattan, n_neighbors=19, weights=uniform;, score=0.729 total time=   1.6s\n",
      "[CV 3/5] END algorithm=auto, metric=manhattan, n_neighbors=19, weights=uniform;, score=0.739 total time=   1.6s\n",
      "[CV 4/5] END algorithm=auto, metric=manhattan, n_neighbors=19, weights=uniform;, score=0.733 total time=   1.6s\n",
      "[CV 5/5] END algorithm=auto, metric=manhattan, n_neighbors=19, weights=uniform;, score=0.735 total time=   1.7s\n",
      "[CV 1/5] END algorithm=auto, metric=manhattan, n_neighbors=19, weights=distance;, score=0.719 total time=   1.6s\n",
      "[CV 2/5] END algorithm=auto, metric=manhattan, n_neighbors=19, weights=distance;, score=0.705 total time=   1.5s\n",
      "[CV 3/5] END algorithm=auto, metric=manhattan, n_neighbors=19, weights=distance;, score=0.720 total time=   1.5s\n",
      "[CV 4/5] END algorithm=auto, metric=manhattan, n_neighbors=19, weights=distance;, score=0.710 total time=   1.8s\n",
      "[CV 5/5] END algorithm=auto, metric=manhattan, n_neighbors=19, weights=distance;, score=0.715 total time=   1.5s\n",
      "[CV 1/5] END algorithm=ball_tree, metric=euclidean, n_neighbors=19, weights=uniform;, score=0.742 total time=   2.7s\n",
      "[CV 2/5] END algorithm=ball_tree, metric=euclidean, n_neighbors=19, weights=uniform;, score=0.729 total time=   2.7s\n",
      "[CV 3/5] END algorithm=ball_tree, metric=euclidean, n_neighbors=19, weights=uniform;, score=0.738 total time=   2.7s\n",
      "[CV 4/5] END algorithm=ball_tree, metric=euclidean, n_neighbors=19, weights=uniform;, score=0.730 total time=   2.7s\n",
      "[CV 5/5] END algorithm=ball_tree, metric=euclidean, n_neighbors=19, weights=uniform;, score=0.734 total time=   2.7s\n",
      "[CV 1/5] END algorithm=ball_tree, metric=euclidean, n_neighbors=19, weights=distance;, score=0.720 total time=   2.6s\n",
      "[CV 2/5] END algorithm=ball_tree, metric=euclidean, n_neighbors=19, weights=distance;, score=0.706 total time=   2.8s\n",
      "[CV 3/5] END algorithm=ball_tree, metric=euclidean, n_neighbors=19, weights=distance;, score=0.719 total time=   2.7s\n",
      "[CV 4/5] END algorithm=ball_tree, metric=euclidean, n_neighbors=19, weights=distance;, score=0.707 total time=   2.6s\n",
      "[CV 5/5] END algorithm=ball_tree, metric=euclidean, n_neighbors=19, weights=distance;, score=0.714 total time=   2.7s\n",
      "[CV 1/5] END algorithm=ball_tree, metric=manhattan, n_neighbors=19, weights=uniform;, score=0.741 total time=   2.5s\n",
      "[CV 2/5] END algorithm=ball_tree, metric=manhattan, n_neighbors=19, weights=uniform;, score=0.727 total time=   2.8s\n",
      "[CV 3/5] END algorithm=ball_tree, metric=manhattan, n_neighbors=19, weights=uniform;, score=0.739 total time=   2.5s\n",
      "[CV 4/5] END algorithm=ball_tree, metric=manhattan, n_neighbors=19, weights=uniform;, score=0.732 total time=   2.4s\n",
      "[CV 5/5] END algorithm=ball_tree, metric=manhattan, n_neighbors=19, weights=uniform;, score=0.735 total time=   2.4s\n",
      "[CV 1/5] END algorithm=ball_tree, metric=manhattan, n_neighbors=19, weights=distance;, score=0.720 total time=   2.3s\n",
      "[CV 2/5] END algorithm=ball_tree, metric=manhattan, n_neighbors=19, weights=distance;, score=0.705 total time=   2.3s\n",
      "[CV 3/5] END algorithm=ball_tree, metric=manhattan, n_neighbors=19, weights=distance;, score=0.720 total time=   2.3s\n",
      "[CV 4/5] END algorithm=ball_tree, metric=manhattan, n_neighbors=19, weights=distance;, score=0.710 total time=   2.3s\n",
      "[CV 5/5] END algorithm=ball_tree, metric=manhattan, n_neighbors=19, weights=distance;, score=0.715 total time=   2.3s\n",
      "[CV 1/5] END algorithm=kd_tree, metric=euclidean, n_neighbors=19, weights=uniform;, score=0.742 total time=   1.5s\n",
      "[CV 2/5] END algorithm=kd_tree, metric=euclidean, n_neighbors=19, weights=uniform;, score=0.729 total time=   1.5s\n",
      "[CV 3/5] END algorithm=kd_tree, metric=euclidean, n_neighbors=19, weights=uniform;, score=0.737 total time=   1.5s\n",
      "[CV 4/5] END algorithm=kd_tree, metric=euclidean, n_neighbors=19, weights=uniform;, score=0.729 total time=   1.5s\n",
      "[CV 5/5] END algorithm=kd_tree, metric=euclidean, n_neighbors=19, weights=uniform;, score=0.735 total time=   1.5s\n",
      "[CV 1/5] END algorithm=kd_tree, metric=euclidean, n_neighbors=19, weights=distance;, score=0.720 total time=   1.4s\n",
      "[CV 2/5] END algorithm=kd_tree, metric=euclidean, n_neighbors=19, weights=distance;, score=0.706 total time=   1.4s\n",
      "[CV 3/5] END algorithm=kd_tree, metric=euclidean, n_neighbors=19, weights=distance;, score=0.719 total time=   1.3s\n",
      "[CV 4/5] END algorithm=kd_tree, metric=euclidean, n_neighbors=19, weights=distance;, score=0.708 total time=   1.3s\n",
      "[CV 5/5] END algorithm=kd_tree, metric=euclidean, n_neighbors=19, weights=distance;, score=0.714 total time=   1.4s\n",
      "[CV 1/5] END algorithm=kd_tree, metric=manhattan, n_neighbors=19, weights=uniform;, score=0.742 total time=   1.8s\n",
      "[CV 2/5] END algorithm=kd_tree, metric=manhattan, n_neighbors=19, weights=uniform;, score=0.729 total time=   1.7s\n",
      "[CV 3/5] END algorithm=kd_tree, metric=manhattan, n_neighbors=19, weights=uniform;, score=0.739 total time=   1.7s\n",
      "[CV 4/5] END algorithm=kd_tree, metric=manhattan, n_neighbors=19, weights=uniform;, score=0.733 total time=   1.8s\n",
      "[CV 5/5] END algorithm=kd_tree, metric=manhattan, n_neighbors=19, weights=uniform;, score=0.735 total time=   1.7s\n",
      "[CV 1/5] END algorithm=kd_tree, metric=manhattan, n_neighbors=19, weights=distance;, score=0.719 total time=   1.6s\n",
      "[CV 2/5] END algorithm=kd_tree, metric=manhattan, n_neighbors=19, weights=distance;, score=0.705 total time=   1.5s\n",
      "[CV 3/5] END algorithm=kd_tree, metric=manhattan, n_neighbors=19, weights=distance;, score=0.720 total time=   1.5s\n",
      "[CV 4/5] END algorithm=kd_tree, metric=manhattan, n_neighbors=19, weights=distance;, score=0.710 total time=   1.5s\n",
      "[CV 5/5] END algorithm=kd_tree, metric=manhattan, n_neighbors=19, weights=distance;, score=0.715 total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(82135) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END algorithm=brute, metric=euclidean, n_neighbors=19, weights=uniform;, score=0.743 total time=   0.6s\n",
      "[CV 2/5] END algorithm=brute, metric=euclidean, n_neighbors=19, weights=uniform;, score=0.727 total time=   0.4s\n",
      "[CV 3/5] END algorithm=brute, metric=euclidean, n_neighbors=19, weights=uniform;, score=0.736 total time=   0.4s\n",
      "[CV 4/5] END algorithm=brute, metric=euclidean, n_neighbors=19, weights=uniform;, score=0.728 total time=   0.4s\n",
      "[CV 5/5] END algorithm=brute, metric=euclidean, n_neighbors=19, weights=uniform;, score=0.736 total time=   0.4s\n",
      "[CV 1/5] END algorithm=brute, metric=euclidean, n_neighbors=19, weights=distance;, score=0.722 total time=   0.3s\n",
      "[CV 2/5] END algorithm=brute, metric=euclidean, n_neighbors=19, weights=distance;, score=0.706 total time=   0.3s\n",
      "[CV 3/5] END algorithm=brute, metric=euclidean, n_neighbors=19, weights=distance;, score=0.719 total time=   0.2s\n",
      "[CV 4/5] END algorithm=brute, metric=euclidean, n_neighbors=19, weights=distance;, score=0.708 total time=   0.2s\n",
      "[CV 5/5] END algorithm=brute, metric=euclidean, n_neighbors=19, weights=distance;, score=0.716 total time=   0.3s\n",
      "[CV 1/5] END algorithm=brute, metric=manhattan, n_neighbors=19, weights=uniform;, score=0.741 total time=   0.5s\n",
      "[CV 2/5] END algorithm=brute, metric=manhattan, n_neighbors=19, weights=uniform;, score=0.729 total time=   0.4s\n",
      "[CV 3/5] END algorithm=brute, metric=manhattan, n_neighbors=19, weights=uniform;, score=0.738 total time=   0.5s\n",
      "[CV 4/5] END algorithm=brute, metric=manhattan, n_neighbors=19, weights=uniform;, score=0.732 total time=   0.5s\n",
      "[CV 5/5] END algorithm=brute, metric=manhattan, n_neighbors=19, weights=uniform;, score=0.735 total time=   0.5s\n",
      "[CV 1/5] END algorithm=brute, metric=manhattan, n_neighbors=19, weights=distance;, score=0.720 total time=   0.6s\n",
      "[CV 2/5] END algorithm=brute, metric=manhattan, n_neighbors=19, weights=distance;, score=0.705 total time=   0.6s\n",
      "[CV 3/5] END algorithm=brute, metric=manhattan, n_neighbors=19, weights=distance;, score=0.719 total time=   0.6s\n",
      "[CV 4/5] END algorithm=brute, metric=manhattan, n_neighbors=19, weights=distance;, score=0.709 total time=   0.8s\n",
      "[CV 5/5] END algorithm=brute, metric=manhattan, n_neighbors=19, weights=distance;, score=0.715 total time=   0.6s\n",
      "Accuracy: 0.7380184462173938\n",
      "{'algorithm': 'auto', 'metric': 'manhattan', 'n_neighbors': 19, 'weights': 'uniform'}\n",
      "0.7353024291218407\n"
     ]
    }
   ],
   "source": [
    "# Create the parameter grid for the GridSearchCV model running KNeighborsClassifier\n",
    "param_grid = {\n",
    "    'n_neighbors': [19], \n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan'],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "}\n",
    "\n",
    "# Create the GridSearchCV model\n",
    "grid_model = GridSearchCV(KNeighborsClassifier(), param_grid, verbose=3)\n",
    "\n",
    "# Fit the model\n",
    "grid_model.fit(x_train_encoded, y_train)\n",
    "\n",
    "# Make predictions\n",
    "predictions = grid_model.predict(x_test_encoded)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Print the best parameters\n",
    "print(grid_model.best_params_)\n",
    "print(grid_model.best_score_)\n",
    "# print(grid_model.best_estimator_)\n",
    "# print(grid_model.cv_results_)\n",
    "# print(grid_model.best_index_)\n",
    "# print(grid_model.scorer_)\n",
    "# print(grid_model.n_splits_)\n",
    "# print(grid_model.refit_time_)\n",
    "# print(grid_model.error_score)\n",
    "# print(grid_model.param_grid)\n",
    "# print(grid_model.pre_dispatch)\n",
    "# print(grid_model.return_train_score)\n",
    "# print(grid_model.multimetric_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip show scikit-learn xgboost\n",
    "# %pip install --upgrade scikit-learn xgboost\n",
    "\n",
    "#uninstall xgboost and scikit-learn\n",
    "#%pip uninstall xgboost scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'super' object has no attribute '__sklearn_tags__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[332], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m grid_model \u001b[38;5;241m=\u001b[39m GridSearchCV(XGBClassifier(), param_grid, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Fit the model\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[43mgrid_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train_encoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[1;32m     16\u001b[0m predictions \u001b[38;5;241m=\u001b[39m grid_model\u001b[38;5;241m.\u001b[39mpredict(x_test_encoded)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dev/lib/python3.10/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dev/lib/python3.10/site-packages/sklearn/model_selection/_search.py:932\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    928\u001b[0m params \u001b[38;5;241m=\u001b[39m _check_method_params(X, params\u001b[38;5;241m=\u001b[39mparams)\n\u001b[1;32m    930\u001b[0m routed_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_routed_params_for_fit(params)\n\u001b[0;32m--> 932\u001b[0m cv_orig \u001b[38;5;241m=\u001b[39m check_cv(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv, y, classifier\u001b[38;5;241m=\u001b[39m\u001b[43mis_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    933\u001b[0m n_splits \u001b[38;5;241m=\u001b[39m cv_orig\u001b[38;5;241m.\u001b[39mget_n_splits(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39msplitter\u001b[38;5;241m.\u001b[39msplit)\n\u001b[1;32m    935\u001b[0m base_estimator \u001b[38;5;241m=\u001b[39m clone(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dev/lib/python3.10/site-packages/sklearn/base.py:1237\u001b[0m, in \u001b[0;36mis_classifier\u001b[0;34m(estimator)\u001b[0m\n\u001b[1;32m   1230\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1231\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassing a class to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mprint\u001b[39m(inspect\u001b[38;5;241m.\u001b[39mstack()[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m3\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is deprecated and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1232\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill be removed in 1.8. Use an instance of the class instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1233\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m   1234\u001b[0m     )\n\u001b[1;32m   1235\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(estimator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_estimator_type\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassifier\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_tags\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mestimator_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassifier\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dev/lib/python3.10/site-packages/sklearn/utils/_tags.py:405\u001b[0m, in \u001b[0;36mget_tags\u001b[0;34m(estimator)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m klass \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39mmro()):\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__sklearn_tags__\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mvars\u001b[39m(klass):\n\u001b[0;32m--> 405\u001b[0m         sklearn_tags_provider[klass] \u001b[38;5;241m=\u001b[39m \u001b[43mklass\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__sklearn_tags__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    406\u001b[0m         class_order\u001b[38;5;241m.\u001b[39mappend(klass)\n\u001b[1;32m    407\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_more_tags\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mvars\u001b[39m(klass):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dev/lib/python3.10/site-packages/sklearn/base.py:540\u001b[0m, in \u001b[0;36mClassifierMixin.__sklearn_tags__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__sklearn_tags__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 540\u001b[0m     tags \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__sklearn_tags__\u001b[49m()\n\u001b[1;32m    541\u001b[0m     tags\u001b[38;5;241m.\u001b[39mestimator_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassifier\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    542\u001b[0m     tags\u001b[38;5;241m.\u001b[39mclassifier_tags \u001b[38;5;241m=\u001b[39m ClassifierTags()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'super' object has no attribute '__sklearn_tags__'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Create the parameter grid for the GridSearchCV model running Xgboost\n",
    "param_grid = {\n",
    "  #random_state=1, learning_rate=0.05, n_estimators=1000, max_depth=3\n",
    "    'learning_rate': [0.05, 0.1, 0.2],\n",
    "    'n_estimators': [100, 500, 1000],\n",
    "    'max_depth': [3, 7, 11]  \n",
    "}\n",
    "\n",
    "# Create the GridSearchCV model\n",
    "grid_model = GridSearchCV(XGBClassifier(), param_grid, verbose=3)\n",
    "\n",
    "# Fit the model\n",
    "grid_model.fit(x_train_encoded, y_train)\n",
    "\n",
    "# Make predictions\n",
    "predictions = grid_model.predict(x_test_encoded)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Print the best parameters\n",
    "print(grid_model.best_params_)\n",
    "print(grid_model.best_score_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
